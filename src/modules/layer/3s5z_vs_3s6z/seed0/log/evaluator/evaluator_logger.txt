[2025-06-07 01:39:04,251][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 01:39:04,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 01:39:04,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 01:39:04,379][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 01:39:04,410][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 01:39:04,411][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 01:39:04,411][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 01:39:04,411][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 01:39:07,869][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 01:39:07,869][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 01:39:07,869][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 01:39:07,998][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 01:39:08,014][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 01:39:08,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 01:39:08,262][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 01:39:11,253][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 01:39:11,253][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 01:39:11,375][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 01:39:11,510][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 01:39:11,752][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 01:39:11,752][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 01:39:14,449][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 01:39:14,679][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 01:39:14,990][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 01:39:15,009][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 01:39:15,355][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 01:39:16,261][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 01:39:17,907][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 01:39:18,249][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 01:39:18,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 01:39:18,287][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 01:39:19,534][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 01:39:19,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 01:39:22,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 01:39:22,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 01:39:22,228][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 01:39:23,452][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 01:39:23,468][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 01:39:23,468][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 01:39:25,410][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 01:39:26,330][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 01:39:26,541][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 01:39:26,879][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:26,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:29,585][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:29,845][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:30,481][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:31,266][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:33,946][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:34,072][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:34,072][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:34,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:35,047][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:37,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:37,733][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:37,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:38,868][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:39:39,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 01:39:39,698][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 1000.000000 | iteration_1000.pth.tar | 32.000000     | 3262.000000   | 101.937500              | 39.115707     | 83.393610           | 0.818086             | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [0.8577844500541687, 1.4901161193847656e-08, 4.405688762664795, 3.0838325023651123, 2.444610834121704, 2.711077928543091, 0.4431138336658478, 0.8862276077270508, 1.7559881210327148, 0.3353293836116791, 2.5538923740386963, 2.9925150871276855, 1.5419162511825562, 2.154191732406616, 1.664670705795288, 3.1212575435638428, 2.3083834648132324, 1.7529940605163574, 1.5763473510742188, 3.0029940605163574, 1.1526947021484375, 1.9835330247879028, 2.859281539916992, 3.1781439781188965, 2.2964072227478027, 2.2080838680267334, 2.1916167736053467, 5.86227560043335, 3.330838441848755, 1.5553892850875854, 2.130239486694336, 3.211077928543091] | [8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0] | 2.236012                    | 7.843750         | 0.375000          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 01:55:21,142][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 01:55:21,142][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 01:55:21,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 01:55:21,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 01:55:21,185][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 01:55:21,198][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 01:55:21,198][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 01:55:21,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 01:55:24,725][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 01:55:24,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 01:55:24,845][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 01:55:24,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 01:55:24,873][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 01:55:24,874][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 01:55:24,888][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 01:55:24,900][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 01:55:28,578][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 01:55:28,578][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 01:55:28,578][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 01:55:28,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 01:55:28,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 01:55:28,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 01:55:28,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 01:55:28,846][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 01:55:32,040][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 01:55:32,255][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 01:55:32,255][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 01:55:32,255][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 01:55:32,267][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 01:55:32,267][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 01:55:32,394][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 01:55:32,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 01:55:32,417][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 2000.000000 | iteration_2000.pth.tar | 32.000000     | 1217.000000   | 38.031250               | 15.051413     | 80.856196           | 2.126046             | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [5.690120220184326, 6.507485389709473, 6.035928249359131, 6.694611072540283, 5.627245903015137, 6.085329532623291, 6.699102401733398, 7.84880256652832, 6.486527442932129, 7.67215633392334, 6.546407699584961, 7.329341888427734, 7.014970302581787, 6.251497268676758, 5.537425518035889, 6.119760513305664, 5.540419578552246, 5.696107864379883, 3.845808506011963, 6.426647186279297, 6.001497268676758, 4.875748634338379, 6.217066287994385, 5.196107864379883, 4.3682637214660645, 6.7035932540893555, 5.241018295288086, 5.776946544647217, 4.167665004730225, 6.115269660949707, 4.913173675537109, 6.501497268676758] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0] | 5.991673                    | 8.000000         | 1.093750          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:10:58,387][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:10:58,402][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:10:58,402][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:10:58,417][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:10:58,432][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:10:58,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:10:58,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:10:58,874][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:11:02,112][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:11:02,127][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:11:02,140][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:11:02,140][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:11:02,157][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:11:02,172][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:11:02,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:11:02,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:11:05,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:11:05,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:11:05,704][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:11:05,720][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:11:05,720][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:11:05,720][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:11:05,733][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:11:06,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:11:09,189][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:11:09,314][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:11:09,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:11:09,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:11:09,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:11:09,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:11:09,708][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:11:10,399][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:11:10,401][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 3000.000000 | iteration_3000.pth.tar | 32.000000     | 1297.000000   | 40.531250               | 16.048256     | 80.818751           | 1.993986             | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [7.041916370391846, 8.393712997436523, 8.667665481567383, 8.19760513305664, 8.745509147644043, 10.293414115905762, 9.10778522491455, 7.779940605163574, 7.374251842498779, 9.303893089294434, 9.821856498718262, 9.091318130493164, 6.865269660949707, 6.887724876403809, 10.05838394165039, 9.251497268676758, 6.977545261383057, 8.781437873840332, 9.044910430908203, 9.21257495880127, 10.592814445495605, 7.7979044914245605, 9.302395820617676, 8.423653602600098, 5.56137752532959, 8.420659065246582, 9.444611549377441, 9.687126159667969, 8.070359230041504, 7.504491329193115, 8.83682632446289, 9.568862915039062] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0] | 8.565915                    | 8.000000         | 1.531250          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:17:00,707][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:17:00,748][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:17:00,748][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:17:00,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:17:00,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:17:00,774][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:17:00,851][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:17:00,851][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:17:01,367][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:17:01,379][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:17:01,392][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:17:01,404][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:17:01,404][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:17:01,431][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:17:01,474][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:17:01,548][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:17:01,896][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:17:01,922][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:17:01,959][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:17:01,971][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:17:01,971][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:17:02,048][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:17:02,048][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:17:02,104][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:17:02,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:17:02,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:17:02,499][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:17:02,523][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:17:02,548][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:17:02,571][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:17:02,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:17:02,726][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:17:02,727][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 4000.000000 | iteration_4000.pth.tar | 32.000000     | 1353.000000   | 42.281250               | 2.621149      | 516.185807          | 12.208386            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [9.303893089294434, 8.074850082397461, 8.88622760772705, 7.84880256652832, 8.44760513305664, 10.491018295288086, 8.070359230041504, 8.179640769958496, 8.559880256652832, 8.109281539916992, 10.534431457519531, 8.465569496154785, 7.884730815887451, 8.917665481567383, 9.208084106445312, 8.93413257598877, 7.899701118469238, 7.6826348304748535, 9.865269660949707, 9.87275505065918, 7.845808506011963, 8.63622760772705, 7.544910430908203, 9.206586837768555, 8.235030174255371, 9.089820861816406, 9.964072227478027, 10.314372062683105, 8.73802375793457, 7.752994537353516, 9.0, 7.764970302581787] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0] | 8.729042                    | 8.000000         | 1.375000          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:22:02,679][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:22:02,688][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:22:02,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:22:02,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:22:02,927][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:22:02,941][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:22:02,941][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:22:02,951][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:22:03,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:22:03,439][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:22:03,440][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:22:03,440][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:22:03,465][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:22:03,475][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:22:03,476][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:22:03,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:22:04,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:22:04,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:22:04,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:22:04,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:22:04,050][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:22:04,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:22:04,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:22:04,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:22:04,586][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:22:04,586][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:22:04,597][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:22:04,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:22:04,648][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:22:04,659][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:22:04,659][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:22:04,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:22:04,737][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 5000.000000 | iteration_5000.pth.tar | 32.000000     | 1289.000000   | 40.281250               | 2.567988      | 501.949474          | 12.461120            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [8.77095890045166, 10.359281539916992, 10.33533000946045, 9.005988121032715, 8.842814445495605, 10.52395248413086, 10.477545738220215, 8.70059871673584, 8.643712997436523, 10.041916847229004, 11.446107864379883, 10.92215633392334, 9.592814445495605, 10.729042053222656, 9.619760513305664, 8.755988121032715, 10.281437873840332, 9.089820861816406, 10.143712997436523, 9.461078643798828, 8.51197624206543, 9.354790687561035, 9.371257781982422, 9.365269660949707, 8.793413162231445, 8.124252319335938, 9.952095985412598, 10.031437873840332, 6.9535932540893555, 9.46257495880127, 10.30838394165039, 8.420659065246582] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 2.0, 2.0, 1.0] | 9.512304                    | 8.000000         | 1.281250          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:27:11,410][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:27:11,410][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:27:11,434][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:27:11,434][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:27:11,434][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:27:11,434][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:27:11,434][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:27:11,467][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:27:12,131][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:27:12,141][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:27:12,141][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:27:12,169][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:27:12,191][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:27:12,191][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:27:12,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:27:12,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:27:12,625][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:27:12,650][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:27:12,650][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:27:12,650][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:27:12,700][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:27:12,700][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:27:12,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:27:12,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:27:13,366][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:27:13,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:27:13,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:27:13,453][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:27:13,477][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:27:13,488][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:27:13,488][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:27:13,528][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:27:13,529][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 6000.000000 | iteration_6000.pth.tar | 32.000000     | 1249.000000   | 39.031250               | 2.699497      | 462.678818          | 11.854061            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [9.980539321899414, 9.772455215454102, 9.220060348510742, 9.550898551940918, 8.229042053222656, 10.166168212890625, 9.477545738220215, 9.631736755371094, 9.255988121032715, 9.568862915039062, 9.627245903015137, 10.368264198303223, 6.934132099151611, 9.856287956237793, 10.467066764831543, 9.4745512008667, 9.52095890045166, 9.106287956237793, 10.353293418884277, 9.630240440368652, 9.755988121032715, 10.431138038635254, 10.327844619750977, 10.501497268676758, 8.839820861816406, 9.577844619750977, 8.679640769958496, 9.574851036071777, 10.417665481567383, 9.869760513305664, 10.540419578552246, 10.366766929626465] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0] | 9.658589                    | 8.000000         | 0.718750          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:32:16,274][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:32:16,274][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:32:16,328][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:32:16,339][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:32:16,339][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:32:16,349][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:32:16,349][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:32:16,360][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:32:16,853][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:32:16,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:32:16,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:32:16,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:32:16,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:32:16,963][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:32:16,964][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:32:17,198][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:32:17,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:32:17,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:32:17,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:32:17,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:32:17,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:32:17,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:32:17,917][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:32:17,976][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:32:18,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:32:18,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:32:18,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:32:18,440][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:32:18,468][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:32:18,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:32:18,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:32:18,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:32:18,604][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 7000.000000 | iteration_7000.pth.tar | 32.000000     | 1329.000000   | 41.531250               | 2.874594      | 462.326080          | 11.132005            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [10.32335376739502, 10.047904968261719, 10.347305297851562, 9.628743171691895, 10.544910430908203, 11.317365646362305, 11.08533000946045, 10.396706581115723, 8.053892135620117, 10.263473510742188, 9.812874794006348, 10.839820861816406, 9.791916847229004, 10.191617012023926, 9.80838394165039, 10.576347351074219, 9.601797103881836, 10.491018295288086, 11.736527442932129, 11.294910430908203, 10.514970779418945, 10.00898265838623, 10.46257495880127, 10.565868377685547, 9.902694702148438, 10.013473510742188, 9.34880256652832, 11.300898551940918, 12.31137752532959, 11.437126159667969, 10.047904968261719, 10.790419578552246] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 3.0, 0.0, 0.0, 3.0, 4.0, 3.0, 1.0, 2.0] | 10.401853                   | 8.000000         | 1.375000          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:37:23,131][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:37:23,141][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:37:23,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:37:23,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:37:23,159][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:37:23,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:37:23,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:37:23,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:37:23,846][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:37:23,846][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:37:23,857][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:37:23,913][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:37:23,913][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:37:23,925][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:37:23,980][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:37:23,993][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:37:24,461][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:37:24,462][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:37:24,475][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:37:24,558][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:37:24,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:37:24,580][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:37:24,590][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:37:24,688][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:37:25,111][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:37:25,121][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:37:25,121][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:37:25,197][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:37:25,225][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:37:25,225][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:37:25,317][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:37:25,343][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:37:25,344][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 8000.000000 | iteration_8000.pth.tar | 32.000000     | 1337.000000   | 41.781250               | 2.723921      | 490.836485          | 11.747769            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [10.131736755371094, 10.032934188842773, 11.276947021484375, 9.13622760772705, 9.483532905578613, 11.437126159667969, 11.889222145080566, 10.453593254089355, 9.414670944213867, 12.239521026611328, 8.452095985412598, 10.83533000946045, 9.69760513305664, 10.211077690124512, 10.479042053222656, 11.363773345947266, 10.131736755371094, 11.121257781982422, 10.25898265838623, 11.428144454956055, 9.901198387145996, 10.812874794006348, 10.525449752807617, 10.226048469543457, 8.27095890045166, 10.392215728759766, 10.881736755371094, 10.443114280700684, 9.255988121032715, 12.767964363098145, 11.937126159667969, 10.646706581115723] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [3.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 0.0, 4.0, 4.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 5.0, 4.0, 3.0] | 10.485498                   | 8.000000         | 2.187500          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:42:28,866][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:42:28,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:42:28,917][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:42:28,917][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:42:28,940][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:42:28,952][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:42:28,962][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:42:28,973][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:42:29,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:42:29,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:42:29,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:42:29,457][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:42:29,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:42:29,491][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:42:29,503][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:42:29,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:42:30,110][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:42:30,132][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:42:30,199][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:42:30,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:42:30,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:42:30,221][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:42:30,246][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:42:30,246][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:42:30,675][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:42:30,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:42:30,771][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:42:30,782][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:42:30,782][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:42:30,782][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:42:30,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:42:30,837][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:42:30,838][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 9000.000000 | iteration_9000.pth.tar | 32.000000     | 1305.000000   | 40.781250               | 2.566887      | 508.397923          | 12.466462            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.284431457519531, 9.31137752532959, 11.145210266113281, 12.324851036071777, 11.694611549377441, 9.726048469543457, 11.266468048095703, 10.582335472106934, 11.017964363098145, 10.092814445495605, 11.449102401733398, 9.824851036071777, 8.778443336486816, 9.001497268676758, 10.068862915039062, 10.07335376739502, 9.476048469543457, 10.339820861816406, 10.158682823181152, 11.005988121032715, 10.514970779418945, 10.7245512008667, 11.544910430908203, 9.574851036071777, 9.661677360534668, 9.666168212890625, 11.306886672973633, 10.928144454956055, 11.13622760772705, 8.399701118469238, 10.167665481567383, 10.778443336486816] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [3.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0] | 10.407093                   | 8.000000         | 2.125000          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:47:36,874][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:47:36,874][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:47:36,874][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:47:36,885][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:47:36,885][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:47:36,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:47:36,979][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:47:36,992][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:47:37,528][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:47:37,539][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:47:37,567][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:47:37,567][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:47:37,567][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:47:37,689][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:47:37,709][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:47:37,877][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:47:38,105][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:47:38,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:47:38,158][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:47:38,242][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:47:38,242][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:47:38,303][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:47:38,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:47:38,769][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:47:38,999][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:47:39,010][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:47:39,054][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:47:39,113][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:47:39,113][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:47:39,167][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:47:39,273][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:47:39,386][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:47:39,387][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 10000.000000 | iteration_10000.pth.tar | 32.000000     | 1353.000000   | 42.281250               | 3.211451      | 421.304864          | 9.964343             | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [8.776947021484375, 9.9745512008667, 9.185628890991211, 10.238024711608887, 9.001497268676758, 9.729042053222656, 10.142215728759766, 7.437126159667969, 9.32335376739502, 11.52095890045166, 10.703593254089355, 7.995509147644043, 10.441617012023926, 8.645210266113281, 10.235030174255371, 10.341318130493164, 11.041916847229004, 8.371257781982422, 8.982036590576172, 9.07335376739502, 9.865269660949707, 8.290419578552246, 11.152694702148438, 9.941617012023926, 9.892215728759766, 8.420659065246582, 8.532934188842773, 8.95958137512207, 10.576347351074219, 7.100299835205078, 10.491018295288086, 9.571856498718262] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0] | 9.498597                    | 8.000000         | 1.375000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:52:45,758][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:52:45,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:52:45,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:52:45,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:52:45,785][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:52:45,785][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:52:45,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:52:45,828][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:52:46,642][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:52:46,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:52:46,680][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:52:46,707][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:52:46,722][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:52:46,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:52:46,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:52:46,748][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:52:47,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:52:47,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:52:47,266][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:52:47,294][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:52:47,323][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:52:47,323][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:52:47,427][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:52:47,441][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:52:47,819][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:52:47,881][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:52:47,881][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:52:47,892][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:52:47,892][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:52:47,904][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:52:47,970][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:52:47,970][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:52:47,971][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 11000.000000 | iteration_11000.pth.tar | 32.000000     | 1298.000000   | 40.562500               | 2.754522      | 471.225097          | 11.617260            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.604790687561035, 11.278443336486816, 12.104790687561035, 10.455090522766113, 10.420659065246582, 9.7215576171875, 9.550898551940918, 9.991018295288086, 10.20059871673584, 10.68413257598877, 10.359281539916992, 11.074851036071777, 12.149701118469238, 10.62275505065918, 10.116766929626465, 12.383234024047852, 9.4970064163208, 10.155689239501953, 9.833832740783691, 11.230539321899414, 10.66018009185791, 11.68413257598877, 10.293413162231445, 11.19760513305664, 11.374252319335938, 10.435628890991211, 10.338323593139648, 12.095808982849121, 10.290419578552246, 11.029940605163574, 13.017964363098145, 11.50898265838623] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 0.0] | 10.855072                   | 8.000000         | 1.812500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 02:57:55,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 02:57:55,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 02:57:55,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 02:57:55,319][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 02:57:55,344][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 02:57:55,344][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 02:57:55,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 02:57:55,379][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 02:57:56,049][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 02:57:56,049][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 02:57:56,061][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 02:57:56,093][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 02:57:56,104][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 02:57:56,105][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 02:57:56,141][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 02:57:56,217][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 02:57:56,530][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 02:57:56,552][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 02:57:56,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 02:57:56,612][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 02:57:56,678][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 02:57:56,678][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 02:57:56,712][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 02:57:56,814][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 02:57:57,062][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 02:57:57,075][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 02:57:57,102][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 02:57:57,168][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 02:57:57,221][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 02:57:57,232][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 02:57:57,295][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 02:57:57,352][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 02:57:57,354][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 12000.000000 | iteration_12000.pth.tar | 32.000000     | 1329.000000   | 41.531250               | 2.588117      | 513.500753          | 12.364202            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.306886672973633, 10.766467094421387, 9.191617012023926, 11.175149917602539, 10.167665481567383, 10.564372062683105, 9.437126159667969, 9.516467094421387, 11.242515563964844, 9.149701118469238, 11.076347351074219, 11.097306251525879, 9.220060348510742, 7.974551200866699, 9.764970779418945, 10.645210266113281, 11.362276077270508, 9.676647186279297, 11.245509147644043, 10.191617012023926, 12.083832740783691, 12.714072227478027, 9.184131622314453, 10.815868377685547, 9.296407699584961, 9.690119743347168, 8.517964363098145, 10.324851036071777, 9.649701118469238, 9.917665481567383, 11.775449752807617, 11.300898551940918] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0] | 10.313857                   | 8.000000         | 1.937500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:03:03,401][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:03:03,410][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:03:03,419][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:03:03,466][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:03:03,466][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:03:03,466][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:03:03,477][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:03:03,536][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:03:03,912][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:03:03,923][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:03:03,959][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:03:03,969][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:03:03,992][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:03:04,002][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:03:04,054][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:03:04,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:03:04,397][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:03:04,424][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:03:04,660][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:03:04,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:03:04,710][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:03:04,722][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:03:04,780][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:03:04,850][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:03:05,114][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:03:05,124][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:03:05,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:03:05,143][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:03:05,165][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:03:05,175][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:03:05,196][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:03:05,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:03:05,302][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 13000.000000 | iteration_13000.pth.tar | 32.000000     | 1345.000000   | 42.031250               | 2.339766      | 574.843781          | 13.676581            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [10.735030174255371, 10.946107864379883, 11.678144454956055, 11.112276077270508, 12.89820384979248, 10.10778522491455, 10.329341888427734, 10.571856498718262, 11.36976146697998, 10.467065811157227, 11.365269660949707, 9.218563079833984, 10.754491806030273, 9.859281539916992, 12.263473510742188, 10.597305297851562, 11.137724876403809, 9.621257781982422, 9.952095985412598, 10.420659065246582, 11.139222145080566, 13.149701118469238, 11.30838394165039, 10.633234024047852, 10.9715576171875, 10.836827278137207, 8.794910430908203, 11.281437873840332, 10.29940128326416, 11.832335472106934, 10.513473510742188, 11.88622760772705] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [4.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0] | 10.876638                   | 8.000000         | 2.218750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:07:54,072][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:07:54,104][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:07:54,104][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:07:54,104][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:07:54,117][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:07:54,117][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:07:54,151][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:07:54,151][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:07:54,577][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:07:54,577][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:07:54,610][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:07:54,620][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:07:54,620][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:07:54,630][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:07:54,703][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:07:54,714][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:07:55,052][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:07:55,052][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:07:55,083][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:07:55,093][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:07:55,093][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:07:55,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:07:55,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:07:55,220][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:07:55,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:07:55,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:07:55,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:07:55,582][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:07:55,631][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:07:55,687][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:07:55,715][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:07:55,741][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:07:55,743][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 14000.000000 | iteration_14000.pth.tar | 32.000000     | 1313.000000   | 41.031250               | 2.293459      | 572.497642          | 13.952722            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [10.580839157104492, 10.814371109008789, 11.053893089294434, 10.562874794006348, 11.137724876403809, 8.82335376739502, 11.353293418884277, 9.830839157104492, 10.633234024047852, 9.552395820617676, 10.55838394165039, 9.995509147644043, 10.324851036071777, 10.970060348510742, 10.953593254089355, 11.353293418884277, 11.706587791442871, 9.736527442932129, 10.395210266113281, 12.502994537353516, 10.754491806030273, 9.395210266113281, 12.486527442932129, 9.752994537353516, 10.480539321899414, 9.964072227478027, 10.907186508178711, 11.031437873840332, 9.988024711608887, 10.571856498718262, 8.158682823181152, 11.7245512008667] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0] | 10.564231                   | 8.000000         | 1.406250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:12:44,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:12:44,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:12:44,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:12:44,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:12:44,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:12:44,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:12:44,109][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:12:44,149][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:12:44,553][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:12:44,553][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:12:44,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:12:44,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:12:44,573][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:12:44,582][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:12:44,605][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:12:44,640][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:12:45,020][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:12:45,029][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:12:45,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:12:45,047][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:12:45,067][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:12:45,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:12:45,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:12:45,119][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:12:45,521][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:12:45,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:12:45,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:12:45,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:12:45,553][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:12:45,633][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:12:45,754][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:12:45,767][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:12:45,768][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 15000.000000 | iteration_15000.pth.tar | 32.000000     | 1233.000000   | 38.531250               | 2.222258      | 554.841053          | 14.399768            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [12.179641723632812, 10.742515563964844, 10.994012832641602, 12.359281539916992, 12.083832740783691, 10.67215633392334, 9.02395248413086, 11.627245903015137, 11.832335472106934, 11.026946067810059, 9.9745512008667, 10.479042053222656, 10.730539321899414, 9.654191970825195, 9.920659065246582, 9.964072227478027, 12.017964363098145, 11.461078643798828, 11.485030174255371, 10.714072227478027, 12.215569496154785, 9.750000953674316, 11.365269660949707, 10.814372062683105, 10.562874794006348, 12.706587791442871, 10.58533000946045, 10.935628890991211, 11.964072227478027, 11.257485389709473, 12.083832740783691, 10.874252319335938] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0] | 11.064325                   | 8.000000         | 1.062500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:17:35,274][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:17:35,284][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:17:35,284][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:17:35,293][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:17:35,304][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:17:35,315][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:17:35,315][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:17:35,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:17:35,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:17:35,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:17:35,801][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:17:35,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:17:35,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:17:35,820][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:17:35,820][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:17:35,856][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:17:36,252][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:17:36,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:17:36,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:17:36,299][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:17:36,312][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:17:36,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:17:36,350][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:17:36,376][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:17:36,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:17:36,799][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:17:36,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:17:36,845][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:17:36,856][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:17:36,884][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:17:36,884][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:17:37,147][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:17:37,149][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 16000.000000 | iteration_16000.pth.tar | 32.000000     | 1289.000000   | 40.281250               | 2.490211      | 517.626731          | 12.850315            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [10.383234024047852, 11.175149917602539, 11.664670944213867, 10.889222145080566, 11.100299835205078, 10.88473129272461, 11.173653602600098, 11.327844619750977, 11.532934188842773, 9.670659065246582, 11.2215576171875, 10.696107864379883, 9.601797103881836, 12.215569496154785, 10.251497268676758, 11.522455215454102, 11.41317367553711, 9.856287956237793, 10.863773345947266, 11.525449752807617, 10.064372062683105, 10.480539321899414, 9.748503684997559, 10.708084106445312, 10.833832740783691, 10.550898551940918, 10.62275505065918, 9.784431457519531, 10.065868377685547, 7.634730815887451, 9.06137752532959, 11.327844619750977] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0] | 10.620416                   | 8.000000         | 1.406250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:22:28,326][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:22:28,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:22:28,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:22:28,376][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:22:28,376][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:22:28,389][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:22:28,389][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:22:28,400][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:22:28,860][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:22:28,860][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:22:28,883][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:22:28,883][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:22:28,907][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:22:28,907][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:22:28,919][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:22:28,931][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:22:29,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:22:29,532][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:22:29,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:22:29,576][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:22:29,588][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:22:29,588][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:22:29,602][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:22:29,665][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:22:30,016][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:22:30,039][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:22:30,039][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:22:30,049][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:22:30,083][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:22:30,095][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:22:30,117][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:22:30,215][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:22:30,217][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 17000.000000 | iteration_17000.pth.tar | 32.000000     | 1289.000000   | 40.281250               | 2.376928      | 542.296616          | 13.462755            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [10.624252319335938, 10.570359230041504, 11.461078643798828, 10.706586837768555, 11.845808982849121, 10.766468048095703, 11.151198387145996, 10.931138038635254, 11.091318130493164, 9.604790687561035, 12.706587791442871, 11.229042053222656, 10.407185554504395, 11.57036018371582, 11.185628890991211, 11.916168212890625, 11.288922309875488, 11.887724876403809, 10.931138038635254, 12.43413257598877, 12.227545738220215, 11.161677360534668, 10.395210266113281, 10.93413257598877, 11.20958137512207, 11.161677360534668, 10.236527442932129, 12.047904968261719, 11.305389404296875, 11.751497268676758, 12.227545738220215, 11.13473129272461] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [3.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 4.0, 1.0, 1.0] | 11.253228                   | 8.000000         | 1.375000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:27:23,006][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:27:23,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:27:23,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:27:23,055][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:27:23,055][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:27:23,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:27:23,081][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:27:23,195][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:27:23,642][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:27:23,678][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:27:23,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:27:23,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:27:23,701][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:27:23,712][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:27:23,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:27:23,760][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:27:24,147][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:27:24,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:27:24,210][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:27:24,210][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:27:24,223][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:27:24,251][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:27:24,293][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:27:24,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:27:24,764][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:27:24,764][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:27:24,774][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:27:24,774][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:27:24,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:27:24,837][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:27:24,853][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:27:24,853][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:27:24,855][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 18000.000000 | iteration_18000.pth.tar | 32.000000     | 1258.000000   | 39.312500               | 2.333519      | 539.100007          | 13.713196            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [9.485030174255371, 12.275449752807617, 10.540419578552246, 11.435628890991211, 11.356287956237793, 9.565868377685547, 11.437126159667969, 9.904191970825195, 10.371257781982422, 10.958084106445312, 11.413174629211426, 10.522455215454102, 12.706587791442871, 11.047904968261719, 9.821856498718262, 11.196107864379883, 10.095808982849121, 12.407186508178711, 12.552395820617676, 11.0, 11.571856498718262, 11.294910430908203, 10.89820384979248, 13.32335376739502, 11.989521026611328, 11.748503684997559, 10.178144454956055, 12.095808982849121, 12.275449752807617, 11.329341888427734, 12.730539321899414, 10.01197624206543] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 4.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0] | 11.235639                   | 8.000000         | 1.750000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:32:16,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:32:16,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:32:16,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:32:16,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:32:16,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:32:16,241][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:32:16,241][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:32:16,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:32:16,733][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:32:16,756][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:32:16,767][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:32:16,767][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:32:16,790][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:32:16,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:32:16,827][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:32:16,839][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:32:17,285][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:32:17,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:32:17,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:32:17,350][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:32:17,350][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:32:17,372][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:32:17,372][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:32:17,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:32:17,915][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:32:17,980][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:32:18,003][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:32:18,017][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:32:18,018][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:32:18,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:32:18,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:32:18,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:32:18,086][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 19000.000000 | iteration_19000.pth.tar | 32.000000     | 1313.000000   | 41.031250               | 2.379387      | 551.822810          | 13.448842            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [10.215569496154785, 11.408682823181152, 10.71257495880127, 11.252994537353516, 10.62275505065918, 11.094311714172363, 9.467065811157227, 11.146706581115723, 13.592815399169922, 12.62275505065918, 10.708084106445312, 11.425149917602539, 11.7245512008667, 13.125748634338379, 12.145210266113281, 11.315868377685547, 12.173652648925781, 11.544910430908203, 12.33533000946045, 11.401198387145996, 11.173653602600098, 11.158682823181152, 10.12275505065918, 10.30838394165039, 11.745509147644043, 11.643712997436523, 12.251497268676758, 12.342814445495605, 12.682635307312012, 11.616766929626465, 12.562874794006348, 10.83533000946045] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0] | 11.515017                   | 8.000000         | 2.218750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:37:13,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:37:13,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:37:13,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:37:13,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:37:13,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:37:13,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:37:13,766][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:37:13,777][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:37:14,258][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:37:14,271][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:37:14,283][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:37:14,294][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:37:14,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:37:14,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:37:14,345][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:37:14,372][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:37:14,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:37:14,841][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:37:14,841][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:37:14,851][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:37:14,851][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:37:14,862][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:37:14,884][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:37:14,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:37:15,526][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:37:15,536][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:37:15,550][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:37:15,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:37:15,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:37:15,580][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:37:15,591][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:37:15,605][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:37:15,607][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 20000.000000 | iteration_20000.pth.tar | 32.000000     | 1265.000000   | 39.531250               | 2.401795      | 526.689377          | 13.323368            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.255989074707031, 11.868264198303223, 11.470060348510742, 10.766467094421387, 9.640718460083008, 11.700599670410156, 11.760479927062988, 11.485030174255371, 10.62275505065918, 11.101797103881836, 10.946107864379883, 11.940120697021484, 12.958084106445312, 10.946107864379883, 11.36377239227295, 13.694611549377441, 13.305389404296875, 10.359281539916992, 11.556886672973633, 11.80838394165039, 10.92215633392334, 11.19760513305664, 10.332335472106934, 10.754491806030273, 12.143712997436523, 11.544910430908203, 12.056886672973633, 10.658682823181152, 13.065868377685547, 10.982036590576172, 11.19760513305664, 11.4970064163208] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 3.0] | 11.465756                   | 8.000000         | 1.343750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:42:09,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:42:09,789][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:42:09,789][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:42:09,798][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:42:09,808][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:42:09,808][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:42:09,831][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:42:09,877][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:42:10,452][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:42:10,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:42:10,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:42:10,526][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:42:10,537][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:42:10,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:42:10,571][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:42:10,597][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:42:11,018][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:42:11,030][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:42:11,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:42:11,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:42:11,121][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:42:11,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:42:11,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:42:11,302][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:42:11,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:42:11,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:42:11,629][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:42:11,629][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:42:11,669][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:42:11,681][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:42:11,716][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:42:11,904][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:42:11,906][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 21000.000000 | iteration_21000.pth.tar | 32.000000     | 1385.000000   | 43.281250               | 2.564556      | 540.054413          | 12.477791            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.796407699584961, 13.205090522766113, 11.413174629211426, 11.317365646362305, 9.486527442932129, 10.2245512008667, 9.624252319335938, 9.19760513305664, 10.893712997436523, 10.419161796569824, 11.844311714172363, 12.764970779418945, 9.856287956237793, 11.772455215454102, 10.419161796569824, 10.467065811157227, 11.173652648925781, 10.095808982849121, 10.02395248413086, 11.185628890991211, 11.781437873840332, 10.838323593139648, 11.796407699584961, 11.11077880859375, 12.10778522491455, 13.005988121032715, 10.682635307312012, 11.353294372558594, 11.137724876403809, 13.661677360534668, 12.796407699584961, 11.9745512008667] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 2.0, 4.0, 0.0, 2.0, 2.0, 1.0, 3.0, 0.0, 0.0, 2.0, 5.0, 4.0, 2.0] | 11.232130                   | 8.000000         | 1.843750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:47:14,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:47:14,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:47:14,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:47:14,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:47:14,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:47:14,087][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:47:14,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:47:14,120][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:47:14,593][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:47:14,593][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:47:14,604][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:47:14,604][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:47:14,614][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:47:14,639][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:47:14,664][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:47:14,703][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:47:15,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:47:15,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:47:15,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:47:15,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:47:15,117][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:47:15,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:47:15,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:47:15,169][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:47:15,580][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:47:15,605][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:47:15,616][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:47:15,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:47:15,677][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:47:15,689][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:47:15,728][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:47:15,756][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:47:15,758][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 22000.000000 | iteration_22000.pth.tar | 32.000000     | 1321.000000   | 41.281250               | 2.223678      | 594.060706          | 14.390570            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.470060348510742, 11.782934188842773, 10.217066764831543, 11.187126159667969, 11.75898265838623, 11.784431457519531, 12.239521026611328, 11.359281539916992, 11.88622760772705, 10.383234024047852, 11.2215576171875, 12.155689239501953, 12.516468048095703, 13.255988121032715, 11.976048469543457, 11.38473129272461, 12.670659065246582, 12.766467094421387, 10.119760513305664, 12.742515563964844, 10.851797103881836, 10.455090522766113, 10.33533000946045, 11.700599670410156, 10.371257781982422, 11.377245903015137, 11.702095985412598, 12.02395248413086, 11.305389404296875, 9.029940605163574, 10.425149917602539, 10.836827278137207] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 4.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 3.0, 0.0, 2.0] | 11.415420                   | 8.000000         | 1.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:52:10,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:52:10,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:52:10,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:52:10,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:52:10,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:52:10,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:52:10,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:52:11,002][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:52:11,369][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:52:11,409][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:52:11,421][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:52:11,446][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:52:11,447][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:52:11,457][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:52:11,523][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:52:11,550][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:52:12,017][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:52:12,017][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:52:12,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:52:12,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:52:12,061][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:52:12,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:52:12,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:52:12,197][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:52:12,608][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:52:12,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:52:12,634][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:52:12,646][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:52:12,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:52:12,748][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:52:12,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:52:12,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:52:12,848][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 23000.000000 | iteration_23000.pth.tar | 32.000000     | 1385.000000   | 43.281250               | 2.862704      | 483.808298          | 11.178242            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [12.658682823181152, 12.766468048095703, 9.865269660949707, 10.791916847229004, 12.790419578552246, 10.908682823181152, 13.083832740783691, 14.167665481567383, 9.856287956237793, 10.61077880859375, 11.760479927062988, 12.766467094421387, 12.757485389709473, 11.796407699584961, 12.01197624206543, 11.760479927062988, 11.473053932189941, 13.257485389709473, 13.185629844665527, 12.754491806030273, 12.10778522491455, 11.772455215454102, 12.526947021484375, 11.71257495880127, 11.17215633392334, 11.450599670410156, 12.862276077270508, 11.842814445495605, 11.652694702148438, 11.185628890991211, 11.836827278137207, 12.263473510742188] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 5.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 4.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0] | 11.981569                   | 8.000000         | 2.218750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 03:57:10,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 03:57:10,363][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 03:57:10,363][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 03:57:10,363][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 03:57:10,429][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 03:57:10,429][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 03:57:10,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 03:57:10,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 03:57:11,028][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 03:57:11,050][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 03:57:11,063][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 03:57:11,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 03:57:11,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 03:57:11,099][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 03:57:11,181][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 03:57:11,227][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 03:57:11,566][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 03:57:11,654][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 03:57:11,654][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 03:57:11,681][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 03:57:11,725][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 03:57:11,739][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 03:57:11,755][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 03:57:11,947][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 03:57:12,185][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 03:57:12,237][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 03:57:12,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 03:57:12,315][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 03:57:12,355][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 03:57:12,385][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 03:57:12,397][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 03:57:12,625][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 03:57:12,627][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 24000.000000 | iteration_24000.pth.tar | 32.000000     | 1466.000000   | 45.812500               | 2.789710      | 525.502704          | 11.470728            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.579341888427734, 11.044910430908203, 13.887724876403809, 10.507485389709473, 11.137724876403809, 10.833832740783691, 10.077844619750977, 10.0, 11.80838394165039, 13.640719413757324, 10.227545738220215, 9.796407699584961, 11.290419578552246, 11.113773345947266, 14.718563079833984, 9.71257495880127, 12.476048469543457, 10.838323593139648, 10.669161796569824, 11.185628890991211, 10.326347351074219, 12.01197624206543, 12.88473129272461, 10.525449752807617, 12.93413257598877, 10.946107864379883, 10.84880256652832, 11.315868377685547, 11.51197624206543, 11.188623428344727, 10.736527442932129, 8.991018295288086] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [4.0, 2.0, 5.0, 3.0, 3.0, 0.0, 3.0, 1.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 1.0, 0.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0] | 11.273999                   | 8.000000         | 2.093750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:02:12,103][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:02:12,103][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:02:12,151][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:02:12,173][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:02:12,173][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 04:02:12,173][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:02:12,187][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:02:12,302][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:02:12,863][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:02:12,890][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:02:13,002][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:02:13,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:02:13,045][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:02:13,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:02:13,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:02:13,283][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:02:13,410][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:02:13,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:02:13,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:02:13,584][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:02:13,597][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:02:13,709][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:02:13,733][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:02:13,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:02:13,987][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:02:14,132][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:02:14,161][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:02:14,221][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:02:14,266][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:02:14,324][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:02:14,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:02:14,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:02:14,544][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 25000.000000 | iteration_25000.pth.tar | 32.000000     | 1586.000000   | 49.562500               | 3.012289      | 526.509938          | 10.623151            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.964072227478027, 12.393712997436523, 11.48353385925293, 12.670659065246582, 13.005988121032715, 13.905689239501953, 10.952095985412598, 13.359281539916992, 14.426647186279297, 13.08533000946045, 11.574851036071777, 11.580839157104492, 14.395210266113281, 11.880239486694336, 13.20958137512207, 10.100299835205078, 12.80838394165039, 13.353294372558594, 13.257485389709473, 12.056886672973633, 13.868264198303223, 12.61077880859375, 11.940119743347168, 13.964072227478027, 13.4970064163208, 12.630240440368652, 11.577844619750977, 11.377245903015137, 13.461078643798828, 13.62275505065918, 12.31137752532959, 12.359281539916992] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [3.0, 2.0, 3.0, 1.0, 1.0, 5.0, 3.0, 4.0, 5.0, 4.0, 3.0, 0.0, 5.0, 1.0, 4.0, 2.0, 4.0, 5.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 4.0, 4.0, 3.0, 2.0, 4.0, 5.0, 3.0, 3.0] | 12.646380                   | 8.000000         | 3.062500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:07:16,985][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:07:16,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:07:17,019][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:07:17,030][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:07:17,112][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 04:07:17,112][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:07:17,112][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:07:17,127][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:07:17,656][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:07:17,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:07:17,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:07:17,731][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:07:17,770][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:07:17,797][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:07:17,873][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:07:17,873][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:07:18,331][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:07:18,345][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:07:18,386][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:07:18,442][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:07:18,701][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:07:18,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:07:18,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:07:19,109][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:07:19,281][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:07:19,375][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:07:19,389][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:07:19,401][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:07:19,511][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:07:19,525][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:07:19,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:07:20,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:07:20,149][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:07:20,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:07:20,229][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:07:20,241][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:07:20,271][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:07:20,424][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:07:20,763][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:07:20,816][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:07:20,880][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:07:20,880][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:07:20,881][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 26000.000000 | iteration_26000.pth.tar | 32.000000     | 2368.000000   | 74.000000               | 4.650765      | 509.163585          | 6.880589             | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [13.859281539916992, 14.368264198303223, 13.744012832641602, 14.600299835205078, 15.806886672973633, 13.748503684997559, 12.21257495880127, 14.958085060119629, 13.989521980285645, 14.467066764831543, 13.856287956237793, 12.667665481567383, 13.485030174255371, 10.538922309875488, 11.856287956237793, 13.425149917602539, 12.919161796569824, 14.59880256652832, 14.095808982849121, 13.80838394165039, 16.044910430908203, 11.880239486694336, 13.342814445495605, 11.476048469543457, 11.226048469543457, 11.437126159667969, 12.215569496154785, 12.267964363098145, 12.25, 8.979042053222656, 12.386228561401367, 13.535928726196289] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [6.0, 6.0, 5.0, 7.0, 7.0, 3.0, 3.0, 6.0, 5.0, 6.0, 6.0, 1.0, 4.0, 1.0, 5.0, 3.0, 4.0, 5.0, 6.0, 4.0, 7.0, 5.0, 5.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 2.0, 5.0, 5.0] | 13.126497                   | 7.968750         | 4.312500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:12:32,965][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:12:32,965][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:12:32,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:12:33,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:12:33,037][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 04:12:33,098][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:12:33,108][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:12:33,196][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:12:33,555][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:12:33,626][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:12:33,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:12:33,657][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:12:33,700][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:12:33,757][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:12:33,793][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:12:34,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:12:34,147][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:12:34,174][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:12:34,245][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:12:34,282][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:12:34,330][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:12:34,367][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:12:34,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:12:34,930][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:12:34,973][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:12:34,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:12:35,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:12:35,095][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:12:35,175][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:12:35,210][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:12:35,334][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:12:35,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:12:35,613][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:12:35,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:12:35,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:12:35,796][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:12:35,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:12:36,053][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:12:36,166][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:12:36,191][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:12:36,295][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:12:36,337][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:12:36,470][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:12:36,495][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:12:36,703][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:12:36,705][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 27000.000000 | iteration_27000.pth.tar | 32.000000     | 2444.000000   | 76.375000               | 4.290064      | 569.688476          | 7.459096             | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [12.775449752807617, 10.708084106445312, 12.67215633392334, 11.281437873840332, 12.682635307312012, 13.953593254089355, 10.68413257598877, 13.676647186279297, 9.645210266113281, 11.685628890991211, 12.193114280700684, 12.646707534790039, 8.7470064163208, 11.19760513305664, 13.71257495880127, 10.953593254089355, 11.324851036071777, 8.476048469543457, 11.892215728759766, 14.142215728759766, 12.838323593139648, 14.426647186279297, 12.937126159667969, 12.678144454956055, 14.953593254089355, 13.187126159667969, 11.232036590576172, 10.218563079833984, 12.763473510742188, 12.239521026611328, 14.732036590576172, 11.92215633392334] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 8.0] | [4.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 4.0, 3.0, 4.0, 4.0, 2.0, 2.0, 1.0, 3.0, 0.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 3.0, 2.0, 5.0, 5.0, 2.0, 2.0, 4.0, 5.0, 5.0, 4.0] | 12.161864                   | 7.968750         | 3.312500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:17:45,760][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:17:45,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:17:45,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:17:45,895][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:17:45,933][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 04:17:46,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:17:46,433][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:17:46,464][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:17:46,589][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:17:46,657][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:17:46,681][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:17:47,231][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:17:47,298][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:17:47,309][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:17:47,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:17:47,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:17:47,523][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:17:47,524][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:17:47,902][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:17:47,930][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:17:48,059][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:17:48,059][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:17:48,250][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:17:48,600][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:17:48,713][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:17:48,992][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:17:49,024][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:17:49,148][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:17:49,242][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:17:49,278][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:17:49,764][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:17:49,828][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:17:49,919][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:17:49,981][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:17:50,099][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:17:50,157][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:17:50,258][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:17:50,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:17:50,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:17:50,577][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:17:50,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:17:50,710][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:50,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:50,918][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:51,307][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:51,651][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:51,661][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:51,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:52,166][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:52,481][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:52,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:52,976][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:53,054][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:53,196][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:53,238][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:53,280][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:17:53,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:17:53,384][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 28000.000000 | iteration_28000.pth.tar | 32.000000     | 4440.000000   | 138.750000              | 8.245229      | 538.493262          | 3.881033             | 0.031250    | 0.173993   | 1.000000   | 0.000000   | [12.461078643798828, 16.164670944213867, 8.161677360534668, 11.42215633392334, 15.185628890991211, 13.441617012023926, 12.693114280700684, 11.856287956237793, 11.29940128326416, 13.995509147644043, 14.2470064163208, 9.82036018371582, 14.91916275024414, 13.02095890045166, 13.2215576171875, 11.732036590576172, 16.850299835205078, 12.893712997436523, 13.363773345947266, 12.754491806030273, 12.76197624206543, 11.026947021484375, 11.748503684997559, 5.497005939483643, 20.0, 12.465569496154785, 9.470060348510742, 14.314372062683105, 7.272455215454102, 14.155689239501953, 14.958084106445312, 12.904191970825195] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 7.0, 8.0, 7.0, 8.0, 8.0, 7.0, 7.0, 0.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [4.0, 8.0, 2.0, 3.0, 6.0, 5.0, 4.0, 6.0, 4.0, 7.0, 5.0, 5.0, 6.0, 5.0, 6.0, 3.0, 8.0, 6.0, 5.0, 6.0, 6.0, 4.0, 6.0, 2.0, 9.0, 5.0, 3.0, 6.0, 3.0, 5.0, 6.0, 5.0] | 12.689980                   | 7.343750         | 5.125000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:23:06,059][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:23:06,154][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:23:06,154][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:23:06,238][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:23:06,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 04:23:06,399][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:23:06,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:23:06,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:23:07,228][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:23:07,267][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:23:07,355][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:23:07,421][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 04:23:07,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:23:07,724][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:23:08,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:23:08,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:23:08,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:23:08,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:23:08,263][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:23:08,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:23:08,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:23:08,760][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:23:08,857][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:23:09,160][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:23:09,343][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:23:09,566][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:23:09,657][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:23:09,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 04:23:09,679][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:23:09,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:23:09,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:23:10,094][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:23:10,285][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:23:10,285][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:23:10,411][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:23:10,421][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:23:10,521][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:23:10,635][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:23:11,036][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:23:11,047][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:23:11,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:23:11,103][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:11,245][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:11,472][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:11,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:11,824][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:11,824][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:11,888][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,108][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,108][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,256][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,686][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,687][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,698][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,746][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,760][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:12,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:13,369][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:13,433][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:13,433][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:23:13,502][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:23:13,504][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 29000.000000 | iteration_29000.pth.tar | 32.000000     | 4411.000000   | 137.843750              | 8.007898      | 550.831195          | 3.996055             | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [8.241018295288086, 9.941617012023926, 7.482036113739014, 15.688623428344727, 13.368264198303223, 15.937126159667969, 15.028443336486816, 7.769461154937744, 14.61077880859375, 16.191617965698242, 8.383234024047852, 14.616766929626465, 12.347306251525879, 13.817365646362305, 14.025449752807617, 16.958084106445312, 12.61077880859375, 16.706586837768555, 15.688623428344727, 15.688623428344727, 13.137724876403809, 14.55838394165039, 10.528443336486816, 15.050898551940918, 15.7245512008667, 12.232036590576172, 9.046407699584961, 14.932635307312012, 9.378743171691895, 10.767964363098145, 7.952096462249756, 14.60778522491455] | [8.0, 8.0, 8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 3.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0] | [3.0, 4.0, 1.0, 8.0, 6.0, 7.0, 6.0, 2.0, 6.0, 7.0, 3.0, 7.0, 5.0, 5.0, 7.0, 7.0, 3.0, 8.0, 8.0, 8.0, 4.0, 6.0, 3.0, 7.0, 7.0, 4.0, 2.0, 6.0, 3.0, 3.0, 2.0, 4.0] | 12.906859                   | 7.656250         | 5.062500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:28:29,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:28:29,556][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:28:29,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:28:29,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:28:29,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 04:28:29,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:28:30,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:28:30,348][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:28:30,460][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:28:30,489][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:28:30,622][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:28:30,982][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:28:30,995][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:28:31,079][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:28:31,232][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:28:31,276][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:28:31,277][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:28:31,419][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:28:31,756][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:28:31,819][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:28:31,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:28:32,010][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:28:32,115][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:28:32,144][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:28:32,604][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:28:32,858][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:28:32,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:28:32,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:28:33,077][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:28:33,172][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:28:33,328][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:28:33,499][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:28:33,592][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:28:33,725][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:28:33,781][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:28:33,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:28:33,873][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:28:34,293][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:28:34,427][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:28:34,455][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:28:34,457][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 30000.000000 | iteration_30000.pth.tar | 32.000000     | 2913.000000   | 91.031250               | 5.548774      | 524.980841          | 5.767040             | 0.062500    | 0.242061   | 1.000000   | 0.000000   | [13.880240440368652, 16.9940128326416, 10.797904968261719, 15.711078643798828, 14.396707534790039, 12.13622760772705, 11.371257781982422, 3.2934134006500244, 14.332335472106934, 12.09880256652832, 11.908682823181152, 8.612276077270508, 14.850299835205078, 7.559880256652832, 16.275449752807617, 20.0, 13.826348304748535, 13.991018295288086, 8.7245512008667, 12.000000953674316, 11.844311714172363, 16.850299835205078, 15.181138038635254, 10.502994537353516, 12.10778522491455, 12.035928726196289, 10.13473129272461, 15.844311714172363, 15.7245512008667, 13.920659065246582, 12.58682632446289, 20.0] | [4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 8.0, 8.0, 8.0, 3.0] | [7.0, 8.0, 5.0, 7.0, 5.0, 4.0, 4.0, 1.0, 6.0, 4.0, 4.0, 3.0, 6.0, 3.0, 7.0, 9.0, 6.0, 5.0, 2.0, 4.0, 5.0, 8.0, 6.0, 3.0, 3.0, 4.0, 4.0, 8.0, 7.0, 6.0, 4.0, 9.0] | 13.109188                   | 7.437500         | 5.218750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:33:59,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:33:59,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:33:59,521][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:33:59,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:33:59,555][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 04:33:59,567][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:33:59,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:34:00,132][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:34:00,182][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:34:00,210][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:34:00,292][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:34:00,662][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:34:01,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:34:01,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:34:01,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:34:01,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:34:01,507][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:34:01,754][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:34:01,823][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:34:01,823][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:34:01,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:34:02,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:34:02,263][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:34:02,461][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:34:02,541][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:34:02,614][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:34:02,755][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:34:02,804][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:34:03,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:34:03,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:34:03,406][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:34:03,660][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:34:03,698][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:34:03,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:34:03,775][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:34:03,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:34:03,954][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:34:03,956][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 31000.000000 | iteration_31000.pth.tar | 32.000000     | 2788.000000   | 87.125000               | 5.131050      | 543.358593          | 6.236541             | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [11.714072227478027, 14.381736755371094, 11.281437873840332, 11.275449752807617, 10.739521026611328, 10.158682823181152, 16.405689239501953, 10.52395248413086, 12.203593254089355, 10.215569496154785, 11.88473129272461, 15.748503684997559, 12.455090522766113, 13.455090522766113, 11.526947021484375, 14.275449752807617, 12.444611549377441, 6.986527442932129, 14.13473129272461, 14.61077880859375, 5.9880242347717285, 10.91018009185791, 9.827844619750977, 12.169161796569824, 12.278443336486816, 13.477545738220215, 11.550898551940918, 9.931138038635254, 12.703593254089355, 11.59880256652832, 13.772455215454102, 14.094311714172363] | [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 7.0, 8.0, 8.0, 8.0, 8.0, 5.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0] | [4.0, 5.0, 4.0, 5.0, 4.0, 4.0, 7.0, 3.0, 4.0, 5.0, 5.0, 6.0, 5.0, 4.0, 3.0, 5.0, 5.0, 1.0, 5.0, 7.0, 2.0, 3.0, 4.0, 4.0, 4.0, 6.0, 4.0, 3.0, 5.0, 4.0, 7.0, 5.0] | 12.022643                   | 7.687500         | 4.437500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:39:45,922][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:39:46,065][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 04:39:46,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:39:47,096][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 04:39:47,620][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 04:39:47,655][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:39:47,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:39:47,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:39:47,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:39:47,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:39:47,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:39:48,227][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:39:48,447][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:39:48,470][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 04:39:48,519][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:39:48,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 04:39:48,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:39:49,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:39:49,483][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 04:39:49,656][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:39:49,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:39:49,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:39:50,125][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:39:50,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:39:50,826][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:39:50,857][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:39:50,966][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:39:51,236][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:39:51,558][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:39:51,849][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 04:39:52,185][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:39:52,198][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:39:52,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:39:52,233][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:39:52,262][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:39:52,684][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:39:53,048][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:39:53,101][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:39:53,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:39:53,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:39:53,999][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:39:54,000][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 32000.000000 | iteration_32000.pth.tar | 32.000000     | 4808.000000   | 150.250000              | 8.738021      | 550.239038          | 3.662157             | 0.281250    | 0.449609   | 1.000000   | 0.000000   | [16.802396774291992, 16.327844619750977, 16.514970779418945, 15.676647186279297, 20.0, 11.42215633392334, 15.678144454956055, 14.826348304748535, 20.000001907348633, 16.863773345947266, 15.720060348510742, 16.694610595703125, 13.772455215454102, 20.0, 20.0, 13.880240440368652, 11.832335472106934, 15.700599670410156, 14.863773345947266, 20.0, 14.670659065246582, 20.0, 13.170659065246582, 16.061378479003906, 15.041916847229004, 20.0, 14.215569496154785, 16.682636260986328, 15.017964363098145, 11.88473129272461, 20.0, 20.0] | [3.0, 8.0, 6.0, 7.0, 2.0, 8.0, 8.0, 5.0, 1.0, 8.0, 8.0, 7.0, 8.0, 0.0, 0.0, 8.0, 8.0, 7.0, 8.0, 4.0, 5.0, 1.0, 8.0, 6.0, 4.0, 0.0, 4.0, 6.0, 5.0, 8.0, 0.0, 1.0] | [8.0, 8.0, 8.0, 7.0, 9.0, 5.0, 7.0, 7.0, 9.0, 8.0, 8.0, 8.0, 7.0, 9.0, 9.0, 5.0, 5.0, 8.0, 7.0, 9.0, 7.0, 9.0, 5.0, 8.0, 7.0, 9.0, 7.0, 8.0, 7.0, 5.0, 9.0, 9.0] | 16.353809                   | 5.062500         | 7.531250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:46:03,987][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:46:04,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:46:04,102][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 04:46:04,195][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:46:04,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 04:46:04,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:46:04,860][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:46:05,104][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:46:05,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:46:05,305][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 04:46:05,328][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 04:46:05,736][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:46:05,879][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:46:05,879][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:46:06,055][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 04:46:06,147][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 04:46:06,172][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:46:06,474][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 04:46:06,555][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:46:06,556][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:46:06,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:46:07,017][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 04:46:07,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 04:46:07,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 04:46:07,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:46:07,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:46:07,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 04:46:08,001][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:46:08,173][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:46:08,197][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:46:08,197][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:46:08,816][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 04:46:09,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:46:09,454][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:46:09,855][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:46:10,375][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:46:10,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:46:11,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:46:11,153][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:46:11,153][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:46:11,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:11,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:11,880][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:11,932][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 04:46:11,969][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:12,017][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:12,028][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 04:46:12,533][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:12,558][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:12,640][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:12,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:12,858][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:13,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:13,802][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:46:13,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 04:46:13,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:46:13,988][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 33000.000000 | iteration_33000.pth.tar | 32.000000     | 5409.000000   | 169.031250              | 10.694198     | 505.788267          | 2.992277             | 0.156250    | 0.363092   | 1.000000   | 0.000000   | [20.0, 12.522455215454102, 14.33533000946045, 16.335329055786133, 16.718563079833984, 20.000001907348633, 10.088323593139648, 10.995509147644043, 14.89820384979248, 15.19760513305664, 16.083833694458008, 15.904191970825195, 15.4970064163208, 14.92215633392334, 20.0, 14.62275505065918, 20.0, 16.41916275024414, 15.962575912475586, 12.037425994873047, 9.814372062683105, 16.666168212890625, 10.595808982849121, 20.0, 13.784431457519531, 15.136228561401367, 12.63473129272461, 12.874252319335938, 13.041916847229004, 15.005989074707031, 13.616766929626465, 14.845808982849121] | [0.0, 3.0, 8.0, 5.0, 6.0, 0.0, 8.0, 8.0, 6.0, 5.0, 5.0, 7.0, 7.0, 8.0, 0.0, 8.0, 0.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 1.0, 3.0, 8.0, 5.0, 3.0, 3.0, 8.0, 5.0, 8.0] | [9.0, 6.0, 6.0, 8.0, 8.0, 9.0, 3.0, 5.0, 7.0, 7.0, 8.0, 8.0, 7.0, 6.0, 9.0, 6.0, 9.0, 8.0, 8.0, 4.0, 3.0, 8.0, 4.0, 9.0, 7.0, 7.0, 6.0, 6.0, 6.0, 7.0, 6.0, 7.0] | 15.017403                   | 5.468750         | 6.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:52:42,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:52:42,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:52:42,567][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 04:52:42,667][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 04:52:43,321][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 04:52:43,418][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 04:52:44,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:52:44,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:52:44,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 04:52:44,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:52:44,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 04:52:44,817][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:52:44,902][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:52:44,913][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:52:44,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 04:52:45,000][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:52:45,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:52:45,755][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:52:45,855][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:52:46,387][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:52:46,545][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:52:46,912][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:52:47,332][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:52:47,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:52:47,615][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 04:52:47,639][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:52:47,650][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:52:47,919][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:52:48,420][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:52:48,736][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:52:48,849][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 04:52:48,972][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:52:49,002][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:52:49,313][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:52:49,417][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:52:49,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:52:49,446][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 34000.000000 | iteration_34000.pth.tar | 32.000000     | 3965.000000   | 123.906250              | 7.616673      | 520.568505          | 4.201309             | 0.125000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 14.778443336486816, 17.04790496826172, 8.574851036071777, 14.562874794006348, 12.383234024047852, 11.880240440368652, 20.0, 16.682636260986328, 11.965569496154785, 9.366766929626465, 11.664670944213867, 13.772455215454102, 11.652694702148438, 15.688623428344727, 16.491018295288086, 11.976048469543457, 15.688623428344727, 16.730539321899414, 8.651198387145996, 15.844311714172363, 20.0, 12.814372062683105, 13.651198387145996, 13.916168212890625, 16.109281539916992, 15.059881210327148, 12.742515563964844, 20.0, 14.874252319335938, 15.461078643798828, 13.784431457519531] | [1.0, 5.0, 8.0, 8.0, 5.0, 8.0, 4.0, 3.0, 6.0, 8.0, 8.0, 8.0, 7.0, 8.0, 8.0, 7.0, 8.0, 4.0, 5.0, 8.0, 5.0, 0.0, 4.0, 8.0, 7.0, 8.0, 8.0, 3.0, 1.0, 6.0, 8.0, 5.0] | [9.0, 7.0, 7.0, 1.0, 7.0, 4.0, 6.0, 9.0, 8.0, 5.0, 3.0, 5.0, 7.0, 3.0, 8.0, 8.0, 5.0, 8.0, 8.0, 3.0, 8.0, 9.0, 6.0, 6.0, 7.0, 7.0, 6.0, 6.0, 9.0, 7.0, 7.0, 7.0] | 14.494246                   | 5.937500         | 6.437500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 04:58:57,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 04:58:57,956][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 04:58:57,956][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 04:58:57,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 04:58:57,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 04:58:58,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 04:58:58,657][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 04:58:58,770][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 04:58:58,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 04:58:59,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 04:58:59,552][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 04:58:59,577][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 04:58:59,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 04:58:59,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 04:58:59,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 04:59:00,296][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 04:59:00,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 04:59:00,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 04:59:00,607][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 04:59:00,662][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 04:59:00,793][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 04:59:01,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 04:59:01,334][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 04:59:01,440][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 04:59:01,684][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 04:59:02,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 04:59:02,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 04:59:02,369][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 04:59:02,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:59:02,785][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:59:03,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:59:03,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 04:59:03,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:59:03,442][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:59:03,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:59:03,711][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 04:59:04,063][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:59:04,419][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:59:04,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 04:59:04,609][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:59:04,622][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:59:04,636][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 04:59:04,812][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 04:59:05,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:59:05,382][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:59:05,485][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:59:05,539][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:59:05,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 04:59:05,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 04:59:05,763][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 35000.000000 | iteration_35000.pth.tar | 32.000000     | 4608.000000   | 144.000000              | 8.606570      | 535.404910          | 3.718090             | 0.187500    | 0.390312   | 1.000000   | 0.000000   | [14.083832740783691, 15.336827278137207, 12.550898551940918, 15.868264198303223, 14.044910430908203, 16.732036590576172, 16.75, 9.456586837768555, 16.107786178588867, 14.414670944213867, 12.263473510742188, 16.02395248413086, 11.953593254089355, 14.7245512008667, 20.0, 10.718563079833984, 17.19760513305664, 14.215569496154785, 16.754491806030273, 15.844311714172363, 20.0, 11.064372062683105, 16.711078643798828, 20.0, 14.766468048095703, 13.44760513305664, 20.0, 14.797904968261719, 17.001497268676758, 15.688623428344727, 20.0, 20.0] | [7.0, 8.0, 5.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 6.0, 2.0, 8.0, 8.0, 4.0, 6.0, 8.0, 4.0, 8.0, 8.0, 1.0, 7.0, 8.0, 2.0, 8.0, 8.0, 5.0, 2.0, 0.0] | [6.0, 7.0, 6.0, 8.0, 7.0, 8.0, 8.0, 3.0, 6.0, 6.0, 2.0, 8.0, 5.0, 7.0, 9.0, 4.0, 8.0, 7.0, 8.0, 6.0, 9.0, 3.0, 8.0, 9.0, 7.0, 5.0, 9.0, 6.0, 7.0, 8.0, 9.0, 9.0] | 15.578734                   | 6.281250         | 6.812500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:05:20,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 05:05:20,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 05:05:20,780][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 05:05:20,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 05:05:20,936][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 05:05:20,950][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 05:05:21,261][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 05:05:21,517][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 05:05:21,566][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 05:05:21,639][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 05:05:21,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 05:05:22,098][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 05:05:22,255][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 05:05:22,433][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 05:05:23,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 05:05:23,239][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 05:05:23,251][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 05:05:23,272][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 05:05:23,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 05:05:23,785][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 05:05:23,983][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 05:05:24,048][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 05:05:24,063][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 05:05:24,140][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 05:05:24,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 05:05:24,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 05:05:24,576][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 05:05:24,780][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 05:05:24,883][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 05:05:24,884][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 05:05:24,958][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 05:05:25,613][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 05:05:26,046][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:05:26,070][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:05:26,137][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 05:05:26,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:05:26,654][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:05:26,858][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:05:26,923][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:05:26,990][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 05:05:26,992][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 36000.000000 | iteration_36000.pth.tar | 32.000000     | 3697.000000   | 115.531250              | 7.170062      | 515.616217          | 4.463002             | 0.250000    | 0.433013   | 1.000000   | 0.000000   | [13.844311714172363, 12.802395820617676, 20.000001907348633, 14.071856498718262, 13.341318130493164, 11.940119743347168, 20.0, 16.41916275024414, 20.0, 15.449102401733398, 20.0, 16.155689239501953, 16.61676788330078, 20.0, 13.772455215454102, 15.109282493591309, 20.0, 13.640719413757324, 14.43413257598877, 16.275449752807617, 13.772455215454102, 16.694610595703125, 15.628743171691895, 16.12874412536621, 15.871257781982422, 15.916168212890625, 11.552395820617676, 14.203593254089355, 10.047904968261719, 20.0, 15.991018295288086, 20.0] | [8.0, 8.0, 0.0, 8.0, 5.0, 8.0, 0.0, 8.0, 0.0, 5.0, 2.0, 5.0, 8.0, 2.0, 7.0, 8.0, 0.0, 6.0, 8.0, 7.0, 5.0, 8.0, 8.0, 8.0, 8.0, 7.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0] | [6.0, 5.0, 9.0, 6.0, 6.0, 4.0, 9.0, 6.0, 9.0, 7.0, 9.0, 8.0, 7.0, 9.0, 7.0, 7.0, 9.0, 6.0, 7.0, 8.0, 7.0, 7.0, 6.0, 7.0, 8.0, 8.0, 5.0, 6.0, 4.0, 9.0, 8.0, 9.0] | 15.927489                   | 5.593750         | 7.125000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:11:26,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 05:11:26,221][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 05:11:26,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 05:11:26,258][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 05:11:26,309][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 05:11:26,379][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 05:11:26,974][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 05:11:27,127][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 05:11:27,270][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 05:11:27,664][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 05:11:27,664][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 05:11:28,700][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 05:11:28,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 05:11:28,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 05:11:28,807][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 05:11:29,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 05:11:29,474][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 05:11:29,508][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 05:11:29,519][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 05:11:29,582][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 05:11:29,629][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 05:11:30,022][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 05:11:30,058][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 05:11:30,214][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 05:11:30,346][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 05:11:30,420][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 05:11:31,077][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 05:11:31,200][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:11:31,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:11:31,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:11:31,979][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:11:32,101][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:11:32,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:11:32,311][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:11:32,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:11:32,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:11:32,967][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:11:32,999][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:11:33,287][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:11:33,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 05:11:33,597][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 37000.000000 | iteration_37000.pth.tar | 32.000000     | 4553.000000   | 142.281250              | 8.381999      | 543.187847          | 3.817705             | 0.375000    | 0.484123   | 1.000000   | 0.000000   | [20.000001907348633, 20.0, 20.0, 20.0, 15.387724876403809, 20.0, 14.359281539916992, 20.0, 15.904191970825195, 20.0, 15.492515563964844, 16.82634735107422, 16.347305297851562, 20.0, 9.944611549377441, 15.832335472106934, 20.0, 20.0, 16.467065811157227, 15.005989074707031, 16.818862915039062, 20.0, 11.532934188842773, 13.121257781982422, 13.829341888427734, 15.80838394165039, 13.089820861816406, 16.706586837768555, 15.856287956237793, 16.730539321899414, 20.0, 16.64670753479004] | [1.0, 0.0, 0.0, 0.0, 8.0, 1.0, 4.0, 0.0, 6.0, 0.0, 8.0, 5.0, 5.0, 1.0, 8.0, 5.0, 2.0, 1.0, 6.0, 5.0, 8.0, 1.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 7.0, 6.0, 0.0, 5.0] | [9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 7.0, 9.0, 7.0, 9.0, 7.0, 8.0, 8.0, 9.0, 3.0, 7.0, 9.0, 9.0, 8.0, 7.0, 8.0, 9.0, 5.0, 5.0, 6.0, 7.0, 6.0, 8.0, 7.0, 8.0, 9.0, 8.0] | 16.928378                   | 4.156250         | 7.656250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:17:37,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 05:17:37,945][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 05:17:37,981][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 05:17:38,002][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 05:17:38,002][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 05:17:38,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 05:17:38,325][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 05:17:38,669][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 05:17:38,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 05:17:39,053][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 05:17:39,127][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 05:17:39,128][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 05:17:39,217][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 05:17:39,445][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 05:17:39,527][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 05:17:39,782][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 05:17:39,919][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 05:17:39,956][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 05:17:40,165][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 05:17:40,403][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 05:17:40,441][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 05:17:40,441][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 05:17:40,694][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 05:17:41,125][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 05:17:41,374][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 05:17:41,772][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 05:17:41,823][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 05:17:42,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 05:17:42,052][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 05:17:42,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 05:17:42,639][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 05:17:42,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:17:42,731][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:17:42,743][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:17:42,982][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:17:43,028][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:17:43,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:17:43,429][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 05:17:43,430][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 38000.000000 | iteration_38000.pth.tar | 32.000000     | 3539.000000   | 110.593750              | 6.285335      | 563.056706          | 5.091216             | 0.437500    | 0.496078   | 1.000000   | 0.000000   | [15.916168212890625, 20.0, 20.0, 16.311378479003906, 15.791916847229004, 20.0, 20.0, 16.754491806030273, 20.0, 20.0, 20.0, 15.137724876403809, 20.0, 20.0, 16.802396774291992, 15.652695655822754, 20.0, 15.844311714172363, 16.862276077270508, 9.637724876403809, 15.688623428344727, 20.0, 16.609281539916992, 14.63473129272461, 16.974552154541016, 20.0, 16.754491806030273, 16.583833694458008, 20.000001907348633, 16.071857452392578, 20.0, 14.467066764831543] | [6.0, 0.0, 0.0, 8.0, 8.0, 1.0, 2.0, 6.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 5.0, 8.0, 1.0, 6.0, 5.0, 8.0, 8.0, 2.0, 8.0, 4.0, 8.0, 0.0, 6.0, 8.0, 0.0, 8.0, 0.0, 5.0] | [8.0, 9.0, 9.0, 7.0, 7.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 8.0, 7.0, 9.0, 8.0, 8.0, 1.0, 8.0, 9.0, 8.0, 7.0, 8.0, 9.0, 8.0, 7.0, 9.0, 7.0, 9.0, 7.0] | 17.577985                   | 4.125000         | 7.968750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:23:49,792][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 05:23:49,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 05:23:49,917][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 05:23:49,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 05:23:50,524][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 05:23:50,667][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 05:23:50,884][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 05:23:50,950][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 05:23:51,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 05:23:51,204][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 05:23:51,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 05:23:51,565][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 05:23:51,566][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 05:23:51,629][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 05:23:51,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 05:23:51,941][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 05:23:51,953][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 05:23:52,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 05:23:52,396][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 05:23:52,683][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 05:23:52,945][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 05:23:52,990][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 05:23:53,143][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 05:23:53,285][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 05:23:53,780][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 05:23:53,835][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 05:23:53,877][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 05:23:53,943][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 05:23:53,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 05:23:54,172][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 05:23:54,173][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 05:23:54,442][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 05:23:54,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 05:23:54,833][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:23:54,849][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:23:55,452][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:23:55,536][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:23:55,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:23:55,892][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:23:56,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 05:23:56,785][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 39000.000000 | iteration_39000.pth.tar | 32.000000     | 3969.000000   | 124.031250              | 7.657159      | 518.338447          | 4.179096             | 0.468750    | 0.499022   | 1.000000   | 0.000000   | [20.0, 16.890718460083008, 15.50898265838623, 20.0, 16.811378479003906, 20.0, 15.772455215454102, 17.097305297851562, 14.878743171691895, 20.0, 20.0, 16.751497268676758, 17.026947021484375, 15.305389404296875, 20.0, 14.395210266113281, 16.730539321899414, 16.706586837768555, 20.0, 20.0, 14.504491806030273, 20.0, 20.0, 20.0, 11.616766929626465, 15.726048469543457, 13.017964363098145, 16.83832359313965, 20.0, 20.0, 20.0, 20.0] | [1.0, 8.0, 8.0, 1.0, 8.0, 0.0, 6.0, 8.0, 8.0, 1.0, 3.0, 8.0, 8.0, 6.0, 1.0, 6.0, 7.0, 7.0, 4.0, 1.0, 8.0, 0.0, 0.0, 1.0, 8.0, 8.0, 8.0, 7.0, 0.0, 1.0, 0.0, 0.0] | [9.0, 8.0, 7.0, 9.0, 7.0, 9.0, 7.0, 8.0, 7.0, 9.0, 9.0, 8.0, 8.0, 7.0, 9.0, 7.0, 8.0, 8.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 5.0, 8.0, 6.0, 8.0, 9.0, 9.0, 9.0, 9.0] | 17.674355                   | 4.406250         | 8.093750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:29:57,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 05:29:57,770][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 05:29:57,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 05:29:57,870][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 05:29:58,210][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 05:29:58,265][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 05:29:58,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 05:29:58,548][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 05:29:58,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 05:29:59,099][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 05:29:59,099][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 05:29:59,148][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 05:29:59,332][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 05:29:59,332][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 05:29:59,332][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 05:29:59,427][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 05:30:00,090][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 05:30:00,227][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 05:30:00,454][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 05:30:01,105][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 05:30:01,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 05:30:01,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 05:30:01,703][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 05:30:01,915][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 05:30:01,915][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 05:30:01,915][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 05:30:02,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 05:30:02,187][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 05:30:02,588][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 05:30:02,715][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 05:30:02,728][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 05:30:02,855][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:30:03,182][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:30:03,348][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:30:03,425][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:30:03,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:30:03,694][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:30:03,947][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:30:03,958][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:30:04,224][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:30:04,246][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:30:04,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:30:04,772][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:30:04,878][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:30:04,909][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:30:05,193][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:30:05,433][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 05:30:05,434][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 40000.000000 | iteration_40000.pth.tar | 32.000000     | 4490.000000   | 140.312500              | 8.586268      | 522.928031          | 3.726881             | 0.218750    | 0.413399   | 1.000000   | 0.000000   | [13.832335472106934, 16.58682632446289, 16.0, 20.0, 20.0, 20.0, 16.874252319335938, 17.119760513305664, 16.62275505065918, 15.796407699584961, 13.904191970825195, 11.326347351074219, 17.04191780090332, 16.375749588012695, 14.275449752807617, 12.452095985412598, 15.149701118469238, 16.562875747680664, 20.0, 16.82634735107422, 15.952095985412598, 20.0, 15.688623428344727, 20.0, 15.305389404296875, 14.526947021484375, 20.0, 15.688623428344727, 9.818862915039062, 12.532934188842773, 14.121257781982422, 15.688623428344727] | [7.0, 7.0, 6.0, 2.0, 2.0, 3.0, 6.0, 8.0, 8.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 6.0, 0.0, 8.0, 0.0, 6.0, 8.0, 0.0, 8.0, 8.0, 8.0, 8.0, 6.0] | [7.0, 8.0, 8.0, 9.0, 9.0, 9.0, 8.0, 8.0, 7.0, 8.0, 5.0, 5.0, 7.0, 8.0, 5.0, 4.0, 7.0, 7.0, 9.0, 8.0, 8.0, 9.0, 8.0, 9.0, 7.0, 5.0, 9.0, 8.0, 4.0, 4.0, 7.0, 8.0] | 16.127199                   | 6.062500         | 7.250000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:36:04,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 05:36:04,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 05:36:04,305][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 05:36:04,354][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 05:36:04,998][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 05:36:05,131][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 05:36:05,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 05:36:05,228][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 05:36:05,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 05:36:05,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 05:36:05,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 05:36:05,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 05:36:06,214][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 05:36:06,324][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 05:36:06,461][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 05:36:06,786][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 05:36:06,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 05:36:06,858][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 05:36:06,962][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 05:36:07,189][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 05:36:07,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 05:36:07,465][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 05:36:07,640][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 05:36:07,966][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 05:36:07,966][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 05:36:08,039][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 05:36:08,078][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 05:36:08,330][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 05:36:08,660][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 05:36:08,876][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:36:08,888][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:36:09,037][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 05:36:09,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:36:09,091][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:36:09,185][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:36:09,355][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:36:09,392][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:36:09,871][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:36:09,885][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:36:09,899][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:36:09,938][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:36:10,157][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:36:10,250][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:36:10,264][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 05:36:10,268][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 41000.000000 | iteration_41000.pth.tar | 32.000000     | 3653.000000   | 114.156250              | 6.987851      | 522.764469          | 4.579377             | 0.625000    | 0.484123   | 1.000000   | 0.000000   | [17.224552154541016, 20.0, 20.0, 16.694610595703125, 20.0, 20.0, 20.0, 20.0, 16.18712615966797, 16.862276077270508, 20.0, 15.904191970825195, 20.0, 20.0, 17.085330963134766, 20.0, 16.7275447845459, 20.0, 20.0, 20.0, 13.965569496154785, 20.0, 20.0, 20.0, 20.0, 16.508983612060547, 16.107784271240234, 20.0, 15.844311714172363, 20.0, 16.82634735107422, 20.0] | [8.0, 0.0, 0.0, 8.0, 0.0, 3.0, 1.0, 1.0, 7.0, 8.0, 1.0, 8.0, 1.0, 2.0, 8.0, 0.0, 8.0, 1.0, 0.0, 2.0, 8.0, 3.0, 0.0, 0.0, 0.0, 8.0, 7.0, 0.0, 3.0, 2.0, 6.0, 1.0] | [7.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 8.0, 7.0, 9.0, 7.0, 9.0, 9.0, 8.0, 9.0, 8.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 7.0, 8.0, 9.0, 8.0, 9.0, 8.0, 9.0] | 18.623082                   | 3.281250         | 8.406250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:42:06,839][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 05:42:06,885][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 05:42:06,910][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 05:42:06,970][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 05:42:07,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 05:42:07,544][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 05:42:07,544][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 05:42:07,626][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 05:42:07,704][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 05:42:07,778][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 05:42:08,438][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 05:42:08,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 05:42:08,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 05:42:08,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 05:42:08,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 05:42:08,632][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 05:42:08,662][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 05:42:08,758][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 05:42:09,174][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 05:42:09,283][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 05:42:09,320][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 05:42:09,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 05:42:09,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 05:42:09,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 05:42:10,017][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 05:42:10,121][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 05:42:10,132][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 05:42:10,401][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 05:42:10,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 05:42:11,003][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:42:11,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:42:11,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:42:11,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:42:11,063][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:42:11,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:42:11,298][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:42:11,903][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:42:11,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:42:11,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:42:11,952][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:42:12,108][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:42:12,159][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 05:42:12,161][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 42000.000000 | iteration_42000.pth.tar | 32.000000     | 3359.000000   | 104.968750              | 6.069104      | 553.459006          | 5.272607             | 0.781250    | 0.413399   | 1.000000   | 0.000000   | [17.182636260986328, 20.0, 20.0, 20.0, 12.919161796569824, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.41916275024414, 20.000001907348633, 20.0, 20.0, 20.0, 16.41916275024414, 16.862276077270508, 13.0, 16.928144454956055, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [8.0, 0.0, 1.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 7.0, 7.0, 8.0, 8.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0] | [8.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 6.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.054080                   | 1.968750         | 8.656250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:48:46,397][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 05:48:46,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 05:48:46,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 05:48:46,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 05:48:46,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 05:48:46,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 05:48:46,609][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 05:48:46,901][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 05:48:47,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 05:48:47,441][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 05:48:47,441][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 05:48:47,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 05:48:47,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 05:48:47,528][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 05:48:47,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 05:48:47,808][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 05:48:48,220][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 05:48:48,221][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 05:48:48,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 05:48:48,299][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 05:48:48,341][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 05:48:48,530][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 05:48:48,801][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 05:48:49,041][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 05:48:49,111][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 05:48:49,241][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 05:48:49,264][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 05:48:49,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 05:48:49,567][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 05:48:49,935][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 05:48:49,947][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 05:48:50,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 05:48:50,164][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:48:50,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 05:48:50,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:48:50,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:48:50,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 05:48:50,943][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:48:50,955][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 05:48:50,956][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 43000.000000 | iteration_43000.pth.tar | 32.000000     | 2858.000000   | 89.312500               | 5.159272      | 553.954127          | 6.202425             | 0.687500    | 0.463512   | 1.000000   | 0.000000   | [15.688623428344727, 20.0, 20.0, 16.323354721069336, 20.0, 20.0, 20.0, 9.772455215454102, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.26197624206543, 10.61377239227295, 20.000001907348633, 20.0, 16.741018295288086, 20.0, 20.0, 20.0, 20.0, 16.742515563964844, 20.0, 15.568862915039062, 20.0, 9.20059871673584, 20.0, 20.0, 14.03293514251709, 20.0] | [8.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 8.0, 8.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 1.0, 7.0, 1.0, 8.0, 0.0, 8.0, 2.0, 0.0, 8.0, 0.0] | [8.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 4.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 5.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 8.0, 9.0, 4.0, 9.0, 9.0, 6.0, 9.0] | 18.123316                   | 2.843750         | 8.250000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 05:54:47,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 05:54:47,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 05:54:47,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 05:54:47,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 05:54:47,747][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 05:54:47,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 05:54:47,843][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 05:54:48,044][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 05:54:48,363][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 05:54:48,659][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 05:54:48,715][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 05:54:48,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 05:54:48,753][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 05:54:49,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 05:54:49,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 05:54:49,503][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 05:54:49,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 05:54:49,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 05:54:49,561][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 05:54:49,771][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 05:54:49,820][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 05:54:50,164][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 05:54:50,237][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 05:54:50,262][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 05:54:50,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 05:54:50,326][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 05:54:50,369][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 05:54:50,645][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 05:54:50,709][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 05:54:51,204][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:54:51,279][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:54:51,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:54:51,326][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:54:51,337][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:54:51,337][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 05:54:51,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 05:54:52,127][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 05:54:52,128][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 44000.000000 | iteration_44000.pth.tar | 32.000000     | 2748.000000   | 85.875000               | 5.256378      | 522.793459          | 6.087842             | 0.781250    | 0.413399   | 1.000000   | 0.000000   | [17.327844619750977, 16.71556854248047, 20.0, 16.335329055786133, 20.0, 20.0, 20.0, 20.0, 20.0, 15.76197624206543, 20.0, 12.241018295288086, 20.0, 20.0, 13.473054885864258, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.790419578552246, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [8.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 8.0, 0.0, 0.0, 8.0, 2.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 7.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0] | [8.0, 8.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 6.0, 9.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 18.957663                   | 2.406250         | 8.531250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:00:47,236][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:00:47,285][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:00:47,315][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:00:47,343][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:00:47,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 06:00:47,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 06:00:47,928][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 06:00:48,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 06:00:48,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 06:00:48,095][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:00:48,095][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:00:48,130][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 06:00:48,207][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 06:00:48,680][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 06:00:48,754][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 06:00:48,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 06:00:48,819][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 06:00:48,897][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:00:48,926][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:00:48,953][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 06:00:49,624][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 06:00:49,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 06:00:49,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 06:00:49,928][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:00:49,939][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 06:00:50,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 06:00:50,449][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:00:50,499][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 06:00:50,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 06:00:50,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:00:50,560][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:00:50,716][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:00:51,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:00:51,298][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:00:51,337][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:00:51,350][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:00:51,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 06:00:51,442][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:00:51,573][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:00:51,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 06:00:51,686][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 45000.000000 | iteration_45000.pth.tar | 32.000000     | 2889.000000   | 90.281250               | 5.365113      | 538.478844          | 5.964459             | 0.812500    | 0.390312   | 1.000000   | 0.000000   | [20.0, 20.0, 15.664671897888184, 20.000001907348633, 20.0, 20.0, 16.128742218017578, 20.0, 20.0, 20.0, 17.002994537353516, 20.0, 20.0, 20.0, 20.0, 15.75898265838623, 14.155689239501953, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.089820861816406, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 6.0, 1.0, 0.0, 1.0, 8.0, 2.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 8.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.181278                   | 1.593750         | 8.687500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:06:44,179][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:06:44,179][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:06:44,205][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:06:44,206][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:06:44,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 06:06:44,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 06:06:44,597][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 06:06:45,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 06:06:45,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 06:06:45,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:06:45,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:06:45,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 06:06:45,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 06:06:45,669][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 06:06:45,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 06:06:45,936][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 06:06:46,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 06:06:46,037][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:06:46,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:06:46,101][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 06:06:46,486][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 06:06:46,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 06:06:46,622][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 06:06:46,731][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:06:46,892][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 06:06:46,892][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 06:06:46,892][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:06:47,607][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:06:47,694][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:06:47,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:06:47,862][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:06:47,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:06:48,040][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:06:48,054][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:06:48,537][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:06:48,624][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 06:06:48,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:06:48,650][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 06:06:48,650][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 06:06:48,651][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 46000.000000 | iteration_46000.pth.tar | 32.000000     | 2787.000000   | 87.093750               | 5.300839      | 525.765840          | 6.036780             | 0.781250    | 0.413399   | 1.000000   | 0.000000   | [20.0, 20.000001907348633, 20.0, 15.688623428344727, 20.0, 11.199102401733398, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.380240440368652, 20.0, 20.0, 20.0, 17.13323402404785, 20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 16.31437110900879, 20.0, 20.0] | [0.0, 1.0, 1.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 1.0, 3.0, 8.0, 1.0, 1.0, 0.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 8.0, 1.0, 0.0] | [9.0, 9.0, 9.0, 8.0, 9.0, 4.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0] | 18.940401                   | 1.968750         | 8.593750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:12:45,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:12:45,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 06:12:45,228][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:12:45,304][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:12:45,330][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 06:12:45,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 06:12:45,858][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 06:12:45,959][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 06:12:46,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 06:12:46,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:12:46,312][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:12:46,413][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 06:12:46,530][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 06:12:46,755][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 06:12:46,756][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 06:12:46,920][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 06:12:47,093][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 06:12:47,116][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:12:47,158][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:12:47,246][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 06:12:47,598][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 06:12:47,741][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 06:12:48,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 06:12:48,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:12:48,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 06:12:48,250][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 06:12:48,551][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:12:48,720][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:12:48,985][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 06:12:49,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:12:49,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:12:49,157][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:12:49,418][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:12:49,545][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:12:49,702][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:12:49,895][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:12:50,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:12:50,505][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 06:12:50,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:12:50,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:12:50,839][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 06:12:50,840][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 47000.000000 | iteration_47000.pth.tar | 32.000000     | 3328.000000   | 104.000000              | 6.382833      | 521.398570          | 5.013448             | 0.718750    | 0.449609   | 1.000000   | 0.000000   | [20.0, 20.0, 16.40718650817871, 20.0, 14.363773345947266, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.550898551940918, 20.0, 20.0, 16.59880256652832, 20.0, 20.0, 17.131736755371094, 14.203593254089355, 16.41916275024414, 20.0, 13.230539321899414, 20.0, 16.4940128326416, 20.0, 20.000001907348633, 20.0, 20.0] | [1.0, 1.0, 8.0, 0.0, 8.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 1.0, 1.0, 7.0, 0.0, 1.0, 8.0, 8.0, 7.0, 2.0, 8.0, 0.0, 8.0, 1.0, 0.0, 2.0, 1.0] | [9.0, 9.0, 8.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 8.0, 9.0, 9.0, 8.0, 7.0, 8.0, 9.0, 6.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0] | 18.731241                   | 2.656250         | 8.562500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:18:54,610][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:18:54,669][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:18:54,683][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 06:18:54,728][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:18:54,775][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 06:18:54,805][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 06:18:55,102][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 06:18:55,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 06:18:55,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 06:18:55,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:18:55,855][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 06:18:55,949][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 06:18:56,003][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 06:18:56,160][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 06:18:56,303][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 06:18:56,412][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 06:18:56,556][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 06:18:56,584][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:18:56,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:18:57,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 06:18:57,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 06:18:57,440][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 06:18:57,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 06:18:57,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:18:57,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 06:18:57,973][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 06:18:58,125][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 06:18:58,341][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 06:18:58,604][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:18:58,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 06:18:58,769][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:18:58,870][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 06:18:59,229][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:18:59,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:18:59,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:18:59,922][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 06:18:59,925][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                    | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 48000.000000 | iteration_48000.pth.tar | 32.000000     | 3109.000000   | 97.156250               | 6.112905      | 508.596136          | 5.234827             | 0.500000    | 0.500000   | 1.000000   | 0.000000   | [13.161677360534668, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 12.29940128326416, 16.682636260986328, 16.43113899230957, 20.000001907348633, 20.0, 16.196107864379883, 20.0, 20.0, 20.0, 12.23353385925293, 15.31137752532959, 15.640719413757324, 13.655689239501953, 14.127245903015137, 20.0, 14.754491806030273, 20.0, 20.0, 15.02395248413086, 20.0, 16.335330963134766, 20.0, 14.546407699584961, 14.359281539916992, 15.341318130493164] | [8.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 8.0, 7.0, 8.0, 2.0, 1.0, 8.0, 0.0, 0.0, 1.0, 8.0, 8.0, 8.0, 8.0, 8.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 7.0, 0.0, 8.0, 5.0, 8.0] | [5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 8.0, 8.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 5.0, 6.0, 7.0, 6.0, 6.0, 9.0, 6.0, 9.0, 9.0, 7.0, 9.0, 8.0, 9.0, 7.0, 7.0, 7.0] | 17.378135                   | 4.093750         | 7.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:24:57,233][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:24:57,270][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:24:57,284][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:24:57,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:24:57,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 06:24:57,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 06:24:57,333][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 06:24:57,380][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 06:24:58,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 06:24:58,103][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:24:58,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:24:58,140][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 06:24:58,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 06:24:58,230][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 06:24:58,230][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 06:24:58,876][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 06:24:59,123][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 06:24:59,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:24:59,245][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:24:59,260][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 06:24:59,348][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 06:24:59,771][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 06:24:59,934][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 06:25:00,018][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:25:00,050][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 06:25:00,072][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 06:25:00,127][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:25:00,451][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:25:00,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 06:25:00,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 06:25:00,610][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:25:00,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:25:00,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:25:00,752][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:25:00,786][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:25:01,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:25:01,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:25:01,497][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 06:25:01,498][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 49000.000000 | iteration_49000.pth.tar | 32.000000     | 2779.000000   | 86.843750               | 5.062436      | 548.945260          | 6.321068             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 16.874252319335938, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 17.025449752807617, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.640719413757324, 20.0, 20.0, 20.0] | [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 3.0, 9.0, 9.0, 9.0] | 19.350908                   | 1.062500         | 8.718750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:30:59,380][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 06:30:59,479][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:30:59,479][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:30:59,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:30:59,514][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 06:30:59,529][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 06:30:59,578][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 06:31:00,346][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 06:31:00,359][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 06:31:00,421][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:31:00,474][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:31:00,475][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 06:31:00,475][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 06:31:01,106][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 06:31:01,214][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 06:31:01,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 06:31:01,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 06:31:01,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:31:01,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:31:02,128][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 06:31:02,165][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 06:31:02,177][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 06:31:02,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 06:31:02,630][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 06:31:02,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 06:31:02,950][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 06:31:02,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 06:31:03,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:31:03,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 06:31:03,687][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:31:03,875][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 06:31:04,112][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:31:04,173][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 06:31:04,185][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 06:31:04,186][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 50000.000000 | iteration_50000.pth.tar | 32.000000     | 2863.000000   | 89.468750               | 5.742760      | 498.540749          | 5.572233             | 0.718750    | 0.449609   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 14.429640769958496, 20.0, 20.0, 20.0, 10.85778522491455, 20.0, 20.0, 16.10628890991211, 20.0, 20.0, 15.700599670410156, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 12.223053932189941, 14.251497268676758, 20.0, 20.0, 10.46257495880127, 20.0, 20.0, 20.0, 16.778444290161133, 20.0, 20.0, 20.000001907348633, 14.426647186279297] | [1.0, 1.0, 0.0, 8.0, 1.0, 0.0, 0.0, 8.0, 0.0, 1.0, 8.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 8.0, 4.0, 0.0, 0.0, 8.0, 0.0, 2.0, 1.0, 4.0, 0.0, 0.0, 0.0, 6.0] | [9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 5.0, 9.0, 9.0, 8.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 7.0, 9.0, 9.0, 3.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 6.0] | 18.288642                   | 2.125000         | 8.281250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:37:05,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:37:05,276][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:37:05,299][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:37:05,389][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:37:05,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 06:37:05,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 06:37:05,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 06:37:05,987][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 06:37:06,011][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 06:37:06,114][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:37:06,156][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:37:06,781][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 06:37:07,223][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 06:37:07,267][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 06:37:07,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 06:37:07,385][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 06:37:07,642][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 06:37:08,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:37:08,247][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 06:37:08,350][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 06:37:08,481][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 06:37:08,814][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 06:37:09,109][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 06:37:09,232][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:37:09,243][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:37:09,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 06:37:09,635][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 06:37:09,861][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 06:37:09,886][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 06:37:10,036][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 06:37:10,062][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:37:10,165][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:37:10,472][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 06:37:10,589][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:37:10,688][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:37:10,711][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:37:10,734][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:37:10,922][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:37:11,140][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:37:11,414][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:37:11,548][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 06:37:11,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:37:11,902][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:37:12,046][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 06:37:12,223][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:37:12,279][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 06:37:12,281][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 51000.000000 | iteration_51000.pth.tar | 32.000000     | 4067.000000   | 127.093750              | 7.798625      | 521.502221          | 4.103288             | 0.593750    | 0.491132   | 1.000000   | 0.000000   | [20.0, 14.215569496154785, 16.98802375793457, 20.0, 16.850299835205078, 16.502994537353516, 20.0, 16.7215576171875, 20.0, 20.0, 15.781437873840332, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 13.844311714172363, 16.562875747680664, 14.251497268676758, 20.0, 20.0, 20.0, 15.321856498718262, 16.706586837768555, 20.0, 9.14820384979248, 20.0, 20.0, 15.654191970825195, 20.0, 20.0] | [0.0, 6.0, 8.0, 0.0, 6.0, 5.0, 0.0, 8.0, 0.0, 0.0, 8.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 8.0, 7.0, 6.0, 1.0, 0.0, 0.0, 8.0, 8.0, 0.0, 8.0, 0.0, 2.0, 8.0, 0.0, 0.0] | [9.0, 7.0, 8.0, 9.0, 8.0, 8.0, 9.0, 8.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 8.0, 7.0, 9.0, 9.0, 9.0, 7.0, 8.0, 9.0, 2.0, 9.0, 9.0, 7.0, 9.0, 9.0] | 18.079669                   | 3.125000         | 8.187500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:43:05,373][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:43:05,373][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:43:05,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:43:05,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:43:05,404][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 06:43:05,416][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 06:43:05,452][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 06:43:06,006][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 06:43:06,117][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 06:43:06,229][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:43:06,240][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:43:06,283][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 06:43:06,403][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 06:43:06,968][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 06:43:06,991][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 06:43:07,003][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 06:43:07,157][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 06:43:07,196][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:43:07,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:43:07,721][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 06:43:07,746][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 06:43:07,757][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 06:43:07,908][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 06:43:07,964][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:43:08,170][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 06:43:08,580][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 06:43:08,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:43:08,700][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:43:08,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 06:43:08,786][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:43:08,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:43:09,509][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 06:43:09,566][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:43:09,614][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:43:09,714][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:43:09,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:43:09,823][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:43:09,834][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:43:10,208][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 06:43:10,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 06:43:10,303][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                        | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 52000.000000 | iteration_52000.pth.tar | 32.000000     | 3225.000000   | 100.781250              | 5.686030      | 567.179534          | 5.627828             | 0.750000    | 0.433013   | 1.000000   | 0.000000   | [16.043413162231445, 20.0, 16.550899505615234, 20.0, 20.0, 16.98802375793457, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.862276077270508, 20.0, 20.0, 20.0, 15.501497268676758, 10.014970779418945, 16.694610595703125, 20.0, 20.0, 15.688623428344727, 20.0, 20.000001907348633, 20.0, 20.0, 20.0] | [8.0, 0.0, 7.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 8.0, 8.0, 7.0, 1.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 0.0] | [8.0, 9.0, 8.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 7.0, 4.0, 8.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 18.885760                   | 2.093750         | 8.593750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:49:46,840][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:49:46,866][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:49:46,878][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:49:46,913][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:49:46,925][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 06:49:46,984][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 06:49:47,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 06:49:47,139][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 06:49:47,624][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 06:49:47,704][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:49:47,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:49:48,101][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 06:49:48,136][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 06:49:48,160][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 06:49:48,684][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 06:49:48,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 06:49:48,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 06:49:48,893][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:49:48,931][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:49:48,942][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 06:49:49,465][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 06:49:49,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 06:49:49,501][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 06:49:49,501][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:49:49,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 06:49:49,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 06:49:49,789][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:49:49,881][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 06:49:50,282][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:49:50,344][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:49:50,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:49:50,406][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:49:50,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:49:50,780][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:49:50,940][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 06:49:51,160][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:49:51,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:49:51,405][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 06:49:51,406][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 53000.000000 | iteration_53000.pth.tar | 32.000000     | 2787.000000   | 87.093750               | 5.334700      | 522.428656          | 5.998463             | 0.812500    | 0.390312   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.86077880859375, 20.0, 16.802396774291992, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 15.161677360534668, 20.0, 13.08533000946045, 20.0, 20.0, 20.0, 20.0, 20.0, 17.07634735107422, 20.0, 20.0, 15.269461631774902, 20.0] | [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 8.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 8.0, 1.0, 5.0, 1.0, 1.0, 3.0, 0.0, 0.0, 8.0, 0.0, 1.0, 8.0, 1.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 7.0, 9.0] | 19.039250                   | 1.843750         | 8.593750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 06:55:55,420][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 06:55:55,484][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 06:55:55,484][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 06:55:55,520][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 06:55:55,520][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 06:55:55,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 06:55:55,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 06:55:56,157][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 06:55:56,177][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 06:55:56,219][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 06:55:56,263][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 06:55:56,263][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 06:55:56,274][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 06:55:56,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 06:55:56,329][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 06:55:57,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 06:55:57,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 06:55:57,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 06:55:57,620][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 06:55:57,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 06:55:57,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 06:55:58,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 06:55:58,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 06:55:58,573][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 06:55:58,587][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 06:55:58,750][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 06:55:58,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 06:55:59,089][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 06:55:59,089][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 06:55:59,224][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 06:55:59,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 06:55:59,688][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:55:59,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 06:55:59,796][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 06:55:59,797][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 54000.000000 | iteration_54000.pth.tar | 32.000000     | 2535.000000   | 79.218750               | 5.099460      | 497.111415          | 6.275174             | 0.812500    | 0.390312   | 1.000000   | 0.000000   | [16.57485008239746, 20.0, 16.08233642578125, 20.0, 20.0, 20.0, 14.744012832641602, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 16.2155704498291, 20.0, 20.0, 20.0, 20.0, 14.732036590576172, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.688623428344727] | [8.0, 0.0, 8.0, 0.0, 1.0, 1.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 8.0] | [8.0, 9.0, 8.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0] | 19.188670                   | 1.718750         | 8.750000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:01:54,636][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 07:01:54,674][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:01:54,716][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 07:01:54,716][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:01:54,729][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:01:54,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:01:54,787][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 07:01:55,459][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 07:01:55,507][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:01:55,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 07:01:55,530][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:01:55,530][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:01:55,599][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 07:01:55,613][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 07:01:55,678][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 07:01:57,090][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:01:57,090][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:01:57,102][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:01:57,155][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:01:57,155][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:01:57,224][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 07:01:57,238][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 07:01:57,252][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:01:57,868][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:01:57,920][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 07:01:58,004][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:01:58,100][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 07:01:58,119][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:01:58,119][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:01:58,478][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 07:01:58,737][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 07:01:58,750][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:01:59,006][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:01:59,019][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:01:59,372][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:01:59,492][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:01:59,593][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:01:59,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:01:59,904][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:02:00,424][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 07:02:00,426][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                            | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 55000.000000 | iteration_55000.pth.tar | 32.000000     | 3137.000000   | 98.031250               | 6.581619      | 476.630471          | 4.862026             | 0.812500    | 0.390312   | 1.000000   | 0.000000   | [20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 17.131736755371094, 20.0, 16.440120697021484, 20.0, 20.0, 15.988024711608887, 20.0, 20.0, 20.0, 20.0, 13.244012832641602, 20.0, 16.917665481567383, 20.0, 7.784431457519531, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 8.0, 2.0, 8.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 8.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 4.0, 9.0, 8.0, 9.0, 4.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 18.984562                   | 1.656250         | 8.562500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:08:02,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 07:08:02,346][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 07:08:02,367][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 07:08:02,452][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:08:02,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:08:02,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:08:02,565][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 07:08:02,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 07:08:03,058][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:08:03,167][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 07:08:03,257][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:08:03,291][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:08:03,331][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 07:08:03,406][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 07:08:03,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 07:08:03,526][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:08:03,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:08:03,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:08:04,048][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:08:04,072][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:08:04,332][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 07:08:04,416][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 07:08:04,551][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:08:04,689][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:08:04,897][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 07:08:04,980][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:08:05,014][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 07:08:05,014][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:08:05,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 07:08:05,181][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:08:05,322][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:08:05,453][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 07:08:05,454][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 56000.000000 | iteration_56000.pth.tar | 32.000000     | 2273.000000   | 71.031250               | 4.059973      | 559.855954          | 7.881826             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.446107864379883, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.559881210327148, 13.000000953674316, 11.39820384979248, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 5.0, 5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.200131                   | 1.125000         | 8.562500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:14:02,262][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 07:14:02,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:14:02,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 07:14:02,331][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:14:02,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:14:02,382][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:14:02,441][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 07:14:02,470][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 07:14:03,131][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:14:03,153][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 07:14:03,153][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:14:03,164][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:14:03,175][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 07:14:03,261][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 07:14:03,528][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 07:14:04,423][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:14:04,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:14:04,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 07:14:04,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:14:04,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:14:04,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 07:14:04,830][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 07:14:05,300][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:14:05,351][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:14:05,393][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 07:14:05,421][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:14:05,510][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 07:14:05,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 07:14:05,663][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:14:06,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 07:14:06,953][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:14:06,966][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:14:07,111][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:14:07,168][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:07,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:07,426][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:07,645][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 07:14:07,843][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:07,963][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:07,974][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:08,053][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:08,409][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:08,615][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:08,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:08,876][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:14:08,999][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 07:14:09,001][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 57000.000000 | iteration_57000.pth.tar | 32.000000     | 3651.000000   | 114.093750              | 7.536518      | 484.441251          | 4.245993             | 0.781250    | 0.413399   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 15.688623428344727, 15.36976146697998, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.871257781982422, 15.389222145080566, 20.0, 20.0, 20.0, 12.41317367553711, 20.0, 16.130239486694336, 16.143712997436523, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0] | [2.0, 0.0, 0.0, 1.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 8.0, 8.0, 0.0, 0.0, 1.0, 8.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 8.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 7.0, 9.0, 9.0, 9.0, 3.0, 9.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.000187                   | 1.937500         | 8.531250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:20:16,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 07:20:16,349][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:20:16,397][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 07:20:16,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:20:16,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:20:16,587][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:20:16,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 07:20:17,155][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 07:20:17,197][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:20:17,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 07:20:17,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:20:17,342][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:20:17,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 07:20:17,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 07:20:18,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 07:20:18,344][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:20:18,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:20:18,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:20:18,409][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:20:18,638][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:20:18,684][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 07:20:19,200][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 07:20:19,243][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:20:19,243][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:20:19,323][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 07:20:19,337][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:20:19,365][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 07:20:19,510][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:20:19,511][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:20:20,281][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:20:20,319][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:20:20,319][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:20:20,330][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:20:20,343][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:20:20,540][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:20:20,644][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:20:20,805][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 07:20:21,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:20:21,223][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:20:21,237][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 07:20:21,238][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 58000.000000 | iteration_58000.pth.tar | 32.000000     | 2937.000000   | 91.781250               | 5.748296      | 510.934032          | 5.566867             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.989521026611328, 20.0, 16.6706600189209, 20.0, 20.0] | [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 7.0, 0.0, 2.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 8.0, 9.0, 9.0] | 19.801881                   | 0.656250         | 8.906250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:26:27,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 07:26:27,680][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:26:27,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 07:26:27,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:26:27,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:26:27,743][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:26:28,684][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 07:26:28,710][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 07:26:28,710][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:26:28,750][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 07:26:28,778][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:26:29,223][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 07:26:29,437][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 07:26:29,438][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 07:26:29,532][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 07:26:29,558][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:26:29,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:26:29,609][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:26:29,635][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:26:30,001][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:26:30,246][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 07:26:30,373][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 07:26:30,418][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:26:30,462][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:26:30,508][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 07:26:30,545][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:26:30,545][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 07:26:31,137][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:26:31,442][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:26:31,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:26:31,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:26:31,704][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:26:31,720][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:26:31,771][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:26:31,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 07:26:32,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 07:26:32,449][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:26:32,555][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:26:32,571][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:26:32,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:26:32,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:26:32,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 07:26:32,686][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 59000.000000 | iteration_59000.pth.tar | 32.000000     | 2936.000000   | 91.750000               | 5.797780      | 506.400702          | 5.519354             | 0.843750    | 0.363092   | 1.000000   | 0.000000   | [15.688623428344727, 20.0, 20.0, 7.281437397003174, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.258983612060547, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.676647186279297, 20.0, 20.0, 20.0, 16.131736755371094, 20.0, 20.0, 20.0] | [8.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0] | [8.0, 9.0, 9.0, 2.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0] | 19.126170                   | 1.281250         | 8.656250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:32:34,096][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 07:32:34,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:32:34,109][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 07:32:34,122][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:32:34,122][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:32:34,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:32:34,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 07:32:34,215][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 07:32:34,835][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:32:34,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 07:32:34,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:32:34,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:32:34,933][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 07:32:34,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 07:32:34,967][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 07:32:34,994][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:32:35,689][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:32:35,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:32:35,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:32:35,802][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:32:35,815][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 07:32:35,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 07:32:35,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:32:36,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:32:36,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 07:32:36,831][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:32:36,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 07:32:36,949][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:32:36,963][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:32:37,003][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:32:37,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:32:37,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:32:37,672][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:32:37,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:32:37,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 07:32:37,736][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 60000.000000 | iteration_60000.pth.tar | 32.000000     | 2343.000000   | 73.218750               | 4.597387      | 509.637353          | 6.960476             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.91018009185791, 15.317365646362305, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 6.0, 9.0, 9.0, 9.0, 9.0] | 19.725861                   | 0.625000         | 8.875000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:38:33,119][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 07:38:33,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:38:33,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 07:38:33,164][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:38:33,368][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:38:33,446][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:38:33,654][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 07:38:34,116][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 07:38:34,144][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:38:34,197][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 07:38:34,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:38:34,235][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:38:34,263][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 07:38:34,519][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 07:38:34,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 07:38:34,969][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:38:34,994][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:38:35,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:38:35,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:38:35,605][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:38:35,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 07:38:35,854][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 07:38:35,920][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:38:36,007][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:38:36,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 07:38:36,117][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:38:36,349][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 07:38:36,540][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:38:36,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:38:36,752][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:38:36,897][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:38:36,938][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:38:36,952][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 07:38:36,996][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:38:37,298][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:38:37,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:38:37,536][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 07:38:37,537][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                            | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 61000.000000 | iteration_61000.pth.tar | 32.000000     | 2740.000000   | 85.625000               | 5.267016      | 520.218696          | 6.075547             | 0.812500    | 0.390312   | 1.000000   | 0.000000   | [20.0, 16.862276077270508, 20.0, 20.0, 20.0, 20.0, 14.477545738220215, 20.0, 16.688623428344727, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.498503684997559, 20.0, 20.0, 20.0, 16.889223098754883, 16.05239486694336, 20.0, 20.0, 20.0, 20.0] | [0.0, 7.0, 2.0, 0.0, 0.0, 1.0, 8.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 8.0, 1.0, 0.0, 2.0, 8.0, 8.0, 0.0, 0.0, 0.0, 1.0] | [9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 8.0, 7.0, 9.0, 9.0, 9.0, 9.0] | 19.233393                   | 1.812500         | 8.687500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:44:36,440][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 07:44:36,466][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:44:36,466][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 07:44:36,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:44:36,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:44:36,590][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:44:36,590][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 07:44:37,114][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 07:44:37,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 07:44:37,524][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 07:44:37,524][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:44:37,585][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:44:37,600][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 07:44:37,643][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 07:44:37,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 07:44:38,277][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:44:38,304][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:44:38,398][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:44:38,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:44:38,499][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:44:38,499][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 07:44:38,538][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 07:44:38,612][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:44:39,111][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:44:39,181][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 07:44:39,205][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:44:39,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 07:44:39,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:44:39,344][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:44:39,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 07:44:39,463][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:44:40,100][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:44:40,187][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 07:44:40,188][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 62000.000000 | iteration_62000.pth.tar | 32.000000     | 2392.000000   | 74.750000               | 4.576130      | 522.712436          | 6.992809             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 15.688623428344727, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 12.238024711608887, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.902695655822754, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 4.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0] | 19.463417                   | 1.000000         | 8.718750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:50:39,855][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 07:50:39,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:50:39,949][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 07:50:39,975][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:50:40,027][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:50:40,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 07:50:40,087][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 07:50:40,527][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 07:50:40,664][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:50:40,755][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 07:50:40,778][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:50:40,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:50:40,843][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 07:50:40,884][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 07:50:40,951][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 07:50:41,400][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:50:41,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 07:50:41,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:50:41,710][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 07:50:41,843][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:50:41,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 07:50:41,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 07:50:42,179][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 07:50:42,536][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:50:42,571][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 07:50:42,585][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:50:42,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 07:50:42,834][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:50:42,852][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:50:42,852][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:50:43,278][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:50:43,486][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 07:50:43,487][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 63000.000000 | iteration_63000.pth.tar | 32.000000     | 2313.000000   | 72.281250               | 4.440780      | 520.854470          | 7.205942             | 0.843750    | 0.363092   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 14.396707534790039, 20.0, 16.365270614624023, 20.0, 16.910181045532227, 20.0, 20.0, 20.0, 20.0, 20.0, 9.18413257598877, 20.0, 10.862276077270508, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 1.0, 0.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 7.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 4.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 18.991205                   | 1.437500         | 8.531250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 07:57:20,372][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 07:57:20,385][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 07:57:20,398][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 07:57:20,398][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 07:57:20,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 07:57:20,521][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 07:57:20,692][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 07:57:21,230][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 07:57:21,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 07:57:21,321][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 07:57:21,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 07:57:21,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 07:57:22,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 07:57:22,261][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 07:57:22,304][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 07:57:22,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 07:57:22,551][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 07:57:22,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 07:57:23,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 07:57:23,081][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 07:57:23,081][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 07:57:23,108][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 07:57:23,135][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 07:57:23,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 07:57:23,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 07:57:23,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 07:57:23,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 07:57:23,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 07:57:23,895][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:57:23,936][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 07:57:23,936][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:57:23,999][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:57:24,250][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:57:24,250][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:57:24,808][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 07:57:24,887][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 07:57:24,887][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 07:57:24,888][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 64000.000000 | iteration_64000.pth.tar | 32.000000     | 2741.000000   | 85.656250               | 5.445963      | 503.308608          | 5.875912             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.723054885864258, 20.0, 20.0, 20.0, 16.865270614624023, 20.0, 20.0, 16.65868377685547, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 15.688623428344727, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 2.0, 2.0, 0.0, 8.0, 0.0, 0.0, 7.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 1.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0] | 19.560489                   | 1.250000         | 8.875000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:03:23,240][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 08:03:23,266][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 08:03:23,293][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:03:23,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 08:03:23,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:03:23,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:03:23,350][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 08:03:24,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 08:03:24,206][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:03:24,256][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 08:03:24,269][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:03:24,310][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:03:25,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 08:03:25,081][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 08:03:25,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 08:03:25,223][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 08:03:25,291][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 08:03:25,533][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:03:25,919][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:03:25,969][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 08:03:25,982][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 08:03:26,004][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 08:03:26,114][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 08:03:26,168][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:03:26,325][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 08:03:26,750][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:03:26,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 08:03:26,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:03:27,127][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:03:27,191][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:03:27,387][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:03:27,700][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:03:27,733][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:03:27,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 08:03:27,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:03:28,035][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:03:28,096][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 08:03:28,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:03:28,453][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 08:03:28,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:03:28,524][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:03:28,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:03:28,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:03:28,924][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:03:28,936][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:03:29,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:03:29,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 08:03:29,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 08:03:29,563][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 65000.000000 | iteration_65000.pth.tar | 32.000000     | 3714.000000   | 116.062500              | 7.119324      | 521.678763          | 4.494809             | 0.843750    | 0.363092   | 1.000000   | 0.000000   | [20.0, 20.0, 14.173653602600098, 20.0, 20.0, 20.0, 20.0, 16.562875747680664, 16.65718650817871, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.700599670410156, 13.926647186279297, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 8.0, 3.0, 0.0, 3.0, 0.0, 6.0, 8.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 7.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.281905                   | 1.437500         | 8.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:09:29,492][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 08:09:29,584][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 08:09:29,598][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:09:29,612][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 08:09:29,628][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:09:29,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:09:29,849][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 08:09:30,423][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 08:09:30,455][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:09:30,538][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 08:09:30,598][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:09:30,665][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:09:30,694][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 08:09:31,227][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 08:09:31,402][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 08:09:31,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 08:09:31,468][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 08:09:31,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:09:31,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:09:31,687][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 08:09:31,739][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 08:09:32,166][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 08:09:32,320][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 08:09:32,320][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:09:32,364][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 08:09:32,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:09:32,526][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 08:09:32,572][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:09:32,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:09:32,955][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:09:33,154][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:09:33,169][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:09:33,196][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:09:33,445][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:09:33,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:09:33,709][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:09:34,140][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:09:34,194][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 08:09:34,300][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:09:34,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:09:34,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 08:09:34,372][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 66000.000000 | iteration_66000.pth.tar | 32.000000     | 2880.000000   | 90.000000               | 5.796012      | 496.893363          | 5.521037             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 16.842815399169922, 20.0, 20.0, 20.0, 20.0, 16.071857452392578, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.528443336486816, 20.000001907348633, 20.0] | [0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 1.0, 1.0] | [9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0] | 19.576348                   | 0.937500         | 8.843750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:15:33,287][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 08:15:33,299][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 08:15:33,310][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:15:33,335][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 08:15:33,349][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:15:33,425][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:15:33,469][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 08:15:34,091][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 08:15:34,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:15:34,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 08:15:34,235][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:15:34,273][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:15:34,273][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 08:15:34,285][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 08:15:34,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 08:15:35,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 08:15:35,192][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 08:15:35,272][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:15:35,287][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:15:35,302][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 08:15:35,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 08:15:35,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 08:15:35,932][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 08:15:36,194][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:15:36,225][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 08:15:36,225][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:15:36,254][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 08:15:36,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:15:37,002][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:15:37,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:15:37,050][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:15:37,061][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:15:37,158][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:15:37,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:15:37,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 08:15:37,893][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 08:15:37,979][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:15:38,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:15:38,099][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:15:38,160][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:15:38,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:15:38,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:15:38,679][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 08:15:38,680][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 67000.000000 | iteration_67000.pth.tar | 32.000000     | 3158.000000   | 98.687500               | 6.396178      | 493.732371          | 5.002988             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 15.688623428344727, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.58682632446289, 15.113773345947266, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 5.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 6.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.471183                   | 1.156250         | 8.843750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:21:34,928][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 08:21:34,978][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 08:21:34,978][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:21:34,990][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 08:21:35,001][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:21:35,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:21:35,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 08:21:35,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 08:21:35,866][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:21:35,893][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 08:21:35,931][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:21:35,931][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:21:35,941][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 08:21:35,953][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 08:21:36,010][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 08:21:36,217][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 08:21:36,866][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 08:21:36,890][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:21:36,900][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:21:36,922][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 08:21:36,957][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 08:21:36,981][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 08:21:36,992][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 08:21:37,240][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:21:37,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 08:21:37,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:21:37,743][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 08:21:37,767][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:21:37,791][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:21:37,791][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:21:37,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:21:38,037][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 08:21:38,039][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 68000.000000 | iteration_68000.pth.tar | 32.000000     | 2057.000000   | 64.281250               | 4.026896      | 510.815341          | 7.946568             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.344311714172363, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.854510                   | 0.343750         | 8.937500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:27:36,166][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 08:27:36,194][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 08:27:36,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:27:36,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 08:27:36,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:27:36,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:27:36,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 08:27:36,400][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 08:27:37,036][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:27:37,079][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 08:27:37,079][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:27:37,104][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:27:37,104][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 08:27:37,160][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 08:27:37,199][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 08:27:37,225][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 08:27:38,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 08:27:38,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:27:38,140][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:27:38,167][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 08:27:38,167][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 08:27:38,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 08:27:38,274][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 08:27:38,371][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:27:38,914][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 08:27:38,958][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:27:39,027][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 08:27:39,041][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:27:39,041][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:27:39,107][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:27:39,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:27:39,317][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 08:27:39,318][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 69000.000000 | iteration_69000.pth.tar | 32.000000     | 2057.000000   | 64.281250               | 3.950243      | 520.727437          | 8.100767             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [15.687126159667969, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.405689239501953, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.690401                   | 0.593750         | 8.812500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:34:12,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 08:34:12,045][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 08:34:12,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:34:12,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 08:34:12,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:34:12,207][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:34:12,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 08:34:12,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 08:34:12,855][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:34:12,903][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 08:34:12,914][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:34:12,925][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:34:12,966][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 08:34:13,139][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 08:34:13,154][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 08:34:13,247][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 08:34:13,901][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 08:34:13,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:34:13,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:34:14,120][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 08:34:14,316][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 08:34:14,316][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 08:34:14,381][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 08:34:14,838][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:34:14,855][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 08:34:15,071][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:34:15,084][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 08:34:15,294][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:34:15,308][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:34:15,663][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 08:34:15,954][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:34:15,971][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:34:16,095][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 08:34:16,355][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:34:16,536][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:34:16,631][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:34:16,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 08:34:16,849][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 70000.000000 | iteration_70000.pth.tar | 32.000000     | 2772.000000   | 86.625000               | 5.721526      | 484.486101          | 5.592913             | 0.812500    | 0.390312   | 1.000000   | 0.000000   | [14.426647186279297, 13.562874794006348, 20.0, 16.176647186279297, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.844311714172363, 20.0, 20.0, 13.226048469543457, 20.0, 15.688623428344727, 20.0] | [8.0, 8.0, 0.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 5.0, 0.0] | [7.0, 5.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 4.0, 9.0, 9.0, 5.0, 9.0, 8.0, 9.0] | 18.872661                   | 1.593750         | 8.468750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:41:41,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 08:41:41,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 08:41:42,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:41:42,024][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 08:41:42,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:41:42,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:41:42,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 08:41:42,896][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 08:41:42,973][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:41:42,973][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 08:41:43,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:41:43,070][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:41:43,070][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 08:41:43,070][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 08:41:44,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 08:41:44,287][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 08:41:44,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 08:41:44,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:41:44,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:41:44,382][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 08:41:45,124][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 08:41:45,257][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 08:41:45,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 08:41:45,348][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:41:45,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 08:41:45,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:41:45,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 08:41:45,467][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 08:41:45,934][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:41:46,045][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:41:46,114][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 08:41:46,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:41:46,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:41:46,174][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:41:46,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:41:46,734][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 08:41:47,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 08:41:47,065][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 71000.000000 | iteration_71000.pth.tar | 32.000000     | 2884.000000   | 90.125000               | 6.139642      | 469.734259          | 5.212031             | 0.781250    | 0.413399   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 15.017964363098145, 20.0, 20.0, 16.085329055786133, 20.0, 20.0, 20.0, 20.0, 20.0, 16.426647186279297, 11.351797103881836, 20.0, 20.0, 11.169161796569824, 20.0, 20.0, 20.0, 12.4970064163208, 20.0, 20.0, 20.0, 20.0, 14.528443336486816, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 1.0, 8.0, 0.0, 1.0, 1.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 3.0, 9.0, 9.0, 5.0, 9.0, 9.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0] | 18.658636                   | 1.843750         | 8.343750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:48:20,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 08:48:20,983][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 08:48:21,035][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:48:21,035][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 08:48:21,086][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:48:21,086][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:48:21,110][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 08:48:21,786][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 08:48:21,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:48:21,918][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 08:48:21,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:48:21,968][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:48:22,593][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 08:48:22,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 08:48:22,817][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 08:48:22,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 08:48:22,966][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 08:48:22,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:48:23,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:48:24,664][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 08:48:24,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 08:48:25,080][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 08:48:25,113][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 08:48:25,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:48:25,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 08:48:25,382][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:48:26,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 08:48:26,421][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:48:26,571][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:48:26,678][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:48:26,714][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:48:26,725][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:48:26,775][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:48:26,990][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:48:27,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:48:27,429][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:48:27,618][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:48:27,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:48:27,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:48:27,712][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:48:27,947][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:48:28,351][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 08:48:28,641][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 08:48:28,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:28,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:28,808][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:28,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:29,007][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:29,483][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:29,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 08:48:29,570][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:29,645][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:29,669][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:48:29,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 08:48:29,746][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 72000.000000 | iteration_72000.pth.tar | 32.000000     | 3939.000000   | 123.093750              | 9.957286      | 395.589717          | 3.213727             | 0.812500    | 0.390312   | 1.000000   | 0.000000   | [16.778444290161133, 20.0, 16.63473129272461, 16.062875747680664, 20.0, 20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 16.30838394165039, 20.0, 20.0, 20.0, 20.0, 20.0, 15.175150871276855, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [6.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [8.0, 9.0, 8.0, 8.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.270257                   | 1.500000         | 8.718750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 08:54:53,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 08:54:53,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 08:54:53,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 08:54:53,675][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 08:54:53,675][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 08:54:53,686][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 08:54:53,729][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 08:54:53,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 08:54:54,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 08:54:54,590][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 08:54:54,590][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 08:54:54,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 08:54:54,643][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 08:54:54,658][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 08:54:54,689][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 08:54:54,741][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 08:54:55,541][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 08:54:55,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 08:54:55,915][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 08:54:56,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 08:54:56,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 08:54:56,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 08:54:56,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 08:54:56,199][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 08:54:56,812][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 08:54:56,941][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 08:54:56,941][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 08:54:56,967][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 08:54:56,979][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 08:54:57,004][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 08:54:57,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:54:57,667][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:54:57,835][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:54:57,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:54:57,861][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:54:57,873][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:54:57,884][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:54:57,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 08:54:58,074][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 08:54:58,075][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 73000.000000 | iteration_73000.pth.tar | 32.000000     | 2481.000000   | 77.531250               | 5.495729      | 451.441474          | 5.822703             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.865270                   | 0.406250         | 8.968750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:01:42,364][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:01:42,378][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:01:42,463][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:01:42,463][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:01:42,478][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:01:42,478][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:01:42,579][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:01:43,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:01:43,396][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 09:01:43,427][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:01:43,494][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:01:43,508][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:01:43,536][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:01:43,567][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 09:01:43,608][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 09:01:44,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 09:01:44,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:01:44,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:01:44,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:01:44,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:01:44,833][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:01:44,833][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:01:44,873][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:01:45,390][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:01:45,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:01:45,511][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:01:45,537][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:01:45,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:01:45,657][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:01:45,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:01:45,831][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:01:46,302][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 09:01:46,411][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:01:46,577][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:01:46,669][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 09:01:46,670][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 74000.000000 | iteration_74000.pth.tar | 32.000000     | 2381.000000   | 74.406250               | 5.255695      | 453.032392          | 6.088634             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 12.390719413757324, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.667665481567383] | [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0] | 19.564325                   | 0.656250         | 8.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:08:18,927][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:08:18,978][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:08:19,010][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:08:19,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:08:19,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:08:19,059][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:08:19,170][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:08:19,252][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:08:19,942][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 09:08:19,968][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:08:19,979][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:08:20,002][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:08:20,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:08:20,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:08:20,204][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 09:08:20,572][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 09:08:20,753][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:08:20,807][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:08:20,831][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:08:20,908][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:08:20,935][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:08:21,000][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:08:21,561][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:08:21,615][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:08:21,708][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 09:08:21,793][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:08:21,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 09:08:22,053][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:08:22,081][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:08:22,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:08:22,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:08:22,982][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:08:23,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:08:23,091][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:08:23,266][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:08:23,643][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:08:23,683][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:08:23,825][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 09:08:23,827][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 75000.000000 | iteration_75000.pth.tar | 32.000000     | 2843.000000   | 88.843750               | 5.959673      | 477.039608          | 5.369422             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.410181045532227, 20.0, 20.000001907348633, 16.453594207763672, 14.601797103881836, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.83832359313965, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.000001907348633, 20.0] | [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 8.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.509497                   | 1.000000         | 8.812500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:14:37,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:14:37,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:14:37,615][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:14:37,615][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:14:37,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:14:37,804][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:14:37,851][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:14:38,548][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:14:38,604][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 09:14:38,672][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:14:38,672][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:14:38,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:14:39,008][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:14:39,053][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:14:39,589][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 09:14:39,639][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 09:14:39,651][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:14:39,675][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:14:39,764][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:14:39,775][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:14:39,869][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:14:39,897][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:14:40,461][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:14:40,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:14:40,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:14:40,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:14:40,676][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:14:40,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:14:40,748][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:14:40,803][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:14:41,353][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:14:41,388][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:14:41,438][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:14:41,505][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:14:41,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:14:41,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:14:41,703][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:14:42,418][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:14:42,434][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 09:14:42,435][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 76000.000000 | iteration_76000.pth.tar | 32.000000     | 2738.000000   | 85.562500               | 5.781625      | 473.569322          | 5.534777             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.02395248413086, 20.0, 20.000001907348633, 20.0] | [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0] | 19.813249                   | 0.343750         | 8.937500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:20:54,850][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:20:54,922][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:20:54,923][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:20:54,980][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:20:54,981][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:20:55,009][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:20:55,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:20:55,058][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:20:55,912][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 09:20:55,966][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:20:56,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:20:56,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:20:56,120][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:20:56,133][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:20:56,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 09:20:56,243][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 09:20:57,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:20:57,103][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:20:57,103][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:20:57,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:20:57,424][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:20:57,474][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:20:57,487][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:20:57,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:20:58,290][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:20:58,331][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:20:58,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:20:58,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:20:58,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:20:58,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:20:58,600][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:20:59,154][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:20:59,177][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:20:59,240][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:20:59,266][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:20:59,277][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:20:59,368][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:20:59,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 09:20:59,861][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 77000.000000 | iteration_77000.pth.tar | 32.000000     | 2723.000000   | 85.093750               | 6.000653      | 453.783959          | 5.332753             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 16.850299835205078, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 7.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.901572                   | 0.406250         | 8.968750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:27:13,199][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:27:13,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:27:13,330][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:27:13,330][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:27:13,330][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:27:13,341][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:27:13,341][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:27:13,403][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:27:13,905][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 09:27:14,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:27:14,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:27:14,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:27:14,453][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:27:14,470][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:27:14,499][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 09:27:14,725][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 09:27:15,027][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:27:15,295][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:27:15,307][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:27:15,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:27:15,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:27:15,371][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:27:15,421][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:27:15,688][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:27:16,087][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:27:16,219][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:27:16,254][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:27:16,254][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:27:16,315][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:27:16,344][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:27:16,497][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:27:16,602][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 09:27:16,603][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 78000.000000 | iteration_78000.pth.tar | 32.000000     | 2089.000000   | 65.281250               | 4.274767      | 488.681595          | 7.485788             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 12.131736755371094, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 3.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.754117                   | 0.531250         | 8.812500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:33:37,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:33:37,972][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 09:33:38,009][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:33:38,021][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:33:38,021][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:33:38,060][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:33:38,074][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:33:38,089][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:33:38,889][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 09:33:38,987][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:33:39,001][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:33:39,014][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:33:39,014][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 09:33:39,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:33:39,039][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 09:33:39,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 09:33:39,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:33:39,948][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:33:40,011][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:33:40,023][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:33:40,033][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:33:40,045][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:33:40,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:33:40,105][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:33:40,803][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:33:40,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:33:40,984][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:33:41,000][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:33:41,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:33:41,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 09:33:41,075][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:33:41,152][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 09:33:41,154][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 79000.000000 | iteration_79000.pth.tar | 32.000000     | 1985.000000   | 62.031250               | 4.395867      | 451.560503          | 7.279565             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.17215633392334, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 12.450599670410156, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.363773345947266, 20.0, 20.0, 20.0, 13.113773345947266, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 3.0, 9.0, 9.0] | 19.159385                   | 1.156250         | 8.500000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:40:01,329][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:40:01,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:40:01,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:40:01,393][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:40:01,424][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:40:01,425][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:40:01,454][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:40:01,468][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:40:02,258][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 09:40:02,269][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:40:02,292][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:40:02,315][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:40:02,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:40:02,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:40:02,363][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 09:40:02,601][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 09:40:03,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:40:03,419][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:40:03,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:40:03,469][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:40:03,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:40:03,663][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:40:04,170][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:40:04,328][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 09:40:04,353][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:40:04,353][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:40:04,393][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:40:04,525][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:40:04,626][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:40:05,101][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 09:40:05,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:40:05,169][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:40:05,279][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:40:05,279][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:40:05,326][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:40:05,389][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:40:05,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:40:06,249][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 09:40:06,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 09:40:06,276][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 80000.000000 | iteration_80000.pth.tar | 32.000000     | 2730.000000   | 85.312500               | 6.018844      | 453.575453          | 5.316635             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [14.613773345947266, 20.0, 20.0, 20.0, 20.0, 20.0, 15.688623428344727, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 12.736527442932129, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.730539321899414, 20.0, 20.0, 20.000001907348633, 20.000001907348633, 20.0] | [8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0] | [7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 3.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.367796                   | 1.156250         | 8.687500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:46:18,865][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:46:18,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:46:18,910][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:46:18,923][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:46:18,939][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:46:18,939][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:46:19,020][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:46:19,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:46:19,975][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 09:46:19,975][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:46:20,005][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:46:20,005][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:46:20,255][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:46:20,337][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:46:20,636][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 09:46:20,820][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 09:46:20,860][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:46:20,885][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 09:46:20,885][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:46:21,217][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 09:46:21,273][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:46:21,472][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:46:21,712][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:46:21,969][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:46:21,994][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:46:22,004][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:46:22,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:46:22,393][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:46:22,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:46:22,943][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:46:23,003][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:46:23,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:46:23,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 09:46:23,313][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:46:23,604][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 09:46:23,618][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:46:23,819][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:46:23,939][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 09:46:23,940][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                            | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 81000.000000 | iteration_81000.pth.tar | 32.000000     | 2939.000000   | 91.843750               | 6.179753      | 475.585319          | 5.178200             | 0.812500    | 0.390312   | 1.000000   | 0.000000   | [20.0, 15.708084106445312, 20.000001907348633, 20.0, 15.988024711608887, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.59880256652832, 20.0, 20.0, 20.0, 20.0, 20.0, 12.968563079833984, 20.0, 20.0, 20.0, 20.0, 20.0, 15.556886672973633, 20.0, 20.0, 20.0, 14.766468048095703, 20.0, 20.0, 20.0, 20.0] | [0.0, 8.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 7.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 3.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0] | 19.112088                   | 1.406250         | 8.562500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:52:34,677][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:52:34,756][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:52:34,757][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:52:34,757][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:52:34,769][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:52:34,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:52:34,860][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:52:35,759][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:52:35,819][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 09:52:35,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:52:35,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:52:35,868][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:52:35,939][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:52:36,080][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:52:36,622][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 09:52:36,697][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 09:52:36,728][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:52:36,739][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:52:36,739][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:52:36,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:52:37,106][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:52:37,530][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 09:52:37,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:52:37,558][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:52:37,574][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:52:37,674][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:52:37,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:52:38,195][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:52:38,528][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 09:52:38,545][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:52:38,574][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:52:38,628][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:52:38,639][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:52:38,650][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:52:38,780][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:52:39,223][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:52:39,785][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:39,801][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:39,801][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:39,876][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:39,974][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:40,332][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:40,698][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:40,698][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:40,712][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:40,789][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:41,001][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 09:52:41,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:52:41,335][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 09:52:41,337][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 82000.000000 | iteration_82000.pth.tar | 32.000000     | 3632.000000   | 113.500000              | 7.542026      | 481.568223          | 4.242892             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [11.967066764831543, 20.0, 20.0, 15.92215633392334, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.137724876403809, 15.441617012023926, 20.0, 20.0, 20.0, 20.0] | [8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 0.0, 0.0] | [4.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 7.0, 9.0, 9.0, 9.0, 9.0] | 19.327143                   | 1.156250         | 8.656250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 09:58:50,438][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 09:58:50,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 09:58:50,458][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 09:58:50,459][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 09:58:50,494][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 09:58:50,494][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 09:58:50,505][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 09:58:50,505][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 09:58:51,644][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 09:58:51,644][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 09:58:51,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 09:58:51,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 09:58:51,703][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 09:58:51,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 09:58:51,782][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 09:58:52,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 09:58:52,529][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 09:58:52,566][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 09:58:52,598][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 09:58:52,598][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 09:58:52,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 09:58:52,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 09:58:52,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 09:58:53,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 09:58:53,645][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 09:58:53,656][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 09:58:53,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 09:58:53,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 09:58:53,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 09:58:53,813][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 09:58:54,199][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:54,485][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:54,526][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:54,537][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:54,577][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:54,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:54,646][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:55,347][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:55,347][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 09:58:55,371][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 09:58:55,372][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 83000.000000 | iteration_83000.pth.tar | 32.000000     | 2817.000000   | 88.031250               | 5.799033      | 485.770628          | 5.518161             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 15.386228561401367, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.721089                   | 0.531250         | 8.906250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:05:09,453][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 10:05:09,482][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 10:05:09,495][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:05:09,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:05:09,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:05:09,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:05:09,555][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:05:10,775][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 10:05:10,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:05:10,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:05:10,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:05:10,838][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:05:10,838][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:05:10,852][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:05:11,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 10:05:11,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 10:05:11,763][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:05:11,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:05:11,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:05:11,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:05:11,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:05:11,909][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:05:12,579][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 10:05:12,698][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:05:12,728][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 10:05:12,740][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 10:05:12,752][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:05:12,798][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:05:12,798][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:05:12,812][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:05:13,714][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:05:13,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:05:13,884][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:05:13,898][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:05:13,898][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:05:13,925][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:05:13,925][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:05:14,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:05:14,835][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:05:14,837][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 84000.000000 | iteration_84000.pth.tar | 32.000000     | 2746.000000   | 85.812500               | 6.237162      | 440.264330          | 5.130538             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [13.461078643798828, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0] | [6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.795659                   | 0.343750         | 8.906250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:11:26,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 10:11:26,459][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 10:11:26,486][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:11:26,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:11:26,533][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:11:26,533][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:11:26,665][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:11:26,665][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 10:11:27,423][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:11:27,454][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:11:27,482][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:11:27,497][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:11:27,610][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:11:27,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:11:27,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 10:11:27,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 10:11:28,293][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:11:28,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:11:28,733][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:11:28,812][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:11:28,860][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:11:28,874][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:11:29,241][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 10:11:29,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:11:29,475][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 10:11:29,526][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 10:11:29,604][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:11:29,630][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:11:29,641][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:11:29,641][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:11:30,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:11:30,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:11:30,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:11:30,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:11:30,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:11:30,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:11:30,437][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 85000.000000 | iteration_85000.pth.tar | 32.000000     | 2367.000000   | 73.968750               | 5.111644      | 463.060413          | 6.260217             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.887724876403809, 20.0, 15.227545738220215, 20.0, 20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 9.0, 7.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.462622                   | 0.906250         | 8.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:18:23,219][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 10:18:23,230][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 10:18:23,241][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:18:23,241][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:18:23,251][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:18:23,260][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:18:23,324][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:18:23,352][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 10:18:24,120][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:18:24,131][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:18:24,131][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:18:24,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:18:24,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:18:24,224][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:18:24,267][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 10:18:24,295][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 10:18:25,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:18:25,368][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:18:25,394][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:18:25,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:18:25,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:18:25,447][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:18:25,458][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 10:18:25,495][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:18:26,293][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 10:18:26,305][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 10:18:26,345][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:18:26,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:18:26,450][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:18:26,463][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:18:26,550][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:18:26,631][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 10:18:26,633][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 86000.000000 | iteration_86000.pth.tar | 32.000000     | 2009.000000   | 62.781250               | 4.473823      | 449.056682          | 7.152720             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.299402236938477, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.884356                   | 0.468750         | 8.937500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:24:36,102][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 10:24:36,154][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 10:24:36,166][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:24:36,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:24:36,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:24:36,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:24:36,280][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:24:36,482][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 10:24:36,991][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:24:37,008][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:24:37,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:24:37,062][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:24:37,111][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:24:37,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:24:37,239][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 10:24:37,443][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 10:24:37,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:24:37,934][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:24:37,964][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:24:37,964][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:24:37,978][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:24:38,232][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:24:38,247][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 10:24:38,570][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:24:39,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 10:24:39,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 10:24:39,253][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:24:39,265][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:24:39,450][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:24:39,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:24:39,634][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:24:39,704][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:24:39,705][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 87000.000000 | iteration_87000.pth.tar | 32.000000     | 1977.000000   | 61.781250               | 4.520139      | 437.375915          | 7.079428             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 12.155689239501953, 20.0, 20.0, 20.0, 15.616766929626465, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.000001907348633, 20.0] | [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 4.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.617889                   | 0.656250         | 8.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:30:47,295][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 10:30:47,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 10:30:47,335][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:30:47,346][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:30:47,346][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:30:47,346][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:30:47,359][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:30:47,359][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 10:30:48,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:30:48,192][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:30:48,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:30:48,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:30:48,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:30:48,288][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:30:48,326][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 10:30:49,204][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 10:30:49,259][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:30:49,259][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:30:49,287][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:30:49,287][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:30:49,404][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:30:49,481][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:30:50,040][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 10:30:50,078][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:30:50,078][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 10:30:50,113][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 10:30:50,113][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:30:50,123][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:30:50,200][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:30:50,225][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:30:50,995][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:30:50,995][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:30:51,007][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:30:51,019][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:30:51,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:30:51,083][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 10:30:51,498][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:30:51,498][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 10:30:52,537][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:30:52,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:30:52,624][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:30:52,625][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 88000.000000 | iteration_88000.pth.tar | 32.000000     | 2777.000000   | 86.781250               | 6.314572      | 439.776456          | 5.067644             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.179641723632812, 20.0, 20.0, 20.0, 20.0, 20.0, 15.595808982849121, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.574851036071777] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 8.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0] | 19.604697                   | 0.843750         | 8.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:36:58,499][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 10:36:58,608][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 10:36:58,608][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:36:58,632][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:36:58,632][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:36:58,658][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:36:58,658][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:36:58,669][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 10:36:59,305][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:36:59,409][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:36:59,447][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:36:59,447][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:36:59,459][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:36:59,469][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:36:59,496][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 10:36:59,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 10:37:00,366][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:37:00,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:37:00,539][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:37:00,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:37:00,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:37:00,583][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:37:00,598][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 10:37:00,656][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:37:01,421][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 10:37:01,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 10:37:01,556][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:37:01,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:37:01,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:37:01,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:37:01,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:37:01,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:37:01,582][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 89000.000000 | iteration_89000.pth.tar | 32.000000     | 1890.000000   | 59.062500               | 3.845464      | 491.488170          | 8.321493             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.395210266113281, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 3.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.731100                   | 0.375000         | 8.812500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:43:07,980][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 10:43:07,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 10:43:07,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:43:07,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:43:08,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:43:08,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:43:08,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:43:09,325][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 10:43:09,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:43:09,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:43:09,412][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:43:09,466][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:43:09,478][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:43:09,522][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:43:10,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 10:43:10,334][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 10:43:10,363][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:43:10,363][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:43:10,394][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:43:10,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:43:10,447][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:43:10,484][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:43:11,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 10:43:11,181][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:43:11,192][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 10:43:11,192][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 10:43:11,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:43:11,256][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:43:11,256][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:43:11,284][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:43:11,953][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:43:12,053][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:43:12,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:43:12,120][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:43:12,135][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:43:12,136][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:43:12,152][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:43:12,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:43:13,011][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:43:13,013][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 90000.000000 | iteration_90000.pth.tar | 32.000000     | 2706.000000   | 84.562500               | 6.067445      | 445.986714          | 5.274048             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.844311714172363, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.870135                   | 0.375000         | 8.968750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:49:16,520][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 10:49:16,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 10:49:16,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:49:16,541][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:49:16,541][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:49:16,594][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:49:16,605][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:49:16,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 10:49:17,332][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:49:17,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:49:17,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:49:17,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:49:17,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:49:17,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:49:17,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 10:49:17,797][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 10:49:18,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:49:18,505][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:49:18,517][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:49:18,529][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:49:18,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:49:18,580][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:49:18,675][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 10:49:18,752][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:49:19,420][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 10:49:19,445][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 10:49:19,468][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:49:19,468][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:49:19,479][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:49:19,560][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 10:49:19,608][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:49:19,793][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:49:19,794][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 91000.000000 | iteration_91000.pth.tar | 32.000000     | 2033.000000   | 63.531250               | 4.092921      | 496.711226          | 7.818376             | 1.000000    | 0.000000   | 1.000000   | 1.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 20.000000                   | 0.125000         | 9.000000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 10:55:23,782][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 10:55:23,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 10:55:23,804][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 10:55:23,828][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 10:55:23,828][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 10:55:23,838][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 10:55:23,892][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 10:55:23,905][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 10:55:24,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 10:55:24,767][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 10:55:24,767][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 10:55:24,778][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 10:55:24,817][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 10:55:24,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 10:55:24,898][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 10:55:25,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 10:55:25,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 10:55:25,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 10:55:25,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 10:55:25,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 10:55:25,688][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 10:55:25,864][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 10:55:25,974][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 10:55:26,219][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 10:55:26,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 10:55:26,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 10:55:26,586][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 10:55:26,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 10:55:26,814][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 10:55:26,814][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 10:55:26,814][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 10:55:27,006][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 10:55:27,008][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                            | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 92000.000000 | iteration_92000.pth.tar | 32.000000     | 2081.000000   | 65.031250               | 4.186223      | 497.106802          | 7.644122             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 8.669161796569824, 20.0, 20.0, 20.000001907348633, 11.889222145080566, 20.0, 20.000001907348633, 20.000001907348633, 20.0, 20.0, 16.627246856689453, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 8.0, 3.0, 1.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 3.0, 9.0, 9.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.287051                   | 1.031250         | 8.625000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:01:30,909][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:01:30,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:01:31,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:01:31,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:01:31,028][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:01:31,029][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:01:31,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:01:31,954][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 11:01:32,008][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:01:32,020][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 11:01:32,044][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:01:32,044][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:01:32,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:01:32,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:01:32,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 11:01:32,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:01:32,956][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:01:32,985][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:01:32,999][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:01:33,014][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:01:33,014][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:01:34,162][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:01:34,217][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:01:34,245][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:01:34,245][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 11:01:34,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 11:01:34,492][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 11:01:34,925][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 11:01:34,968][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 11:01:35,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:01:35,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:01:35,099][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:01:35,116][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:01:35,373][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:01:35,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:01:35,787][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:01:35,882][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:01:35,882][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:01:35,884][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 93000.000000 | iteration_93000.pth.tar | 32.000000     | 2756.000000   | 86.125000               | 5.795471      | 475.543732          | 5.521553             | 0.843750    | 0.363092   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 16.782934188842773, 20.0, 20.0, 20.0, 14.742515563964844, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 16.841318130493164, 20.0, 15.416168212890625, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 16.706586837768555, 20.0] | [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 1.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0] | 19.390298                   | 1.343750         | 8.750000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:07:43,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:07:43,605][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:07:43,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:07:43,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:07:43,665][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:07:43,707][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:07:43,732][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:07:44,394][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 11:07:44,473][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:07:44,488][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:07:44,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:07:44,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:07:44,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 11:07:44,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:07:44,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 11:07:45,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:07:45,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:07:45,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:07:45,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:07:45,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:07:45,804][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:07:45,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:07:46,298][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:07:46,434][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:07:46,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 11:07:46,574][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:07:46,614][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:07:46,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 11:07:46,836][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:07:47,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:07:47,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:07:47,605][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:07:47,652][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:07:47,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:07:47,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:07:47,897][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:07:48,142][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:07:48,498][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 11:07:48,498][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:48,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:48,593][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:48,606][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:48,766][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:48,834][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:49,159][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:49,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:49,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:49,499][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:07:49,545][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:07:49,548][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 94000.000000 | iteration_94000.pth.tar | 32.000000     | 3296.000000   | 103.000000              | 6.774241      | 486.548958          | 4.723776             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 16.86676788330078, 20.0, 20.0, 20.0, 15.988024711608887, 20.0, 16.41916275024414, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 1.0, 8.0, 1.0, 6.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 8.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.664811                   | 0.843750         | 8.906250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:14:05,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:14:05,767][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:14:05,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:14:05,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:14:05,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:14:05,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:14:05,831][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:14:05,864][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 11:14:06,665][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:14:06,691][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:14:06,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:14:06,731][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:14:06,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:14:06,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:14:06,789][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 11:14:06,918][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:14:07,657][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:14:07,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:14:07,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:14:07,720][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:14:07,765][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:14:07,824][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:14:07,824][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:14:07,854][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:14:08,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 11:14:08,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:14:08,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:14:08,823][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 11:14:08,850][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:14:08,909][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:14:08,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:14:09,024][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:14:09,026][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 95000.000000 | iteration_95000.pth.tar | 32.000000     | 1945.000000   | 60.781250               | 4.199530      | 463.147036          | 7.619900             | 1.000000    | 0.000000   | 1.000000   | 1.000000   | [20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 20.000000                   | 0.281250         | 9.000000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:20:19,270][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:20:19,281][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:20:19,313][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:20:19,326][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:20:19,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:20:19,349][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:20:19,361][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:20:19,372][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 11:20:20,390][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:20:20,423][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:20:20,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:20:20,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:20:20,556][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:20:20,596][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:20:21,114][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 11:20:21,191][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:20:21,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:20:21,314][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:20:21,459][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:20:21,593][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:20:21,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 11:20:22,460][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:20:22,460][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:20:22,592][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:20:22,652][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 11:20:22,772][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:20:22,952][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:20:23,235][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 11:20:23,497][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:20:23,552][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:20:23,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:20:23,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:20:23,828][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 11:20:23,828][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:20:24,376][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:20:24,771][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:20:25,056][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:20:25,126][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:20:25,194][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:20:25,195][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 96000.000000 | iteration_96000.pth.tar | 32.000000     | 2714.000000   | 84.812500               | 7.225111      | 375.634350          | 4.428997             | 0.875000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 15.986527442932129, 20.0, 20.0, 20.0, 20.0, 20.0, 16.874252319335938, 20.0, 20.0, 20.0, 20.0, 20.0, 16.00598907470703, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.363773345947266, 20.000001907348633, 20.0] | [0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0] | [9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0] | 19.538455                   | 1.093750         | 8.812500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:26:40,310][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:26:40,322][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:26:40,333][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:26:40,364][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:26:40,393][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:26:40,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:26:40,442][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:26:40,476][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 11:26:41,078][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:26:41,164][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:26:41,165][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:26:41,176][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:26:41,254][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:26:41,282][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:26:41,323][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 11:26:41,494][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:26:41,895][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:26:42,230][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:26:42,230][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:26:42,331][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:26:42,342][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:26:42,366][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:26:42,434][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:26:42,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:26:42,901][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 11:26:42,979][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:26:43,004][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:26:43,108][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 11:26:43,161][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:26:43,231][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:26:43,258][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:26:43,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 11:26:43,563][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 97000.000000 | iteration_97000.pth.tar | 32.000000     | 2073.000000   | 64.781250               | 4.468500      | 463.914116          | 7.161241             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 17.056886672973633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633] | [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.908028                   | 0.468750         | 8.937500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:33:30,812][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:33:30,812][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:33:30,823][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:33:30,852][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:33:30,864][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:33:30,889][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:33:31,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:33:31,109][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 11:33:31,620][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:33:31,646][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:33:31,831][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:33:31,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:33:31,862][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:33:31,907][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:33:32,054][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 11:33:32,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 11:33:32,843][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:33:32,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:33:32,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:33:32,872][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 11:33:32,920][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:33:32,973][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:33:33,024][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:33:33,037][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:33:33,757][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 11:33:33,769][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:33:33,769][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:33:33,791][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 11:33:34,008][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 11:33:34,008][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:33:34,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 11:33:34,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:34,893][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:34,907][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:34,907][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:35,122][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:35,122][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:35,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:35,657][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:35,724][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:35,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:33:35,835][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 11:33:35,837][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 98000.000000 | iteration_98000.pth.tar | 32.000000     | 2775.000000   | 86.718750               | 5.843474      | 474.888729          | 5.476194             | 0.843750    | 0.363092   | 1.000000   | 0.000000   | [20.0, 20.0, 20.000001907348633, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 11.700599670410156, 14.705090522766113, 20.0, 14.329341888427734, 20.0, 16.91317367553711, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.83832359313965, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 7.0, 9.0, 5.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.202704                   | 1.312500         | 8.625000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:39:38,160][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:39:38,196][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:39:38,207][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:39:38,207][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:39:38,233][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:39:38,256][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:39:38,964][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:39:38,975][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 11:39:38,975][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:39:38,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:39:39,028][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 11:39:39,041][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:39:39,098][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:39:39,140][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:39:39,890][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 11:39:39,971][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:39:40,030][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:39:40,043][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:39:40,043][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:39:40,151][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:39:40,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:39:40,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:39:40,909][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:39:40,950][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:39:40,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 11:39:40,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:39:41,074][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:39:41,167][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 11:39:41,201][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:39:41,265][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:39:41,866][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:39:41,881][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:39:41,927][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:39:41,974][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:39:42,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:39:42,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:39:42,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:39:42,070][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 99000.000000 | iteration_99000.pth.tar | 32.000000     | 2317.000000   | 72.406250               | 4.662160      | 496.979924          | 6.863771             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [16.992515563964844, 20.0, 20.0, 20.0, 16.532934188842773, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [8.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [8.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.797670                   | 0.625000         | 8.937500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:45:47,063][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 11:45:47,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:45:47,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:45:47,279][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:45:47,291][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:45:47,303][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:45:47,460][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:45:47,630][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 11:45:48,309][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:45:48,508][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:45:48,549][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:45:48,549][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:45:48,608][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:45:48,647][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:45:48,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 11:45:49,519][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:45:49,716][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:45:49,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:45:49,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:45:49,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:45:49,869][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:45:49,958][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:45:50,458][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:45:50,541][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 11:45:50,552][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 11:45:50,607][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:45:50,633][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:45:50,734][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 11:45:50,778][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:45:50,871][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:45:51,341][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:45:51,406][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:45:51,418][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:45:51,477][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:45:51,526][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:45:51,613][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:45:51,676][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:45:51,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:45:52,205][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:45:52,369][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:45:52,502][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:45:52,514][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:45:52,515][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 100000.000000 | iteration_100000.pth.tar | 32.000000     | 2767.000000   | 86.468750               | 6.233869      | 443.865624          | 5.133249             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.874252319335938, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.902321                   | 0.343750         | 8.968750          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:51:59,427][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:51:59,488][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:51:59,488][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:51:59,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:51:59,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:51:59,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:51:59,517][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 11:51:59,634][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 11:52:00,577][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:52:00,624][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:52:00,658][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:52:00,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:52:00,690][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:52:00,767][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:52:00,780][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 11:52:00,805][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:52:01,607][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:52:01,633][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:52:01,679][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:52:01,724][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:52:01,796][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:52:01,881][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:52:01,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:52:02,492][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:52:02,492][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 11:52:02,514][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:52:02,570][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:52:02,754][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 11:52:02,766][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:52:02,801][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:52:03,325][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:52:03,325][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:52:03,351][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:52:03,375][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:52:03,493][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 11:52:03,596][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:52:03,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:52:03,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:52:04,482][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:52:04,517][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:52:04,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:52:04,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:52:04,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 11:52:04,597][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 101000.000000 | iteration_101000.pth.tar | 32.000000     | 2775.000000   | 86.718750               | 5.994644      | 462.913224          | 5.338098             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 16.422157287597656, 20.0, 13.627245903015137, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.881736755371094, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 1.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0] | [9.0, 9.0, 7.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.591598                   | 0.843750         | 8.812500          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 11:58:16,414][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 11:58:16,414][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 11:58:16,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 11:58:16,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 11:58:16,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 11:58:16,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 11:58:16,484][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 11:58:16,592][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 11:58:17,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 11:58:17,353][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 11:58:17,467][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 11:58:17,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 11:58:17,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 11:58:17,534][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 11:58:17,545][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 11:58:17,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 11:58:18,549][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 11:58:18,592][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 11:58:18,605][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 11:58:18,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 11:58:18,631][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 11:58:18,643][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 11:58:18,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 11:58:18,792][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 11:58:19,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 11:58:19,458][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 11:58:19,485][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 11:58:19,509][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 11:58:19,534][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 11:58:19,645][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 11:58:19,721][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:58:20,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:58:20,307][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:58:20,374][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:58:20,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:58:20,510][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:58:20,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:58:21,566][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 11:58:21,613][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 11:58:21,614][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 102000.000000 | iteration_102000.pth.tar | 32.000000     | 2722.000000   | 85.062500               | 6.439144      | 422.726993          | 4.969605             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 15.257485389709473, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.851796                   | 0.250000         | 8.937500          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:04:32,678][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 12:04:32,831][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:04:32,861][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:04:32,872][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:04:32,886][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:04:32,912][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:04:32,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:04:33,030][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 12:04:33,754][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:04:33,924][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:04:33,935][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 12:04:33,935][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:04:33,958][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:04:33,959][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:04:33,959][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 12:04:34,009][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:04:34,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:04:34,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:04:34,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:04:34,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:04:34,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:04:34,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 12:04:34,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 12:04:34,837][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 12:04:35,382][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:04:35,545][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:04:35,556][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 12:04:35,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:04:35,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:04:35,609][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:04:35,636][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:04:35,648][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 12:04:35,649][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                    | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 103000.000000 | iteration_103000.pth.tar | 32.000000     | 1889.000000   | 59.031250               | 3.750653      | 503.645687          | 8.531849             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 9.035928726196289, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 12.199102401733398, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 3.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.413595                   | 0.593750         | 8.687500          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:10:45,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 12:10:45,684][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:10:45,697][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:10:45,711][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:10:45,722][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:10:45,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:10:45,799][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:10:45,799][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 12:10:46,614][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:10:46,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:10:46,648][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 12:10:46,658][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:10:46,659][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:10:46,710][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:10:46,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 12:10:46,912][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:10:47,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:10:47,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:10:47,840][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:10:47,840][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:10:47,870][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:10:47,883][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 12:10:48,044][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 12:10:48,122][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 12:10:48,686][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:10:48,771][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:10:48,800][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 12:10:48,889][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:10:48,903][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:10:49,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:10:49,076][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:49,613][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:49,882][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:49,908][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:49,951][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:50,037][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:50,096][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:50,265][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:50,798][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:50,849][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:10:50,923][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 12:10:50,925][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 104000.000000 | iteration_104000.pth.tar | 32.000000     | 2728.000000   | 85.250000               | 6.468548      | 421.732986          | 4.947014             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 11.856287956237793, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.745509                   | 0.250000         | 8.906250          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:17:05,445][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 12:17:05,458][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:17:05,508][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:17:05,523][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:17:05,523][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:17:05,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:17:05,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:17:05,579][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 12:17:06,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:17:06,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:17:06,385][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 12:17:06,386][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:17:06,400][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:17:06,466][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:17:06,480][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 12:17:06,584][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:17:07,119][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:17:07,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:17:07,272][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:17:07,283][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:17:07,312][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:17:07,326][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 12:17:07,339][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 12:17:07,419][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 12:17:07,978][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:17:08,047][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:17:08,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 12:17:08,099][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:17:08,111][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:17:08,185][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:17:08,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:17:08,224][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 12:17:08,225][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 105000.000000 | iteration_105000.pth.tar | 32.000000     | 1881.000000   | 58.781250               | 3.812232      | 493.411742          | 8.394033             | 1.000000    | 0.000000   | 1.000000   | 1.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 20.000000                   | 0.125000         | 9.000000          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:23:25,089][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 12:23:25,090][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:23:25,119][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:23:25,161][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:23:25,175][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:23:25,175][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:23:25,190][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:23:25,208][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 12:23:25,903][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:23:25,946][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:23:25,987][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 12:23:25,998][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:23:26,009][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:23:26,071][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:23:26,087][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 12:23:26,755][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:23:26,883][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:23:26,902][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:23:26,915][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:23:26,926][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:23:26,957][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:23:26,969][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 12:23:27,889][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 12:23:27,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 12:23:28,041][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:23:28,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:23:28,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 12:23:28,113][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:23:28,113][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:23:28,151][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:23:28,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:23:28,863][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:23:28,892][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:23:28,922][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:23:28,922][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:23:28,947][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:23:28,959][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:23:29,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:23:29,655][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:23:29,733][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:23:29,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:23:29,819][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:23:29,830][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 12:23:29,832][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 106000.000000 | iteration_106000.pth.tar | 32.000000     | 2734.000000   | 85.437500               | 5.844049      | 467.826305          | 5.475655             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 13.784431457519531, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.805764                   | 0.218750         | 8.937500          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:29:34,382][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 12:29:34,410][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:29:34,422][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:29:34,445][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:29:34,458][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:29:34,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:29:34,532][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:29:34,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 12:29:35,314][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:29:35,574][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:29:35,713][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 12:29:35,713][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:29:35,728][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:29:35,793][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:29:36,461][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 12:29:36,556][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:29:36,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:29:36,803][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:29:36,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:29:36,887][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:29:36,929][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:29:37,433][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 12:29:37,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 12:29:37,574][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 12:29:37,600][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:29:37,689][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:29:37,755][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 12:29:37,796][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:29:37,796][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:29:38,497][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:29:38,569][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:29:38,610][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:29:38,770][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:29:38,801][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:29:38,882][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:29:38,882][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:29:39,405][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:29:39,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 12:29:39,518][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 107000.000000 | iteration_107000.pth.tar | 32.000000     | 2723.000000   | 85.093750               | 5.992007      | 454.438697          | 5.340447             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.82036018371582, 20.0, 20.0, 16.18712615966797, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 1.0, 0.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.687734                   | 0.562500         | 8.843750          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:35:54,396][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 12:35:54,406][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:35:54,429][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:35:54,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:35:54,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:35:54,430][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:35:54,452][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:35:54,462][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 12:35:55,233][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:35:55,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:35:55,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 12:35:55,269][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:35:55,304][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:35:55,333][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:35:55,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 12:35:55,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:35:56,250][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:35:56,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:35:56,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:35:56,483][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:35:56,525][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:35:57,176][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 12:35:57,277][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 12:35:57,288][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 12:35:57,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:35:57,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:35:57,432][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 12:35:57,456][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:35:58,012][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:35:58,125][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 12:35:58,137][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:35:58,162][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:35:58,162][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:35:58,276][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:35:58,276][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:35:58,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:35:59,174][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:35:59,216][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:35:59,280][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:35:59,280][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 12:35:59,281][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                    | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 108000.000000 | iteration_108000.pth.tar | 32.000000     | 2714.000000   | 84.812500               | 5.772320      | 470.174878          | 5.543698             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.41167640686035, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.874252319335938, 20.0, 20.0, 20.0, 20.0, 13.970060348510742, 20.0] | [0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0] | 19.601750                   | 0.875000         | 8.875000          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:42:18,754][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 12:42:18,754][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:42:18,946][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:42:18,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:42:18,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:42:18,973][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:42:19,152][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:42:19,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 12:42:19,948][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:42:20,005][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:42:20,020][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 12:42:20,020][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:42:20,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:42:20,111][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:42:20,122][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 12:42:20,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:42:20,800][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:42:20,861][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:42:20,871][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:42:20,951][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:42:20,951][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:42:20,974][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 12:42:21,053][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 12:42:21,939][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 12:42:22,030][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:42:22,030][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:42:22,077][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 12:42:22,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:42:22,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:42:22,233][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:42:22,913][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:42:22,925][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 12:42:22,952][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:42:22,995][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:42:22,995][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:42:23,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:42:23,065][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:42:23,157][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:42:23,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 12:42:23,781][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 109000.000000 | iteration_109000.pth.tar | 32.000000     | 2674.000000   | 83.562500               | 6.079875      | 439.811674          | 5.263266             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 16.706586837768555, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.897081                   | 0.281250         | 8.968750          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:49:08,246][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 12:49:08,257][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:49:08,280][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:49:08,280][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:49:08,290][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:49:08,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:49:08,314][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:49:08,338][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 12:49:09,120][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:49:09,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:49:09,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 12:49:09,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:49:09,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:49:09,134][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:49:09,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 12:49:09,251][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:49:10,125][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:49:10,237][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:49:10,237][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:49:10,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:49:10,259][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:49:10,271][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 12:49:10,382][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 12:49:11,021][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 12:49:11,123][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:49:11,168][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:49:11,168][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 12:49:11,199][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:49:11,401][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:49:12,031][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:49:12,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:49:12,137][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 12:49:12,205][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:49:12,321][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:49:12,373][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:49:12,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:49:13,278][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:49:13,302][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:49:13,352][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 12:49:13,377][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:49:13,443][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 12:49:13,444][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 110000.000000 | iteration_110000.pth.tar | 32.000000     | 2816.000000   | 88.000000               | 6.385104      | 441.026489          | 5.011665             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.676647186279297, 20.0, 20.0, 20.0, 20.0, 11.005988121032715] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 5.0] | 19.521332                   | 0.406250         | 8.781250          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 12:55:17,614][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 12:55:17,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 12:55:17,663][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 12:55:17,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 12:55:17,712][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 12:55:17,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 12:55:17,733][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 12:55:17,793][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 12:55:18,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 12:55:18,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 12:55:18,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 12:55:18,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 12:55:18,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 12:55:18,833][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 12:55:18,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 12:55:18,918][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 12:55:19,622][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 12:55:19,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 12:55:19,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 12:55:19,743][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 12:55:19,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 12:55:19,849][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 12:55:19,849][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 12:55:19,874][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 12:55:20,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 12:55:20,537][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 12:55:20,552][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 12:55:20,587][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 12:55:20,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 12:55:20,637][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 12:55:20,710][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 12:55:20,826][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 12:55:20,827][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 111000.000000 | iteration_111000.pth.tar | 32.000000     | 1969.000000   | 61.531250               | 4.022404      | 489.508288          | 7.955442             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 15.035928726196289, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 12.895210266113281, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0] | [0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.622848                   | 0.562500         | 8.812500          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:01:26,000][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:01:26,001][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:01:26,036][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:01:26,077][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:01:26,077][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:01:26,089][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:01:26,089][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 13:01:26,100][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 13:01:26,808][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:01:26,870][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:01:26,895][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:01:26,895][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:01:26,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 13:01:26,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:01:26,921][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 13:01:26,948][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:01:27,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:01:27,709][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:01:27,709][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:01:27,720][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:01:27,771][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:01:27,782][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 13:01:27,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:01:27,832][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 13:01:28,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:01:28,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 13:01:28,871][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:01:28,903][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 13:01:28,903][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:01:28,931][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:01:28,988][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:01:29,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:01:29,016][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 112000.000000 | iteration_112000.pth.tar | 32.000000     | 1889.000000   | 59.031250               | 3.730820      | 506.322964          | 8.577202             | 1.000000    | 0.000000   | 1.000000   | 1.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 20.000000                   | 0.125000         | 9.000000          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:07:39,389][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:07:39,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:07:39,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:07:39,574][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:07:39,574][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:07:39,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:07:39,714][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 13:07:39,797][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 13:07:40,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:07:40,568][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:07:40,579][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:07:40,590][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:07:40,632][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 13:07:40,677][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:07:40,704][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 13:07:40,861][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:07:41,405][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:07:41,416][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:07:41,427][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:07:41,481][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:07:41,491][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:07:41,579][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 13:07:41,614][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:07:41,697][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 13:07:42,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:07:42,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 13:07:42,439][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:07:42,485][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 13:07:42,538][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:07:42,628][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:07:42,642][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:07:42,743][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:07:42,745][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 113000.000000 | iteration_113000.pth.tar | 32.000000     | 1961.000000   | 61.281250               | 4.222040      | 464.467463          | 7.579275             | 1.000000    | 0.000000   | 1.000000   | 1.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 20.000000                   | 0.000000         | 9.000000          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:13:50,054][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:13:50,079][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:13:50,079][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:13:50,090][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:13:50,090][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:13:50,101][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:13:50,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 13:13:50,174][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 13:13:51,558][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:13:51,558][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:13:51,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:13:51,615][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:13:51,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 13:13:51,677][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:13:51,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 13:13:51,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:13:52,412][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:13:52,437][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:13:52,437][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:13:52,791][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:13:52,805][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:13:52,805][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 13:13:52,817][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:13:53,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 13:13:53,501][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:13:53,571][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 13:13:53,603][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:13:53,616][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 13:13:53,647][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:13:53,688][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:13:54,340][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:13:54,350][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:13:54,390][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 13:13:54,464][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:13:54,529][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:13:54,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:13:54,608][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:13:54,691][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 13:13:55,533][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:13:55,533][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:13:55,576][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:13:55,586][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:13:55,588][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 114000.000000 | iteration_114000.pth.tar | 32.000000     | 2751.000000   | 85.968750               | 6.749224      | 407.602407          | 4.741286             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.928144454956055, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 14.625748634338379, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0] | [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.642309                   | 0.468750         | 8.875000          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:20:04,012][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:20:04,036][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:20:04,036][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:20:04,036][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:20:04,096][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:20:04,258][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:20:04,276][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 13:20:04,824][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 13:20:05,044][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:20:05,058][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:20:05,154][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:20:05,204][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:20:05,218][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 13:20:05,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:20:05,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 13:20:05,967][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:20:06,281][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:20:06,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:20:06,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:20:06,365][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:20:06,365][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:20:06,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 13:20:06,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:20:07,136][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 13:20:07,147][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:20:07,158][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 13:20:07,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:20:07,288][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 13:20:07,450][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:20:07,947][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:20:07,968][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:20:08,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:20:08,036][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:20:08,072][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:20:08,232][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:20:08,403][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 13:20:08,655][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:20:08,778][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:20:09,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:20:09,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:20:09,151][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:20:09,166][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 13:20:09,329][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:20:09,525][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:20:09,527][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 115000.000000 | iteration_115000.pth.tar | 32.000000     | 2998.000000   | 93.687500               | 6.365713      | 470.960606          | 5.026931             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.000001907348633, 20.0, 20.0, 20.0, 16.381736755371094, 20.0, 15.928144454956055, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 16.107784271240234, 20.000001907348633, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 8.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0] | 19.638052                   | 0.718750         | 8.875000          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:26:14,385][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:26:14,412][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:26:14,449][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:26:14,449][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:26:14,503][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:26:14,516][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:26:14,527][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 13:26:14,555][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 13:26:15,472][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:26:15,495][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:26:15,520][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:26:15,531][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:26:15,541][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 13:26:15,552][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:26:15,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 13:26:15,573][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:26:16,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:26:16,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:26:16,456][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:26:16,456][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:26:16,468][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:26:16,479][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 13:26:16,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:26:17,354][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 13:26:17,379][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:26:17,391][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 13:26:17,427][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:26:17,440][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 13:26:17,454][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:26:17,469][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:26:18,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:26:18,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 13:26:18,570][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:18,570][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:18,582][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:18,582][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:18,609][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:18,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:19,347][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:19,347][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:19,347][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:19,370][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:19,419][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:26:19,419][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:26:19,420][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 116000.000000 | iteration_116000.pth.tar | 32.000000     | 2766.000000   | 86.437500               | 5.842078      | 473.461659          | 5.477503             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.865269                   | 0.312500         | 8.968750          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:32:31,087][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:32:31,115][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:32:31,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:32:31,149][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:32:31,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:32:31,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:32:31,189][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 13:32:31,641][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 13:32:31,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:32:31,985][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:32:31,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:32:31,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:32:31,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 13:32:32,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:32:32,070][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 13:32:33,100][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:32:33,685][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:32:33,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:32:33,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:32:33,774][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:32:33,774][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:32:33,835][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 13:32:34,008][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:32:34,333][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 13:32:34,766][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:32:34,783][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 13:32:34,798][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:32:34,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 13:32:34,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:32:34,987][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:32:35,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:32:35,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:32:35,337][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 117000.000000 | iteration_117000.pth.tar | 32.000000     | 2065.000000   | 64.531250               | 5.046336      | 409.207795          | 6.341235             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.067365646362305, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.38473129272461, 20.0] | [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0] | 19.701628                   | 0.593750         | 8.843750          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:39:37,737][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:39:37,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:39:37,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:39:37,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:39:37,774][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:39:37,774][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:39:37,808][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 13:39:38,006][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 13:39:41,090][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:39:41,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:39:41,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:39:41,189][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:39:41,189][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 13:39:41,230][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:39:41,231][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 13:39:41,293][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:39:42,701][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:39:42,701][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:39:42,712][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:39:42,843][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:39:42,843][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:39:42,866][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 13:39:42,905][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:39:42,945][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 13:39:44,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:39:44,756][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 13:39:44,757][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:39:44,757][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 13:39:44,955][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:39:44,955][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:39:44,969][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:39:45,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:39:45,449][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 118000.000000 | iteration_118000.pth.tar | 32.000000     | 1937.000000   | 60.531250               | 11.163084     | 173.518358          | 2.866591             | 0.968750    | 0.173993   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 12.917665481567383, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.778677                   | 0.343750         | 8.906250          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:49:37,200][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:49:37,359][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:49:37,372][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:49:37,397][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:49:37,409][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:49:37,410][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:49:37,422][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 13:49:37,422][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 13:49:40,645][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:49:40,645][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:49:40,672][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:49:40,683][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:49:40,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 13:49:40,710][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:49:40,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 13:49:43,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:49:43,576][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:49:43,588][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:49:43,600][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:49:43,600][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:49:43,600][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:49:46,322][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 13:49:46,322][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:49:46,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 13:49:46,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:49:46,351][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 13:49:46,548][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:49:46,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 13:49:46,763][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:49:48,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:49:48,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:49:48,500][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:49:48,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:48,539][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:48,539][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:48,667][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:48,732][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:51,791][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:51,895][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:51,895][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:51,910][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:52,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:49:52,215][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:49:52,217][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 119000.000000 | iteration_119000.pth.tar | 32.000000     | 2766.000000   | 86.437500               | 16.027354     | 172.579958          | 1.996587             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 16.84880256652832, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 14.790419578552246, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0] | [9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.738726                   | 0.562500         | 8.906250          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 13:58:47,978][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 13:58:47,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 13:58:47,997][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 13:58:48,046][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 13:58:48,064][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 13:58:48,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 13:58:48,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 13:58:49,457][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 13:58:49,494][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 13:58:49,495][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 13:58:49,495][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 13:58:49,514][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 13:58:49,588][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 13:58:49,588][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 13:58:49,908][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 13:58:53,155][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 13:58:53,167][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 13:58:53,167][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 13:58:53,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 13:58:53,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 13:58:53,679][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 13:58:54,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 13:58:54,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 13:58:54,806][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 13:58:54,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 13:58:54,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 13:58:54,875][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 13:58:54,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 13:58:54,987][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 13:58:55,124][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:58:55,869][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:58:55,881][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:58:55,893][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:58:55,904][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 13:58:55,985][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 13:58:56,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 13:58:56,039][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 120000.000000 | iteration_120000.pth.tar | 32.000000     | 2341.000000   | 73.156250               | 8.980697      | 260.670183          | 3.563198             | 0.906250    | 0.291481   | 1.000000   | 0.000000   | [20.0, 20.0, 15.688623428344727, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.306886672973633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.413174629211426, 20.0, 20.0, 20.0] | [0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0] | 19.544022                   | 0.812500         | 8.843750          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 14:07:28,012][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 14:07:28,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 14:07:28,170][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 14:07:28,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 14:07:28,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 14:07:28,192][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 14:07:28,324][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 14:07:28,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 14:07:29,888][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 14:07:30,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 14:07:30,199][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 14:07:30,218][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 14:07:30,321][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 14:07:30,757][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 14:07:30,928][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 14:07:30,970][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 14:07:31,449][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 17
[2025-06-07 14:07:31,461][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 14:07:31,485][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 14:07:31,497][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 14:07:31,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 14:07:31,581][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 14:07:31,782][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 14:07:31,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 14:07:32,354][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 14:07:32,366][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 14:07:32,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 14:07:32,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 14:07:32,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 14:07:32,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 14:07:32,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:07:33,409][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:07:33,423][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:07:33,450][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:07:33,478][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 14:07:33,494][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:07:34,035][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:07:34,102][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:07:34,932][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 14:07:34,933][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 121000.000000 | iteration_121000.pth.tar | 32.000000     | 2690.000000   | 84.062500               | 8.138113      | 330.543445          | 3.932115             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.988024711608887, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.000001907348633, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.000001907348633, 15.18413257598877] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 7.0] | 19.724130                   | 0.500000         | 8.906250          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 14:16:43,304][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 1
[2025-06-07 14:16:43,365][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 2
[2025-06-07 14:16:43,365][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-07 14:16:43,378][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 4
[2025-06-07 14:16:43,391][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-07 14:16:43,403][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-07 14:16:43,549][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 7
[2025-06-07 14:16:45,368][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 8
[2025-06-07 14:16:45,755][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-07 14:16:45,951][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-07 14:16:46,070][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 11
[2025-06-07 14:16:46,070][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-07 14:16:46,176][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-07 14:16:46,176][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 14
[2025-06-07 14:16:47,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 15
[2025-06-07 14:16:47,276][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 16
[2025-06-07 14:16:47,413][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 14:16:47,425][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-07 14:16:47,438][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 19
[2025-06-07 14:16:47,785][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 20
[2025-06-07 14:16:47,786][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 21
[2025-06-07 14:16:47,786][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-07 14:16:49,395][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 23
[2025-06-07 14:16:49,470][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 24
[2025-06-07 14:16:49,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 25
[2025-06-07 14:16:49,538][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 26
[2025-06-07 14:16:49,570][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 27
[2025-06-07 14:16:49,601][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 28
[2025-06-07 14:16:49,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 29
[2025-06-07 14:16:49,773][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 14:16:51,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 14:16:51,589][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 14:16:51,602][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 30
[2025-06-07 14:16:51,708][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:16:51,825][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:16:52,210][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:16:52,224][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:16:52,644][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:16:53,404][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:16:53,632][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:16:53,707][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 31
[2025-06-07 14:16:53,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 32
[2025-06-07 14:16:53,721][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter    | ckpt_name                | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                    | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 122000.000000 | iteration_122000.pth.tar | 32.000000     | 2711.000000   | 84.718750               | 13.931160     | 194.599730          | 2.297009             | 0.937500    | 0.242061   | 1.000000   | 0.000000   | [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 16.538923263549805, 20.0, 20.0, 20.0, 20.000001907348633, 20.0, 11.33682632446289, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0] | [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] | [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 4.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0] | 19.621117                   | 0.531250         | 8.812500          |
+-------+---------------+--------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
