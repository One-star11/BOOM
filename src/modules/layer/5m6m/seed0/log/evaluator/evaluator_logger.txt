[2025-06-07 17:53:39,128][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 17:53:39,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 17:53:39,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 17:53:39,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 17:53:39,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 17:53:39,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 17:53:39,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 17:53:39,207][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 17:53:39,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 17:53:39,692][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 17:53:39,692][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 17:53:39,692][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 17:53:39,714][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 17:53:39,714][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 17:53:39,765][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 17:53:39,816][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 17:53:40,246][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 17:53:40,269][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 17:53:40,269][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 17:53:40,294][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 17:53:40,319][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 17:53:40,345][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 17:53:40,397][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 17:53:40,483][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 17:53:40,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 17:53:40,835][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 17:53:40,886][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 17:53:40,914][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 17:53:40,914][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 17:53:40,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 17:53:40,963][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 17:53:41,093][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 17:53:41,094][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 1000.000000 | iteration_1000.pth.tar | 32.000000     | 657.000000    | 20.531250               | 2.438587      | 269.418270          | 13.122351            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [4.150943279266357, 4.603773593902588, 3.207547187805176, 4.150943279266357, 4.603773593902588, 5.0188679695129395, 6.150943756103516, 3.8867924213409424, 4.150943279266357, 5.056603908538818, 6.188679218292236, 5.735849380493164, 4.150943756103516, 2.0754716396331787, 5.056603908538818, 5.056603908538818, 2.9811320304870605, 4.150943279266357, 4.150943279266357, 6.4528303146362305, 4.150943279266357, 2.0754716396331787, 4.113207817077637, 5.283019065856934, 4.150943279266357, 6.226415157318115, 7.358490943908691, 5.056603908538818, 4.150943279266357, 2.0754716396331787, 7.584905624389648, 3.6603775024414062] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0] | 4.589623                    | 5.000000         | 1.812500          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 18:47:24,626][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 18:47:24,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 18:47:24,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 18:47:24,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 18:47:24,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 18:47:24,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 18:47:24,640][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 18:47:24,666][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 18:47:25,026][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 18:47:25,047][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 18:47:25,048][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 18:47:25,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 18:47:25,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 18:47:25,068][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 18:47:25,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 18:47:25,111][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 18:47:25,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 18:47:25,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 18:47:25,492][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 18:47:25,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 18:47:25,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 18:47:25,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 18:47:25,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 18:47:25,559][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 18:47:25,903][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 18:47:25,903][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 18:47:25,951][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 18:47:25,951][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 18:47:25,952][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 18:47:25,998][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 18:47:25,998][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 18:47:25,998][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 18:47:26,000][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 2000.000000 | iteration_2000.pth.tar | 32.000000     | 563.000000    | 17.593750               | 1.779588      | 316.365294          | 17.981686            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [4.113207817077637, 4.792452812194824, 5.9245285987854, 3.8867924213409424, 6.150943756103516, 4.301887035369873, 5.245283126831055, 3.6603775024414062, 5.9245285987854, 5.962264060974121, 4.113207817077637, 5.698113441467285, 5.698113441467285, 4.792452812194824, 5.47169828414917, 5.47169828414917, 5.0188679695129395, 5.47169828414917, 5.698113441467285, 4.566037654876709, 4.566037654876709, 5.207547187805176, 6.150943279266357, 5.47169828414917, 5.0188679695129395, 5.245283126831055, 5.0188679695129395, 5.8867926597595215, 5.962264060974121, 4.339622497558594, 6.150943279266357, 5.245283126831055] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0] | 5.194576                    | 5.000000         | 0.968750          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 19:40:55,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 19:40:55,762][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 19:40:55,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 19:40:55,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 19:40:55,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 19:40:55,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 19:40:55,816][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 19:40:55,816][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 19:40:56,256][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 19:40:56,256][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 19:40:56,282][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 19:40:56,309][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 19:40:56,339][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 19:40:56,339][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 19:40:56,339][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 19:40:56,339][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 19:40:56,764][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 19:40:56,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 19:40:56,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 19:40:56,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 19:40:56,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 19:40:56,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 19:40:56,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 19:40:56,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 19:40:57,283][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 19:40:57,312][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 19:40:57,340][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 19:40:57,377][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 19:40:57,378][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 19:40:57,378][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 19:40:57,378][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 19:40:57,401][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 19:40:57,402][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 3000.000000 | iteration_3000.pth.tar | 32.000000     | 545.000000    | 17.031250               | 2.138502      | 254.851270          | 14.963744            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [5.433962345123291, 5.8867926597595215, 6.113207817077637, 6.150943756103516, 5.433962345123291, 5.660377502441406, 6.339622497558594, 6.150943279266357, 5.433962345123291, 5.8867926597595215, 5.207547187805176, 5.660377502441406, 6.113207817077637, 6.830188751220703, 5.207547187805176, 4.754716873168945, 6.566038131713867, 5.8867926597595215, 6.339622497558594, 5.698113441467285, 6.113207817077637, 5.207547187805176, 4.9811320304870605, 5.433962345123291, 5.433962345123291, 5.207547187805176, 6.113207817077637, 5.660377502441406, 5.433962345123291, 4.9811320304870605, 6.377358436584473, 6.150943279266357] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0] | 5.745283                    | 5.000000         | 0.187500          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 20:32:59,538][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 20:32:59,538][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 20:32:59,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 20:32:59,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 20:32:59,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 20:32:59,585][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 20:32:59,585][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 20:32:59,585][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 20:32:59,999][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 20:32:59,999][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 20:33:00,023][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 20:33:00,023][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 20:33:00,024][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 20:33:00,057][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 20:33:00,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 20:33:00,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 20:33:00,489][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 20:33:00,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 20:33:00,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 20:33:00,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 20:33:00,534][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 20:33:00,560][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 20:33:00,560][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 20:33:00,611][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 20:33:00,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 20:33:00,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 20:33:00,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 20:33:00,981][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 20:33:01,004][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 20:33:01,031][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 20:33:01,055][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 20:33:01,077][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 20:33:01,079][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 4000.000000 | iteration_4000.pth.tar | 32.000000     | 569.000000    | 17.781250               | 2.004997      | 283.790887          | 15.960120            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.113207817077637, 5.660377502441406, 6.792452812194824, 6.339622497558594, 6.150943279266357, 5.924528121948242, 5.207547187805176, 5.245283126831055, 4.528302192687988, 5.0188679695129395, 5.283019065856934, 5.207547187805176, 5.660377502441406, 5.433962345123291, 5.660377502441406, 5.660377502441406, 5.8867926597595215, 6.113207817077637, 5.9245285987854, 7.283019065856934, 6.377358436584473, 6.339622497558594, 6.603773593902588, 6.603773593902588, 7.094339847564697, 5.207547187805176, 5.698113441467285, 5.660377502441406, 5.8867926597595215, 6.339622497558594, 6.566037654876709, 6.113207817077637] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] | 5.924528                    | 5.000000         | 0.437500          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 21:25:09,660][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 21:25:09,668][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 21:25:09,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 21:25:09,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 21:25:09,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 21:25:09,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 21:25:09,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 21:25:09,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 21:25:10,105][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 21:25:10,105][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 21:25:10,156][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 21:25:10,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 21:25:10,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 21:25:10,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 21:25:10,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 21:25:10,210][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 21:25:10,647][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 21:25:10,647][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 21:25:10,669][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 21:25:10,694][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 21:25:10,694][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 21:25:10,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 21:25:10,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 21:25:10,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 21:25:11,159][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 21:25:11,159][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 21:25:11,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 21:25:11,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 21:25:11,183][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 21:25:11,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 21:25:11,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 21:25:11,242][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 21:25:11,244][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 5000.000000 | iteration_5000.pth.tar | 32.000000     | 547.000000    | 17.093750               | 2.031356      | 269.278261          | 15.753024            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.113207817077637, 6.830188751220703, 7.056603908538818, 5.9245285987854, 6.566037654876709, 5.8867926597595215, 6.113207817077637, 6.566037654876709, 6.792452812194824, 6.113207817077637, 6.377358436584473, 6.792452812194824, 6.113207817077637, 6.603773593902588, 6.830188751220703, 5.660377502441406, 5.8867926597595215, 6.113207817077637, 6.150943279266357, 6.339622497558594, 6.339622497558594, 6.566037654876709, 7.3207550048828125, 6.792452812194824, 5.8867926597595215, 6.603773593902588, 6.867924690246582, 7.283019065856934, 6.830188751220703, 6.113207817077637, 5.433962345123291, 6.603773593902588] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0] | 6.420991                    | 5.000000         | 0.468750          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 22:17:14,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 22:17:14,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 22:17:14,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 22:17:14,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 22:17:14,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 22:17:14,248][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 22:17:14,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 22:17:14,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 22:17:14,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 22:17:14,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 22:17:14,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 22:17:14,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 22:17:14,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 22:17:14,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 22:17:14,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 22:17:14,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 22:17:15,136][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 22:17:15,163][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 22:17:15,195][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 22:17:15,196][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 22:17:15,196][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 22:17:15,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 22:17:15,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 22:17:15,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 22:17:15,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 22:17:15,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 22:17:15,761][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 22:17:15,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 22:17:15,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 22:17:15,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 22:17:15,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 22:17:15,848][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 22:17:15,850][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 6000.000000 | iteration_6000.pth.tar | 32.000000     | 577.000000    | 18.031250               | 2.069305      | 278.837524          | 15.464126            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.603773593902588, 6.339622497558594, 6.339622497558594, 6.113207817077637, 6.792452812194824, 7.962264537811279, 5.9245285987854, 7.056603908538818, 6.830188751220703, 6.150943756103516, 6.603773593902588, 6.566037654876709, 6.830188751220703, 6.830188751220703, 4.754716873168945, 6.792452812194824, 5.9245285987854, 4.9811320304870605, 6.113207817077637, 6.603773593902588, 5.433962345123291, 7.056603908538818, 6.113207817077637, 5.9245285987854, 7.056603908538818, 6.566037654876709, 6.566037654876709, 6.377358436584473, 6.566038131713867, 6.377358436584473, 6.830188751220703, 6.113207817077637] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0] | 6.409198                    | 5.000000         | 0.531250          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-07 23:10:28,517][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-07 23:10:28,525][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-07 23:10:28,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-07 23:10:28,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 4
[2025-06-07 23:10:28,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-07 23:10:28,562][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-07 23:10:28,585][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 7
[2025-06-07 23:10:28,586][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-07 23:10:29,046][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-07 23:10:29,047][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-07 23:10:29,071][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-07 23:10:29,071][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 12
[2025-06-07 23:10:29,093][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-07 23:10:29,093][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-07 23:10:29,122][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-07 23:10:29,188][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-07 23:10:29,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-07 23:10:29,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-07 23:10:29,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-07 23:10:29,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 20
[2025-06-07 23:10:29,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-07 23:10:29,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-07 23:10:29,673][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-07 23:10:29,699][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-07 23:10:30,097][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-07 23:10:30,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-07 23:10:30,153][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-07 23:10:30,188][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-07 23:10:30,188][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-07 23:10:30,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-07 23:10:30,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-07 23:10:30,269][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-07 23:10:30,270][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 7000.000000 | iteration_7000.pth.tar | 32.000000     | 588.000000    | 18.375000               | 2.212683      | 265.740749          | 14.462082            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [7.283019065856934, 5.8867926597595215, 6.339622974395752, 6.792452812194824, 6.830188751220703, 6.566037654876709, 6.150943756103516, 4.9811320304870605, 7.056603908538818, 6.377358436584473, 6.566037654876709, 6.830188751220703, 6.641509532928467, 6.150943279266357, 6.641509532928467, 6.792452812194824, 6.339622497558594, 6.377358436584473, 5.8867926597595215, 6.377358436584473, 6.150943756103516, 6.339622497558594, 6.113207817077637, 6.830188751220703, 6.566037654876709, 6.830188751220703, 7.056603908538818, 6.339622497558594, 6.113207817077637, 6.641509532928467, 6.566038131713867, 7.283019065856934] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0] | 6.490566                    | 5.000000         | 0.625000          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 00:02:44,154][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 00:02:44,155][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 00:02:44,155][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 00:02:44,155][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 00:02:44,182][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 00:02:44,182][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 00:02:44,182][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 00:02:44,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 00:02:44,673][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 00:02:44,673][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 00:02:44,673][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 00:02:44,673][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 00:02:44,673][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 00:02:44,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 00:02:44,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 00:02:44,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 00:02:45,204][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 00:02:45,230][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 00:02:45,231][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 00:02:45,231][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 00:02:45,231][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 00:02:45,231][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 00:02:45,231][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 00:02:45,253][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 00:02:45,780][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 00:02:45,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 00:02:45,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 00:02:45,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 00:02:45,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 00:02:45,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 00:02:45,809][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 00:02:45,856][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 00:02:45,857][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 8000.000000 | iteration_8000.pth.tar | 32.000000     | 578.000000    | 18.062500               | 2.197405      | 263.037563          | 14.562633            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [7.0188679695129395, 6.792452812194824, 6.339622497558594, 6.377358436584473, 4.301887035369873, 7.283019065856934, 5.433962345123291, 7.056603908538818, 6.377358436584473, 6.603773593902588, 6.603773593902588, 6.339622974395752, 7.3207550048828125, 5.207547187805176, 5.207547187805176, 6.566037654876709, 6.113207817077637, 7.283019065856934, 6.830188751220703, 7.056603908538818, 7.283019065856934, 6.339622497558594, 6.566038131713867, 6.830188751220703, 5.433962345123291, 6.339622974395752, 6.150943279266357, 6.339622974395752, 6.377358436584473, 5.660377502441406, 6.603773593902588, 6.113207817077637] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0] | 6.379717                    | 5.000000         | 0.500000          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 00:56:12,990][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 00:56:12,990][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 00:56:12,990][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 00:56:13,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 00:56:13,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 00:56:13,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 00:56:13,015][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 00:56:13,038][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 00:56:13,524][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 00:56:13,561][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 00:56:13,561][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 00:56:13,561][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 00:56:13,561][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 00:56:13,561][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 00:56:13,561][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 00:56:13,577][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 00:56:14,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 00:56:14,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 00:56:14,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 00:56:14,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 00:56:14,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 00:56:14,066][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 00:56:14,086][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 00:56:14,112][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 00:56:14,548][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 00:56:14,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 00:56:14,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 00:56:14,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 00:56:14,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 00:56:14,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 00:56:14,594][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 00:56:14,594][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 00:56:14,595][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 9000.000000 | iteration_9000.pth.tar | 32.000000     | 562.000000    | 17.562500               | 2.108596      | 266.528004          | 15.175972            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [7.5471696853637695, 4.9811320304870605, 6.377358436584473, 6.339622497558594, 6.603773593902588, 5.8867926597595215, 4.528302192687988, 6.113207817077637, 6.150943756103516, 6.377358436584473, 6.603773593902588, 6.566037654876709, 7.3207550048828125, 6.792452812194824, 6.339622497558594, 7.735849380493164, 7.056603908538818, 7.056603908538818, 5.9245285987854, 7.0188679695129395, 5.8867926597595215, 7.245283126831055, 5.660377502441406, 6.150943279266357, 6.566037654876709, 6.150943756103516, 6.603773593902588, 6.830188751220703, 6.830188751220703, 6.113207817077637, 6.377358436584473, 6.603773593902588] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0] | 6.448113                    | 5.000000         | 0.625000          |
+-------+-------------+------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 01:47:26,691][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 01:47:26,691][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 01:47:26,691][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 01:47:26,716][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 01:47:26,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 01:47:26,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 01:47:26,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 01:47:26,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 01:47:27,178][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 01:47:27,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 01:47:27,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 01:47:27,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 01:47:27,209][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 01:47:27,233][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 01:47:27,233][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 01:47:27,234][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 01:47:27,658][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 01:47:27,658][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 01:47:27,677][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 01:47:27,702][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 01:47:27,702][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 01:47:27,702][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 01:47:27,723][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 01:47:27,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 01:47:28,069][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 01:47:28,095][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 01:47:28,095][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 01:47:28,116][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 01:47:28,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 01:47:28,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 01:47:28,138][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 01:47:28,182][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 01:47:28,183][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 10000.000000 | iteration_10000.pth.tar | 32.000000     | 577.000000    | 18.031250               | 1.968451      | 293.123948          | 16.256441            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.830188751220703, 6.830188751220703, 6.792452812194824, 6.377358436584473, 6.603773593902588, 5.433962345123291, 5.8867926597595215, 6.830188751220703, 6.641509532928467, 7.056603908538818, 6.792452812194824, 7.056603908538818, 6.150943279266357, 6.830188751220703, 7.094339847564697, 6.339622497558594, 6.792452812194824, 6.113207817077637, 5.660377502441406, 7.056603908538818, 6.377358436584473, 5.8867926597595215, 5.47169828414917, 6.339622497558594, 6.830188751220703, 6.867924690246582, 7.509434223175049, 6.415094375610352, 6.377358436584473, 6.830188751220703, 5.433962345123291, 6.603773593902588] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0] | 6.503538                    | 5.000000         | 0.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 02:37:43,868][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 02:37:43,868][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 02:37:43,889][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 02:37:43,889][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 02:37:43,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 02:37:43,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 02:37:43,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 02:37:43,912][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 02:37:44,336][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 02:37:44,359][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 02:37:44,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 02:37:44,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 02:37:44,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 02:37:44,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 02:37:44,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 02:37:44,400][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 02:37:44,778][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 02:37:44,800][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 02:37:44,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 02:37:44,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 02:37:44,846][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 02:37:44,846][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 02:37:44,846][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 02:37:44,866][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 02:37:45,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 02:37:45,252][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 02:37:45,252][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 02:37:45,274][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 02:37:45,274][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 02:37:45,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 02:37:45,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 02:37:45,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 02:37:45,319][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 11000.000000 | iteration_11000.pth.tar | 32.000000     | 569.000000    | 17.781250               | 1.897743      | 299.829825          | 16.862134            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.113207817077637, 6.113207817077637, 8.0, 6.339622974395752, 5.8867926597595215, 6.377358436584473, 6.377358436584473, 6.830188751220703, 6.603773593902588, 7.735849380493164, 6.830188751220703, 6.566037654876709, 6.377358436584473, 6.113207817077637, 6.830188751220703, 5.433962345123291, 6.830188751220703, 6.830188751220703, 6.566037654876709, 7.0188679695129395, 6.377358436584473, 5.9245285987854, 6.603773593902588, 6.377358436584473, 6.603773593902588, 6.603773593902588, 6.339622497558594, 8.0, 7.283019065856934, 6.113207817077637, 7.094339847564697, 8.226415634155273] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0] | 6.666274                    | 5.000000         | 0.781250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 03:29:40,670][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 03:29:40,670][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 03:29:40,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 03:29:40,693][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 03:29:40,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 03:29:40,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 03:29:40,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 03:29:40,772][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 03:29:41,145][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 03:29:41,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 03:29:41,197][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 03:29:41,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 03:29:41,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 03:29:41,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 03:29:41,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 03:29:41,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 03:29:41,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 03:29:41,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 03:29:41,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 03:29:41,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 03:29:41,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 03:29:41,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 03:29:41,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 03:29:41,856][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 03:29:42,258][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 03:29:42,310][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 03:29:42,310][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 03:29:42,311][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 03:29:42,334][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 03:29:42,334][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 03:29:42,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 03:29:42,382][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 03:29:42,384][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 12000.000000 | iteration_12000.pth.tar | 32.000000     | 593.000000    | 18.531250               | 2.134167      | 277.860232          | 14.994144            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [7.056603908538818, 7.056603908538818, 6.603773593902588, 7.094339847564697, 7.0188679695129395, 6.830188751220703, 6.641509532928467, 7.5471696853637695, 6.566038131713867, 6.603773593902588, 6.830188751220703, 6.603773593902588, 6.113207817077637, 7.5471696853637695, 6.603773593902588, 7.773584842681885, 6.641509532928467, 6.377358436584473, 8.0, 7.094339847564697, 8.45283031463623, 5.433962345123291, 7.811320781707764, 8.0, 7.3207550048828125, 6.867924690246582, 6.867924690246582, 7.584905624389648, 6.339622974395752, 5.962264060974121, 7.056603908538818, 5.9245285987854] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0] | 6.944576                    | 5.000000         | 1.406250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 04:21:54,704][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 04:21:54,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 04:21:54,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 04:21:54,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 04:21:54,748][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 04:21:54,748][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 04:21:54,769][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 04:21:54,769][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 04:21:55,165][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 04:21:55,165][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 04:21:55,188][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 04:21:55,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 04:21:55,211][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 04:21:55,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 04:21:55,263][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 04:21:55,316][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 04:21:55,650][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 04:21:55,672][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 04:21:55,672][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 04:21:55,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 04:21:55,695][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 04:21:55,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 04:21:55,745][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 04:21:55,793][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 04:21:56,149][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 04:21:56,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 04:21:56,206][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 04:21:56,207][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 04:21:56,207][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 04:21:56,251][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 04:21:56,251][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 04:21:56,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 04:21:56,302][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 13000.000000 | iteration_13000.pth.tar | 32.000000     | 609.000000    | 19.031250               | 1.994122      | 305.397497          | 16.047159            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [8.188679695129395, 7.283019065856934, 7.509434223175049, 7.056604385375977, 7.773585319519043, 6.339622974395752, 7.3207550048828125, 6.415094375610352, 7.094339847564697, 6.830188751220703, 8.905660629272461, 5.698113441467285, 6.867924690246582, 6.641509532928467, 9.207547187805176, 6.830188751220703, 6.377358436584473, 8.45283031463623, 7.094339847564697, 7.283019065856934, 7.547170162200928, 8.528302192687988, 7.3207550048828125, 7.056603908538818, 7.547170162200928, 6.641509532928467, 7.056603908538818, 7.5471696853637695, 9.132075309753418, 5.8867926597595215, 6.377358436584473, 6.867924690246582] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0] | 7.271227                    | 5.000000         | 1.625000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 05:11:51,729][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 05:11:51,764][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 05:11:51,765][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 05:11:51,765][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 05:11:51,788][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 05:11:51,814][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 05:11:51,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 05:11:51,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 05:11:52,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 05:11:52,328][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 05:11:52,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 05:11:52,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 05:11:52,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 05:11:52,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 05:11:52,459][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 05:11:52,490][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 05:11:52,913][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 05:11:52,914][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 05:11:52,914][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 05:11:52,965][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 05:11:52,987][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 05:11:53,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 05:11:53,032][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 05:11:53,052][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 05:11:53,441][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 05:11:53,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 05:11:53,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 05:11:53,568][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 05:11:53,568][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 05:11:53,589][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 05:11:53,618][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 05:11:53,648][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 05:11:53,650][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 14000.000000 | iteration_14000.pth.tar | 32.000000     | 657.000000    | 20.531250               | 2.385786      | 275.380956          | 13.412771            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.867924690246582, 8.264150619506836, 6.641509532928467, 7.3207550048828125, 9.433961868286133, 8.49056625366211, 8.94339656829834, 6.641509532928467, 7.3207550048828125, 6.415094375610352, 9.88679313659668, 6.867924690246582, 9.886792182922363, 7.547170162200928, 7.283019065856934, 7.584905624389648, 6.867924690246582, 7.094339847564697, 6.830188751220703, 8.037735939025879, 6.1886796951293945, 8.037735939025879, 6.641509532928467, 7.811320781707764, 8.49056625366211, 10.113207817077637, 6.830188751220703, 6.867924690246582, 6.867924690246582, 7.773585319519043, 9.169811248779297, 7.584905624389648] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0] | 7.706368                    | 5.000000         | 2.468750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 06:01:32,675][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 06:01:32,735][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 06:01:32,764][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 06:01:32,764][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 06:01:32,789][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 06:01:32,790][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 06:01:32,817][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 06:01:32,869][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 06:01:33,274][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 06:01:33,300][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 06:01:33,324][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 06:01:33,348][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 06:01:33,348][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 06:01:33,371][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 06:01:33,402][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 06:01:33,402][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 06:01:33,820][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 06:01:33,845][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 06:01:33,845][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 06:01:33,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 06:01:33,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 06:01:33,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 06:01:33,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 06:01:33,939][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 06:01:34,390][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 06:01:34,414][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 06:01:34,414][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 06:01:34,445][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 06:01:34,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 06:01:34,504][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 06:01:34,529][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 06:01:34,529][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 06:01:34,530][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 15000.000000 | iteration_15000.pth.tar | 32.000000     | 683.000000    | 21.343750               | 2.338095      | 292.118160          | 13.686356            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.150943756103516, 8.037735939025879, 6.150943756103516, 9.622641563415527, 9.43396282196045, 6.867924690246582, 8.49056625366211, 8.264150619506836, 6.641509532928467, 7.773585319519043, 8.981132507324219, 5.433962345123291, 8.981132507324219, 6.641509532928467, 4.830188751220703, 8.981132507324219, 8.264151573181152, 7.811320781707764, 8.264151573181152, 9.660377502441406, 8.94339656829834, 7.547170162200928, 8.226415634155273, 7.358490943908691, 8.905660629272461, 8.264150619506836, 7.3207550048828125, 7.584906101226807, 9.88679313659668, 6.415094375610352, 7.056603908538818, 8.716980934143066] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 3.0, 3.0, 2.0, 2.0, 4.0, 0.0, 4.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0] | 7.859670                    | 5.000000         | 2.593750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 06:50:39,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 06:50:39,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 06:50:39,212][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 06:50:39,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 06:50:39,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 06:50:39,227][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 06:50:39,296][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 06:50:39,321][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 06:50:39,671][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 06:50:39,694][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 06:50:39,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 06:50:39,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 06:50:39,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 06:50:39,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 06:50:39,832][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 06:50:39,832][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 06:50:40,176][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 06:50:40,227][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 06:50:40,251][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 06:50:40,276][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 06:50:40,300][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 06:50:40,323][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 06:50:40,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 06:50:40,502][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 06:50:40,675][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 06:50:40,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 06:50:40,816][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 06:50:40,852][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 06:50:40,853][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 06:50:40,877][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 06:50:41,024][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 06:50:41,106][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 06:50:41,108][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 16000.000000 | iteration_16000.pth.tar | 32.000000     | 753.000000    | 23.531250               | 2.416804      | 311.568538          | 13.240628            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [8.301886558532715, 7.358490467071533, 9.207547187805176, 5.9245285987854, 7.358490943908691, 7.132075786590576, 7.584905624389648, 7.358490943908691, 8.037735939025879, 5.509434223175049, 6.641509532928467, 5.509434223175049, 9.43396282196045, 7.584905624389648, 8.528302192687988, 9.88679313659668, 8.037735939025879, 6.867924690246582, 7.811321258544922, 8.981132507324219, 6.641509532928467, 7.811320781707764, 6.641509532928467, 7.584905624389648, 8.037735939025879, 8.49056625366211, 9.660377502441406, 7.5471696853637695, 9.39622688293457, 8.037735939025879, 9.886792182922363, 9.207547187805176] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [4.0, 3.0, 4.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 4.0, 4.0] | 7.875000                    | 5.000000         | 3.000000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 07:42:26,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 07:42:26,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 07:42:26,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 07:42:26,802][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 07:42:26,874][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 07:42:26,899][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 07:42:26,899][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 07:42:26,967][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 07:42:27,717][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 07:42:27,746][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 07:42:27,746][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 07:42:27,795][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 07:42:27,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 07:42:27,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 07:42:27,821][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 07:42:27,844][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 07:42:28,309][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 07:42:28,414][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 07:42:28,444][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 07:42:28,470][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 07:42:28,498][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 07:42:28,498][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 07:42:28,574][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 07:42:28,627][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 07:42:28,949][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 07:42:29,088][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 26
[2025-06-08 07:42:29,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 07:42:29,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 07:42:29,226][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 07:42:29,632][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 07:42:29,802][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 07:42:29,870][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 07:42:29,871][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 17000.000000 | iteration_17000.pth.tar | 32.000000     | 833.000000    | 26.031250               | 3.644385      | 228.570785          | 8.780630             | 0.031250    | 0.173993   | 1.000000   | 0.000000   | [9.169811248779297, 8.528302192687988, 8.716980934143066, 10.830188751220703, 9.660377502441406, 8.264150619506836, 9.207547187805176, 8.754716873168945, 10.377358436584473, 7.584905624389648, 8.301886558532715, 10.377358436584473, 7.773585319519043, 6.4528303146362305, 7.584906101226807, 8.528302192687988, 9.207547187805176, 8.94339656829834, 7.358490467071533, 9.88679313659668, 6.415094375610352, 8.264151573181152, 7.584905624389648, 20.0, 10.377358436584473, 8.94339656829834, 10.377358436584473, 6.641509532928467, 5.509433746337891, 10.113207817077637, 8.528302192687988, 10.603774070739746] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [3.0, 4.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 2.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 2.0, 2.0, 4.0, 4.0, 5.0] | 9.027123                    | 4.875000         | 3.656250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 08:33:19,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 08:33:19,760][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 08:33:19,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 08:33:19,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 08:33:19,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 08:33:19,837][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 6
[2025-06-08 08:33:19,860][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 08:33:19,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 08:33:20,319][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 08:33:20,320][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 08:33:20,375][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 08:33:20,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 08:33:20,459][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 08:33:20,484][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 08:33:20,511][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 08:33:20,540][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 08:33:20,967][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 08:33:21,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 08:33:21,013][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 08:33:21,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 08:33:21,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 08:33:21,130][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 08:33:21,176][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 08:33:21,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 08:33:21,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 08:33:21,578][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 08:33:21,578][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 08:33:21,599][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 08:33:21,624][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 08:33:21,646][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 08:33:21,725][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 08:33:21,803][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 08:33:21,804][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 18000.000000 | iteration_18000.pth.tar | 32.000000     | 787.000000    | 24.593750               | 2.573852      | 305.767439          | 12.432729            | 0.031250    | 0.173993   | 1.000000   | 0.000000   | [20.0, 8.754716873168945, 8.981132507324219, 9.39622688293457, 6.867924690246582, 8.716980934143066, 9.660377502441406, 8.49056625366211, 10.377358436584473, 9.207547187805176, 9.886792182922363, 6.188679218292236, 8.264151573181152, 7.811320781707764, 9.8490571975708, 8.264150619506836, 9.207547187805176, 9.43396282196045, 7.132075786590576, 9.88679313659668, 9.39622688293457, 10.830188751220703, 11.056604385375977, 8.94339656829834, 7.132075786590576, 9.660377502441406, 7.811320781707764, 9.207547187805176, 8.45283031463623, 6.905660629272461, 8.754716873168945, 8.754716873168945] | [1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [6.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 3.0, 4.0, 2.0, 3.0, 4.0, 4.0] | 9.165095                    | 4.875000         | 3.562500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 09:22:14,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 09:22:14,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 09:22:14,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 09:22:14,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 4
[2025-06-08 09:22:14,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-08 09:22:14,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 09:22:14,073][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 09:22:14,117][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 09:22:14,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 09:22:14,646][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 09:22:14,647][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 09:22:14,647][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 09:22:14,647][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 09:22:14,697][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 09:22:14,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 09:22:14,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 09:22:15,300][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 09:22:15,301][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 09:22:15,413][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 09:22:15,413][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 09:22:15,413][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 09:22:15,461][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 09:22:15,461][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 09:22:15,644][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 09:22:15,861][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 09:22:15,885][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 09:22:16,060][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 09:22:16,091][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 09:22:16,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 09:22:16,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 09:22:16,315][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 09:22:16,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 09:22:16,410][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 19000.000000 | iteration_19000.pth.tar | 32.000000     | 833.000000    | 26.031250               | 2.972707      | 280.215998          | 10.764600            | 0.062500    | 0.242061   | 1.000000   | 0.000000   | [8.037735939025879, 8.037735939025879, 8.716980934143066, 8.49056625366211, 9.8490571975708, 9.622641563415527, 10.830188751220703, 10.792452812194824, 20.0, 9.169811248779297, 9.886792182922363, 10.830188751220703, 20.0, 10.566038131713867, 9.169811248779297, 7.358490943908691, 10.113207817077637, 6.867924690246582, 6.867924690246582, 5.283019065856934, 9.207547187805176, 8.0, 8.301886558532715, 9.169811248779297, 10.113207817077637, 8.716980934143066, 10.339622497558594, 8.264150619506836, 10.301886558532715, 6.641509532928467, 9.39622688293457, 7.811320781707764] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 6.0, 3.0, 4.0, 5.0, 6.0, 4.0, 3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0] | 9.586085                    | 4.781250         | 3.406250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 10:12:16,595][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 10:12:16,644][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 10:12:16,644][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 10:12:16,667][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 10:12:16,691][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 5
[2025-06-08 10:12:16,715][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 10:12:16,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 10:12:16,750][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 10:12:17,307][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 10:12:17,485][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 10:12:17,568][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 10:12:17,594][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 10:12:17,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 10:12:17,623][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 10:12:17,651][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 10:12:17,680][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 10:12:18,030][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 10:12:18,203][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 18
[2025-06-08 10:12:18,266][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 10:12:18,317][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 10:12:18,348][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 21
[2025-06-08 10:12:18,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 10:12:18,471][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 10:12:18,594][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 10:12:18,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 10:12:18,846][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 10:12:18,950][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 10:12:19,006][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 10:12:19,159][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 10:12:19,181][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 10:12:19,182][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 10:12:19,287][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 10:12:19,288][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 20000.000000 | iteration_20000.pth.tar | 32.000000     | 897.000000    | 28.031250               | 3.297027      | 272.063278          | 9.705713             | 0.093750    | 0.291481   | 1.000000   | 0.000000   | [8.94339656829834, 10.377358436584473, 11.50943374633789, 9.88679313659668, 10.113207817077637, 11.283019065856934, 7.132075786590576, 9.207547187805176, 9.169811248779297, 11.283019065856934, 11.283019065856934, 10.377358436584473, 20.0, 11.283019065856934, 9.207547187805176, 9.660377502441406, 7.773584842681885, 11.50943374633789, 20.0, 10.377358436584473, 6.188679218292236, 9.660377502441406, 8.264150619506836, 10.113207817077637, 10.339622497558594, 8.264150619506836, 20.0, 9.132075309753418, 8.754716873168945, 9.43396282196045, 9.169811248779297, 9.43396282196045] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [3.0, 5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 3.0, 5.0, 5.0, 5.0, 6.0, 5.0, 4.0, 4.0, 2.0, 5.0, 6.0, 5.0, 2.0, 4.0, 3.0, 4.0, 4.0, 3.0, 6.0, 2.0, 4.0, 4.0, 3.0, 4.0] | 10.597877                   | 4.593750         | 4.093750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 11:04:43,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 11:04:43,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 11:04:43,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 11:04:43,042][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 11:04:43,067][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 11:04:43,067][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 11:04:43,123][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 11:04:43,150][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 11:04:43,681][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 11:04:43,681][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 11:04:43,729][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 11:04:43,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 11:04:43,800][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 11:04:43,800][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 11:04:43,800][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 11:04:43,822][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 11:04:44,412][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 11:04:44,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 11:04:44,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 11:04:44,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 11:04:44,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 11:04:44,592][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 11:04:44,619][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 11:04:44,781][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 11:04:45,191][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 11:04:45,275][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 11:04:45,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 11:04:45,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 11:04:45,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 11:04:45,306][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 11:04:45,511][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 11:04:45,597][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 11:04:45,598][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 21000.000000 | iteration_21000.pth.tar | 32.000000     | 845.000000    | 26.406250               | 3.172396      | 266.360190          | 10.087013            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.415094375610352, 9.88679313659668, 9.207547187805176, 8.45283031463623, 7.3207550048828125, 9.622641563415527, 7.811320781707764, 8.94339656829834, 9.39622688293457, 10.792452812194824, 7.773585319519043, 10.566038131713867, 10.075471878051758, 8.528302192687988, 10.792452812194824, 11.283019065856934, 8.94339656829834, 9.43396282196045, 5.962264060974121, 9.622641563415527, 10.075471878051758, 8.264151573181152, 10.792452812194824, 10.113207817077637, 7.132075309753418, 8.264151573181152, 11.50943374633789, 9.39622688293457, 9.43396282196045, 7.584905624389648, 7.132075786590576, 10.566038131713867] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 5.0, 3.0, 4.0, 3.0, 3.0, 4.0] | 9.096698                    | 5.000000         | 3.312500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 11:54:20,512][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 11:54:20,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 11:54:20,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 11:54:20,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 11:54:20,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 11:54:20,576][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 11:54:20,576][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 11:54:20,576][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 11:54:21,086][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 11:54:21,086][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 11:54:21,107][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 11:54:21,107][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 11:54:21,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 11:54:21,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 11:54:21,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 11:54:21,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 11:54:21,618][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 11:54:21,618][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 11:54:21,638][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 11:54:21,661][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 11:54:21,661][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 11:54:21,682][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 11:54:21,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 11:54:21,794][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 11:54:22,151][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 11:54:22,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 11:54:22,222][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 11:54:22,244][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 11:54:22,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 11:54:22,268][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 11:54:22,311][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 11:54:22,334][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 11:54:22,335][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 22000.000000 | iteration_22000.pth.tar | 32.000000     | 761.000000    | 23.781250               | 2.279632      | 333.825835          | 14.037354            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [6.188679218292236, 6.905660629272461, 10.566038131713867, 8.49056625366211, 9.169811248779297, 9.39622688293457, 9.88679313659668, 8.528302192687988, 8.0, 10.075471878051758, 8.528302192687988, 8.264150619506836, 9.622641563415527, 9.43396282196045, 7.094339847564697, 10.830188751220703, 7.3207550048828125, 9.886792182922363, 7.132075786590576, 7.811320781707764, 8.94339656829834, 8.0, 7.358490467071533, 10.792452812194824, 5.735849380493164, 10.339622497558594, 7.3207550048828125, 7.358490467071533, 8.264151573181152, 8.037735939025879, 7.811320781707764, 8.528302192687988] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0] | 8.488208                    | 5.000000         | 3.125000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 12:42:01,935][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 12:42:01,958][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 12:42:01,958][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 12:42:01,980][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 12:42:01,980][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 12:42:02,000][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 12:42:02,023][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 12:42:02,048][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 12:42:02,452][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 12:42:02,497][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 12:42:02,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 12:42:02,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 12:42:02,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 12:42:02,546][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 14
[2025-06-08 12:42:02,730][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 12:42:02,803][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 12:42:03,027][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 12:42:03,049][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 12:42:03,091][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 12:42:03,137][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 20
[2025-06-08 12:42:03,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 12:42:03,285][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 12:42:03,357][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 12:42:03,381][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 12:42:03,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 12:42:03,617][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 12:42:03,640][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 12:42:03,713][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 12:42:03,759][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 12:42:03,838][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 12:42:03,893][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 12:42:04,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 12:42:04,229][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 12:42:04,230][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 23000.000000 | iteration_23000.pth.tar | 32.000000     | 904.000000    | 28.250000               | 2.810846      | 321.611308          | 11.384471            | 0.062500    | 0.242061   | 1.000000   | 0.000000   | [7.773584842681885, 6.905660629272461, 8.754716873168945, 8.037735939025879, 8.45283031463623, 8.0, 8.037735939025879, 9.169811248779297, 10.339622497558594, 8.45283031463623, 20.0, 7.811320781707764, 6.603773593902588, 7.3207550048828125, 9.660377502441406, 7.811320781707764, 9.169811248779297, 8.49056625366211, 11.735849380493164, 9.169811248779297, 10.301886558532715, 20.0, 9.660377502441406, 9.39622688293457, 8.264150619506836, 11.735849380493164, 9.43396282196045, 11.283019065856934, 9.886792182922363, 11.962264060974121, 7.584905624389648, 7.773585319519043] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.0, 6.0, 3.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 6.0, 4.0, 3.0, 3.0, 5.0, 4.0, 5.0, 4.0, 5.0, 3.0, 2.0] | 9.655660                    | 4.718750         | 3.375000          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 13:27:39,993][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 13:27:40,062][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 13:27:40,062][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 13:27:40,082][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 13:27:40,105][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 13:27:40,105][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 13:27:40,172][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 13:27:40,173][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 13:27:40,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 13:27:40,596][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 13:27:40,618][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 13:27:40,641][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 13:27:40,663][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 13:27:40,708][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 14
[2025-06-08 13:27:40,776][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 13:27:40,798][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 13:27:41,158][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 13:27:41,159][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 13:27:41,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 13:27:41,205][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 13:27:41,205][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 13:27:41,314][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 13:27:41,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 13:27:41,458][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 13:27:41,711][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 13:27:41,754][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 13:27:41,802][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 13:27:41,828][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 13:27:41,940][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 13:27:41,940][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 13:27:41,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 13:27:42,027][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 13:27:42,028][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 24000.000000 | iteration_24000.pth.tar | 32.000000     | 817.000000    | 25.531250               | 2.481889      | 329.184725          | 12.893404            | 0.031250    | 0.173993   | 1.000000   | 0.000000   | [8.037735939025879, 9.8490571975708, 8.264150619506836, 11.056604385375977, 9.88679313659668, 8.49056625366211, 8.226415634155273, 10.377358436584473, 5.698113441467285, 7.358490943908691, 9.660377502441406, 9.886792182922363, 8.49056625366211, 7.358490943908691, 10.075471878051758, 9.886792182922363, 9.207547187805176, 20.0, 11.962264060974121, 8.94339656829834, 10.566038131713867, 9.886792182922363, 9.88679313659668, 8.226415634155273, 8.716980934143066, 7.358490943908691, 10.075471878051758, 8.49056625366211, 10.075471878051758, 7.584905624389648, 8.981132507324219, 9.207547187805176] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [3.0, 3.0, 3.0, 5.0, 4.0, 3.0, 2.0, 5.0, 1.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 4.0, 4.0, 6.0, 5.0, 3.0, 4.0, 4.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0] | 9.430425                    | 4.875000         | 3.468750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 14:11:27,361][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 14:11:27,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 14:11:27,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 14:11:27,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 14:11:27,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 14:11:27,420][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 14:11:27,440][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 14:11:27,483][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 14:11:27,904][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 14:11:27,924][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 14:11:27,945][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 14:11:27,945][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 14:11:27,963][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 14:11:27,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 14:11:28,115][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 14:11:28,137][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 14:11:28,431][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 14:11:28,474][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 14:11:28,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 14:11:28,542][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 14:11:28,543][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 14:11:28,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 22
[2025-06-08 14:11:28,664][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 14:11:28,687][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 14:11:29,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 14:11:29,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 14:11:29,128][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 14:11:29,128][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 14:11:29,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 14:11:29,171][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 14:11:29,191][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 14:11:29,237][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 14:11:29,238][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 25000.000000 | iteration_25000.pth.tar | 32.000000     | 809.000000    | 25.281250               | 2.376481      | 340.419342          | 13.465289            | 0.031250    | 0.173993   | 1.000000   | 0.000000   | [5.056603908538818, 8.716980934143066, 9.39622688293457, 8.981132507324219, 6.641509532928467, 11.018868446350098, 8.981132507324219, 8.754716873168945, 9.886792182922363, 11.50943374633789, 9.169811248779297, 8.037735939025879, 8.0, 8.94339656829834, 10.339622497558594, 9.622641563415527, 8.0, 10.113207817077637, 20.0, 8.037735939025879, 8.981132507324219, 11.283019065856934, 8.981132507324219, 9.622641563415527, 8.49056625366211, 10.566038131713867, 9.660377502441406, 9.169811248779297, 10.301886558532715, 6.415094375610352, 10.33962345123291, 7.811320781707764] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [2.0, 3.0, 3.0, 4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 4.0, 6.0, 3.0, 4.0, 5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0] | 9.400944                    | 4.875000         | 3.437500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 14:55:18,180][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 14:55:18,204][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 14:55:18,247][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 14:55:18,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 14:55:18,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 14:55:18,320][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 14:55:18,320][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 14:55:18,342][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 14:55:18,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 14:55:18,827][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 14:55:18,827][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 14:55:18,846][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 14:55:18,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 14:55:18,867][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 14:55:18,955][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 14:55:19,046][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 14:55:19,353][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 14:55:19,374][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 14:55:19,396][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 14:55:19,418][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 14:55:19,462][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 14:55:19,529][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 14:55:19,598][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 14:55:19,598][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 14:55:19,869][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 14:55:19,937][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 14:55:19,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 14:55:20,033][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 14:55:20,077][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 14:55:20,221][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 14:55:20,221][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 14:55:20,241][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 14:55:20,242][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 26000.000000 | iteration_26000.pth.tar | 32.000000     | 849.000000    | 26.531250               | 2.538458      | 334.455011          | 12.606078            | 0.000000    | 0.000000   | 0.000000   | 0.000000   | [8.981132507324219, 9.39622688293457, 8.264151573181152, 9.43396282196045, 8.981132507324219, 11.962264060974121, 7.811320781707764, 10.830188751220703, 10.113207817077637, 8.716980934143066, 11.50943374633789, 8.037735939025879, 7.094339847564697, 9.43396282196045, 9.39622688293457, 4.150943279266357, 8.49056625366211, 10.566038131713867, 9.169811248779297, 8.754716873168945, 8.94339656829834, 9.39622688293457, 9.886792182922363, 11.962264060974121, 8.981132507324219, 9.886792182922363, 10.377358436584473, 8.528302192687988, 9.43396282196045, 9.207547187805176, 9.660377502441406, 10.339622497558594] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [4.0, 3.0, 3.0, 4.0, 4.0, 5.0, 3.0, 5.0, 4.0, 3.0, 5.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0] | 9.303066                    | 5.000000         | 3.718750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 15:39:09,610][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 15:39:09,632][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 15:39:09,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 15:39:09,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 4
[2025-06-08 15:39:09,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 15:39:09,759][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 15:39:09,779][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 15:39:09,847][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 15:39:10,132][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 15:39:10,176][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 15:39:10,197][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 15:39:10,302][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 15:39:10,343][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 15:39:10,343][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 15:39:10,362][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 15:39:10,384][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 15:39:10,721][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 15:39:10,721][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 15:39:10,768][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 15:39:10,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 15:39:10,907][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 15:39:10,927][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 15:39:10,950][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 15:39:10,973][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 15:39:11,524][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 15:39:11,592][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 15:39:11,661][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 15:39:11,661][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 15:39:11,706][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 15:39:11,727][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 30
[2025-06-08 15:39:11,751][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 15:39:12,018][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 15:39:12,019][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 27000.000000 | iteration_27000.pth.tar | 32.000000     | 937.000000    | 29.281250               | 2.896000      | 323.549724          | 11.049724            | 0.062500    | 0.242061   | 1.000000   | 0.000000   | [11.962264060974121, 7.358490943908691, 10.113207817077637, 20.0, 10.377358436584473, 8.716980934143066, 9.660377502441406, 9.88679313659668, 8.037735939025879, 11.509434700012207, 8.301886558532715, 11.05660343170166, 11.056604385375977, 10.792452812194824, 8.754716873168945, 9.660377502441406, 20.0, 8.716980934143066, 8.94339656829834, 9.43396282196045, 8.528302192687988, 9.886792182922363, 8.754716873168945, 9.886792182922363, 8.49056625366211, 9.169811248779297, 10.603774070739746, 10.603774070739746, 8.037735939025879, 11.283019065856934, 9.622641563415527, 7.5471696853637695] | [5.0, 5.0, 5.0, 2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [5.0, 3.0, 4.0, 6.0, 5.0, 3.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 4.0, 6.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 5.0, 5.0, 3.0, 5.0, 3.0, 2.0] | 10.211085                   | 4.781250         | 4.031250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 16:30:57,435][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 16:30:57,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 16:30:57,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 16:30:57,464][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 4
[2025-06-08 16:30:57,464][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 16:30:57,464][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 16:30:57,515][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 16:30:57,547][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 16:30:58,299][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 9
[2025-06-08 16:30:58,299][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 10
[2025-06-08 16:30:58,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 16:30:58,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-08 16:30:58,327][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 16:30:58,356][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 16:30:58,380][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 16:30:58,489][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 16:30:59,060][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 16:30:59,141][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 16:30:59,175][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 16:30:59,175][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 16:30:59,206][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 16:30:59,243][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 16:30:59,344][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 16:30:59,647][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 16:31:00,279][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 16:31:00,328][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 16:31:00,618][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 16:31:00,649][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 16:31:00,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 16:31:00,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 16:31:00,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 16:31:00,910][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 16:31:00,912][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 28000.000000 | iteration_28000.pth.tar | 32.000000     | 857.000000    | 26.781250               | 4.245594      | 201.856313          | 7.537225             | 0.125000    | 0.330719   | 1.000000   | 0.000000   | [20.0, 20.0, 9.207547187805176, 11.283019065856934, 8.49056625366211, 10.113207817077637, 8.94339656829834, 11.018868446350098, 9.207547187805176, 10.113207817077637, 8.037735939025879, 8.94339656829834, 11.735849380493164, 9.660377502441406, 10.113207817077637, 8.49056625366211, 9.88679313659668, 20.0, 8.754716873168945, 7.584905624389648, 8.754716873168945, 20.0, 8.49056625366211, 11.283019065856934, 10.339622497558594, 8.981132507324219, 5.735849380493164, 11.283019065856934, 9.886792182922363, 9.43396282196045, 7.584905624389648, 6.905660629272461] | [1.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [6.0, 6.0, 4.0, 5.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 3.0, 4.0, 6.0, 4.0, 3.0, 4.0, 6.0, 3.0, 5.0, 4.0, 4.0, 2.0, 5.0, 4.0, 4.0, 3.0, 3.0] | 10.633255                   | 4.468750         | 4.031250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 17:31:01,297][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 17:31:01,374][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 17:31:01,374][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 17:31:01,396][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 17:31:01,422][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 17:31:01,422][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 17:31:01,518][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 17:31:01,600][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 17:31:02,074][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 17:31:02,098][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 17:31:02,129][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 17:31:02,219][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 17:31:02,319][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 17:31:02,319][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 17:31:02,375][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 17:31:02,474][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 17:31:02,729][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 17:31:02,752][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 17:31:02,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 17:31:03,019][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 17:31:03,019][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 17:31:03,041][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 17:31:03,110][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 17:31:03,236][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 17:31:03,385][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 17:31:03,385][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 17:31:03,697][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 17:31:03,747][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 17:31:03,799][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 17:31:03,826][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 30
[2025-06-08 17:31:03,906][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 17:31:04,136][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 17:31:04,138][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 29000.000000 | iteration_29000.pth.tar | 32.000000     | 953.000000    | 29.781250               | 3.509995      | 271.510330          | 9.116821             | 0.031250    | 0.173993   | 1.000000   | 0.000000   | [7.773584842681885, 9.207547187805176, 8.94339656829834, 9.169811248779297, 10.377358436584473, 10.566038131713867, 6.4528303146362305, 10.339622497558594, 9.886792182922363, 11.962264060974121, 10.113207817077637, 20.0, 8.49056625366211, 9.39622688293457, 5.962264060974121, 8.716980934143066, 9.660377502441406, 8.94339656829834, 9.207547187805176, 11.962264060974121, 11.283019065856934, 7.811320781707764, 9.660377502441406, 10.566038131713867, 9.43396282196045, 9.169811248779297, 8.981132507324219, 11.962264060974121, 8.716980934143066, 11.962264060974121, 10.792452812194824, 10.339622497558594] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [2.0, 4.0, 3.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 4.0, 6.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 3.0, 5.0, 4.0, 4.0] | 9.931604                    | 4.875000         | 3.812500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 18:43:33,639][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 18:43:33,675][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 18:43:33,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 18:43:33,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 18:43:33,705][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 18:43:33,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 18:43:33,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 18:43:33,738][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 18:43:34,662][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 18:43:34,697][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 18:43:34,697][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 18:43:34,778][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 18:43:34,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 13
[2025-06-08 18:43:34,856][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 18:43:34,959][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 18:43:35,205][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 18:43:35,716][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 18:43:35,752][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 18:43:35,786][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 18:43:35,818][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 18:43:35,856][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 18:43:35,889][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 18:43:35,966][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 18:43:36,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 18:43:36,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 18:43:36,893][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 18:43:36,928][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 18:43:37,025][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 18:43:37,053][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 18:43:37,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 18:43:37,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 18:43:38,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 18:43:38,053][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 30000.000000 | iteration_30000.pth.tar | 32.000000     | 985.000000    | 30.781250               | 5.324529      | 184.992895          | 6.009921             | 0.031250    | 0.173993   | 1.000000   | 0.000000   | [10.113207817077637, 20.0, 8.301886558532715, 8.716980934143066, 9.88679313659668, 11.735849380493164, 10.830188751220703, 10.113207817077637, 10.113207817077637, 10.603774070739746, 7.5471696853637695, 11.056604385375977, 10.113207817077637, 7.3207550048828125, 8.754716873168945, 9.43396282196045, 9.886792182922363, 8.037735939025879, 8.94339656829834, 11.962264060974121, 8.981132507324219, 8.94339656829834, 10.792452812194824, 8.981132507324219, 8.981132507324219, 10.113207817077637, 8.49056625366211, 8.754716873168945, 11.018868446350098, 9.886792182922363, 9.39622688293457, 11.962264060974121] | [5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [4.0, 6.0, 4.0, 3.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 2.0, 5.0, 4.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 5.0] | 9.992925                    | 4.875000         | 3.937500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 19:40:26,537][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 19:40:26,537][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 19:40:26,583][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 19:40:26,629][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 19:40:26,651][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 19:40:26,651][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 19:40:26,673][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 19:40:26,807][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 19:40:27,648][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 19:40:27,648][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 19:40:27,676][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 19:40:27,718][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 19:40:27,749][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 19:40:27,838][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 19:40:27,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 19:40:27,911][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 19:40:28,281][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 19:40:28,358][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 19:40:28,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 19:40:28,470][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 19:40:28,539][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 19:40:28,563][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 19:40:28,653][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 19:40:28,701][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 19:40:29,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 19:40:29,086][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 19:40:29,087][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-08 19:40:29,258][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 19:40:29,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 19:40:29,289][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 19:40:29,364][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 19:40:29,456][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 19:40:29,457][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 31000.000000 | iteration_31000.pth.tar | 32.000000     | 875.000000    | 27.343750               | 3.522782      | 248.383222          | 9.083729             | 0.031250    | 0.173993   | 1.000000   | 0.000000   | [8.264150619506836, 9.43396282196045, 9.169811248779297, 8.49056625366211, 10.792452812194824, 9.207547187805176, 9.43396282196045, 10.339622497558594, 7.773585319519043, 9.207547187805176, 6.150943279266357, 11.962264060974121, 10.377358436584473, 9.622641563415527, 6.867924690246582, 9.43396282196045, 9.39622688293457, 9.622641563415527, 4.377358436584473, 20.0, 11.509434700012207, 9.8490571975708, 11.735849380493164, 9.207547187805176, 11.018868446350098, 7.811320781707764, 11.735849380493164, 9.622641563415527, 10.566038131713867, 11.735849380493164, 11.018868446350098, 9.39622688293457] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 2.0, 4.0, 1.0, 5.0, 5.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 6.0, 5.0, 3.0, 5.0, 4.0, 4.0, 3.0, 5.0, 3.0, 4.0, 5.0, 4.0, 3.0] | 9.847878                    | 4.843750         | 3.656250          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 20:31:08,321][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 20:31:08,343][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 20:31:08,386][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 20:31:08,386][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 20:31:08,407][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 5
[2025-06-08 20:31:08,408][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 6
[2025-06-08 20:31:08,428][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 20:31:08,539][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 20:31:08,935][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 20:31:09,019][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 10
[2025-06-08 20:31:09,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 11
[2025-06-08 20:31:09,085][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 12
[2025-06-08 20:31:09,146][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 20:31:09,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 20:31:09,213][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 20:31:09,535][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 20:31:09,985][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 20:31:09,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 20:31:09,986][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 20:31:10,091][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 20:31:10,135][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 20:31:10,170][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 20:31:10,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 20:31:10,589][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 20:31:10,799][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 20:31:10,799][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 20:31:10,819][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 20:31:10,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 20:31:10,913][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 20:31:10,944][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 20:31:11,207][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 20:31:11,379][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 20:31:11,380][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 32000.000000 | iteration_32000.pth.tar | 32.000000     | 1001.000000   | 31.281250               | 3.590349      | 278.802989          | 8.912783             | 0.156250    | 0.363092   | 1.000000   | 0.000000   | [8.49056625366211, 20.0, 11.962264060974121, 10.792452812194824, 8.754716873168945, 9.660377502441406, 9.169811248779297, 11.018868446350098, 20.0, 10.566038131713867, 9.39622688293457, 8.49056625366211, 8.226415634155273, 20.0, 9.660377502441406, 8.528302192687988, 8.037735939025879, 11.962264060974121, 10.377358436584473, 10.830188751220703, 6.188679218292236, 8.49056625366211, 11.283019065856934, 10.339622497558594, 20.0, 20.0, 8.301886558532715, 8.301886558532715, 11.962264060974121, 10.830188751220703, 11.018868446350098, 8.264150619506836] | [5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [3.0, 6.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 6.0, 4.0, 3.0, 3.0, 2.0, 6.0, 4.0, 4.0, 3.0, 5.0, 5.0, 5.0, 2.0, 3.0, 5.0, 4.0, 6.0, 6.0, 4.0, 4.0, 5.0, 5.0, 4.0, 3.0] | 11.278302                   | 4.375000         | 4.187500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 21:23:08,667][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 21:23:08,667][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 21:23:08,696][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 21:23:08,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 21:23:08,719][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 21:23:08,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 21:23:08,859][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 21:23:08,991][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 21:23:09,453][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 9
[2025-06-08 21:23:09,479][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 10
[2025-06-08 21:23:09,557][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 21:23:09,680][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 21:23:09,814][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 21:23:09,908][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 21:23:09,991][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 21:23:10,220][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 21:23:10,325][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 21:23:10,645][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 18
[2025-06-08 21:23:10,716][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 19
[2025-06-08 21:23:10,815][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 20
[2025-06-08 21:23:10,868][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 21:23:10,899][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 21:23:11,023][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 21:23:11,152][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 21:23:11,286][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 21:23:11,419][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 21:23:11,462][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 21:23:11,483][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 21:23:11,506][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 21:23:11,661][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 21:23:11,742][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 21:23:11,842][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 32
[2025-06-08 21:23:11,844][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 33000.000000 | iteration_33000.pth.tar | 32.000000     | 1001.000000   | 31.281250               | 4.750093      | 210.732705          | 6.736710             | 0.156250    | 0.363092   | 1.000000   | 0.000000   | [9.207547187805176, 11.735849380493164, 20.0, 8.528302192687988, 11.056604385375977, 9.43396282196045, 11.962264060974121, 7.773584842681885, 10.566038131713867, 7.811320781707764, 20.0, 10.339622497558594, 11.50943374633789, 10.603774070739746, 10.792452812194824, 11.245283126831055, 10.113207817077637, 20.0, 11.962264060974121, 11.056604385375977, 8.264151573181152, 9.207547187805176, 9.169811248779297, 9.207547187805176, 8.981132507324219, 11.50943374633789, 20.0, 9.169811248779297, 11.056604385375977, 11.283019065856934, 9.886792182922363, 20.0] | [5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 1.0] | [4.0, 5.0, 6.0, 4.0, 5.0, 4.0, 5.0, 2.0, 4.0, 3.0, 6.0, 4.0, 5.0, 5.0, 4.0, 4.0, 4.0, 6.0, 5.0, 5.0, 3.0, 4.0, 3.0, 4.0, 4.0, 5.0, 6.0, 3.0, 5.0, 5.0, 4.0, 6.0] | 11.669811                   | 4.343750         | 4.437500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 22:20:30,416][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 22:20:30,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 2
[2025-06-08 22:20:30,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 3
[2025-06-08 22:20:30,448][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 4
[2025-06-08 22:20:30,475][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 22:20:30,475][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 22:20:30,564][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 22:20:30,857][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 22:20:31,746][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 9
[2025-06-08 22:20:31,746][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 1.0, current episode: 10
[2025-06-08 22:20:32,152][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 22:20:32,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 12
[2025-06-08 22:20:32,184][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 22:20:32,686][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 22:20:33,332][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 22:20:34,043][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 22:20:34,522][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 22:20:34,575][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 18
[2025-06-08 22:20:34,601][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 22:20:34,601][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 22:20:34,601][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 22:20:34,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 22:20:34,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 22:20:34,894][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 22:20:35,325][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 22:20:35,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 26
[2025-06-08 22:20:35,383][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 27
[2025-06-08 22:20:35,494][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 22:20:35,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 22:20:35,513][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 22:20:35,744][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 22:20:35,810][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 32
[2025-06-08 22:20:35,811][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 34000.000000 | iteration_34000.pth.tar | 32.000000     | 905.000000    | 28.281250               | 6.419990      | 140.965957          | 4.984432             | 0.125000    | 0.330719   | 1.000000   | 0.000000   | [9.886792182922363, 9.886792182922363, 8.0, 9.88679313659668, 10.113207817077637, 6.4528303146362305, 11.962264060974121, 20.0, 7.773585319519043, 20.0, 8.49056625366211, 11.283019065856934, 10.830188751220703, 9.660377502441406, 9.433961868286133, 8.49056625366211, 9.43396282196045, 20.0, 9.622641563415527, 8.94339656829834, 8.716980934143066, 20.0, 9.88679313659668, 9.207547187805176, 10.113207817077637, 9.39622688293457, 8.981132507324219, 9.886792182922363, 6.226415157318115, 9.43396282196045, 10.830188751220703, 9.849056243896484] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0] | [4.0, 4.0, 2.0, 4.0, 4.0, 3.0, 5.0, 6.0, 2.0, 6.0, 3.0, 5.0, 5.0, 4.0, 4.0, 3.0, 4.0, 6.0, 3.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 3.0, 4.0, 5.0, 3.0] | 10.708727                   | 4.468750         | 3.968750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-08 23:16:15,484][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 1
[2025-06-08 23:16:15,533][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 2
[2025-06-08 23:16:15,533][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 3
[2025-06-08 23:16:15,554][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 4
[2025-06-08 23:16:15,578][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 5
[2025-06-08 23:16:15,578][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-08 23:16:15,621][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 7
[2025-06-08 23:16:15,643][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 8
[2025-06-08 23:16:16,204][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 9
[2025-06-08 23:16:16,232][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 10
[2025-06-08 23:16:16,254][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 11
[2025-06-08 23:16:16,276][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 12
[2025-06-08 23:16:16,302][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 13
[2025-06-08 23:16:16,302][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 14
[2025-06-08 23:16:16,324][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 15
[2025-06-08 23:16:16,363][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 16
[2025-06-08 23:16:16,959][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 17
[2025-06-08 23:16:17,003][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-06-08 23:16:17,003][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 19
[2025-06-08 23:16:17,034][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 20
[2025-06-08 23:16:17,063][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 21
[2025-06-08 23:16:17,186][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 22
[2025-06-08 23:16:17,298][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 23
[2025-06-08 23:16:17,329][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 24
[2025-06-08 23:16:17,796][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 25
[2025-06-08 23:16:17,831][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 1.0, current episode: 26
[2025-06-08 23:16:17,907][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 1.0, current episode: 27
[2025-06-08 23:16:17,954][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 28
[2025-06-08 23:16:17,954][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 29
[2025-06-08 23:16:18,423][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 30
[2025-06-08 23:16:19,240][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 31
[2025-06-08 23:16:19,402][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 32
[2025-06-08 23:16:19,404][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 35000.000000 | iteration_35000.pth.tar | 32.000000     | 946.000000    | 29.562500               | 4.504375      | 210.018015          | 7.104203             | 0.218750    | 0.413399   | 1.000000   | 0.000000   | [20.0, 10.113207817077637, 20.0, 10.075471878051758, 9.660377502441406, 11.283019065856934, 11.05660343170166, 11.962264060974121, 11.735849380493164, 9.207547187805176, 8.94339656829834, 7.358490943908691, 20.0, 9.660377502441406, 11.50943374633789, 8.037735939025879, 6.867924690246582, 10.830188751220703, 10.113207817077637, 20.0, 11.50943374633789, 8.037735939025879, 11.962264060974121, 11.056604385375977, 10.339622497558594, 8.754716873168945, 9.849056243896484, 20.0, 20.0, 20.0, 11.245283126831055, 8.981132507324219] | [1.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 1.0, 1.0, 5.0, 5.0] | [6.0, 4.0, 6.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.0, 6.0, 4.0, 5.0, 3.0, 2.0, 5.0, 4.0, 6.0, 5.0, 3.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 6.0, 6.0, 4.0, 4.0] | 12.192217                   | 4.031250         | 4.468750          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
[2025-06-09 00:07:06,294][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 1
[2025-06-09 00:07:06,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 2
[2025-06-09 00:07:06,318][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 3
[2025-06-09 00:07:06,391][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 4
[2025-06-09 00:07:06,391][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 5
[2025-06-09 00:07:06,415][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 6
[2025-06-09 00:07:06,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 7
[2025-06-09 00:07:06,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 8
[2025-06-09 00:07:06,916][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 9
[2025-06-09 00:07:06,960][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 1.0, current episode: 10
[2025-06-09 00:07:07,051][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 11
[2025-06-09 00:07:07,072][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 12
[2025-06-09 00:07:07,092][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 13
[2025-06-09 00:07:07,136][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 14
[2025-06-09 00:07:07,182][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 15
[2025-06-09 00:07:07,202][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 16
[2025-06-09 00:07:07,492][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 0.0, current episode: 17
[2025-06-09 00:07:07,661][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 18
[2025-06-09 00:07:07,683][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 19
[2025-06-09 00:07:07,707][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 1.0, current episode: 20
[2025-06-09 00:07:07,760][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 21
[2025-06-09 00:07:07,784][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 1.0, current episode: 22
[2025-06-09 00:07:07,812][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 23
[2025-06-09 00:07:07,812][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 24
[2025-06-09 00:07:08,087][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 3 finish episode, final reward: 1.0, current episode: 25
[2025-06-09 00:07:08,300][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 2 finish episode, final reward: 0.0, current episode: 26
[2025-06-09 00:07:08,321][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 4 finish episode, final reward: 0.0, current episode: 27
[2025-06-09 00:07:08,390][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 1 finish episode, final reward: 0.0, current episode: 28
[2025-06-09 00:07:08,436][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 5 finish episode, final reward: 0.0, current episode: 29
[2025-06-09 00:07:08,460][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.0, current episode: 30
[2025-06-09 00:07:08,460][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 7 finish episode, final reward: 0.0, current episode: 31
[2025-06-09 00:07:08,525][interaction_serial_evaluator.py][line: 201][    INFO] [EVALUATOR]env 6 finish episode, final reward: 0.0, current episode: 32
[2025-06-09 00:07:08,526][interaction_serial_evaluator.py][line: 227][    INFO] 
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Name  | train_iter   | ckpt_name               | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min | final_eval_fake_reward                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | dead_allies                                                                                                                                                      | dead_enemies                                                                                                                                                     | final_eval_fake_reward_mean | dead_allies_mean | dead_enemies_mean |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
| Value | 36000.000000 | iteration_36000.pth.tar | 32.000000     | 889.000000    | 27.781250               | 2.946729      | 301.690450          | 10.859499            | 0.156250    | 0.363092   | 1.000000   | 0.000000   | [10.339622497558594, 11.962264060974121, 10.113207817077637, 9.660377502441406, 10.566038131713867, 9.169811248779297, 20.0, 9.88679313659668, 8.226415634155273, 20.0, 10.566038131713867, 9.39622688293457, 8.226415634155273, 8.037735939025879, 9.622641563415527, 20.0, 8.754716873168945, 10.339622497558594, 7.811320781707764, 8.49056625366211, 8.45283031463623, 11.50943374633789, 9.169811248779297, 11.245283126831055, 10.566038131713867, 10.566038131713867, 11.735849380493164, 11.056604385375977, 20.0, 11.509434700012207, 20.0, 9.43396282196045] | [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 5.0, 0.0, 5.0] | [4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 6.0, 4.0, 2.0, 6.0, 4.0, 3.0, 2.0, 3.0, 3.0, 6.0, 4.0, 4.0, 3.0, 3.0, 2.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 6.0, 5.0, 6.0, 4.0] | 11.450472                   | 4.312500         | 4.062500          |
+-------+--------------+-------------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+------------------+-------------------+
